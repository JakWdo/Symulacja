# CLAUDE.md

Ten plik zawiera instrukcje dla Claude Code (claude.ai/code) podczas pracy z kodem w tym repozytorium.

## Output Style

**WA≈ªNE:** Dla tego projektu zawsze u≈ºywaj output style **"edukacyjny"**.

Aktywuj go na poczƒÖtku ka≈ºdej sesji poprzez wczytanie zawarto≈õci z:
`~/.claude/output-styles/edukacyjny.md`

Ten styl zapewnia:
- Konwersacyjny ton (jak kolega z zespo≈Çu)
- Edukacyjne wyja≈õnienia ("dlaczego", nie tylko "co")
- Production-ready kod i dokumentacja
- Polski w komunikacji, angielski w kodzie

## PrzeglƒÖd Projektu

Market Research SaaS - Platforma do wirtualnych grup fokusowych z AI wykorzystujƒÖca Google Gemini do generowania syntetycznych person i symulacji dyskusji badawczych. Wersja produkcyjna z pe≈ÇnƒÖ funkcjonalno≈õciƒÖ.

**Stack Technologiczny:**
- Backend: FastAPI (Python 3.11+), PostgreSQL + pgvector, Redis, Neo4j
- Frontend: React 18 + TypeScript, Vite, TanStack Query, Tailwind CSS
- AI: Google Gemini 2.5 (Flash/Pro) via LangChain
- Infrastruktura: Docker + Docker Compose

## Polecenia Deweloperskie

### Operacje Docker (Podstawowa Metoda Deweloperska)

**Architektura Docker:**
Projekt u≈ºywa **multi-stage Docker builds** dla optymalnej wydajno≈õci:
- **Development**: Hot reload, volume mounts, instant starty
- **Production**: Zoptymalizowane images, nginx, gunicorn, brak dev tools

**Aktywne Kontenery:**
- `postgres` - PostgreSQL + pgvector
- `redis` - Redis (cache i session storage)
- `neo4j` - Neo4j (graf wiedzy)
- `api` - Backend FastAPI
- `frontend` - Frontend React + Vite

#### Development Environment

```bash
# Uruchom wszystkie serwisy (DEVELOPMENT)
docker-compose up -d

# Pierwsze uruchomienie (force rebuild po zmianach w Dockerfile)
docker-compose up -d --build

# Logi
docker-compose logs -f api
docker-compose logs -f frontend

# Restart serwis√≥w (po zmianie kodu Python, je≈õli hot reload nie dzia≈Ça)
docker-compose restart api
docker-compose restart frontend

# Przebuduj kontenery (po zmianie dependencies: requirements.txt, package.json)
docker-compose up --build -d

# Zatrzymaj wszystkie serwisy
docker-compose down

# Zatrzymaj i usu≈Ñ wolumeny (USUWA DANE! U≈ºyj dla czystego startu)
docker-compose down -v
```

**WA≈ªNE - Nowa Architektura:**
- ‚úÖ **Instant starty**: Frontend NIE uruchamia `npm install` przy ka≈ºdym `up` (node_modules cached w image)
- ‚úÖ **Named volumes**: `frontend_node_modules` zapobiega konfliktom host vs container
- ‚úÖ **Multi-stage builds**: ~50% mniejsze images, szybsze buildy dziƒôki layer caching
- ‚úÖ **No duplication**: dependencies instalowane RAZ podczas build, nie przy ka≈ºdym start

**Kiedy Rebuild?**
- ‚úÖ Zmiana `requirements.txt` (Python deps) ‚Üí `docker-compose up --build -d`
- ‚úÖ Zmiana `package.json` (npm deps) ‚Üí `docker-compose up --build -d`
- ‚úÖ Zmiana `Dockerfile` ‚Üí `docker-compose up --build -d`
- ‚ùå Zmiana kodu `.py` lub `.tsx` ‚Üí NIE rebuild (hot reload dzia≈Ça)

#### Production Environment

```bash
# Deploy do produkcji
docker-compose -f docker-compose.prod.yml up -d --build

# Logi produkcyjne
docker-compose -f docker-compose.prod.yml logs -f

# Status serwis√≥w
docker-compose -f docker-compose.prod.yml ps

# Zatrzymaj produkcjƒô
docker-compose -f docker-compose.prod.yml down
```

**Production Features:**
- üöÄ **Frontend**: Nginx serving static build (~25MB image vs ~500MB dev)
- üöÄ **Backend**: Gunicorn z multiple workers (production ASGI server)
- üîí **Security**: Non-root users, resource limits, brak debug mode
- üì¶ **Optimized**: Multi-stage builds, brak development dependencies
- üîå **Internal network**: Databases NIE exposed na host (tylko internal Docker network)

**PRZED DEPLOYEM DO PRODUKCJI:**
1. Skopiuj `.env.production.example` ‚Üí `.env.production`
2. Wype≈Çnij **WSZYSTKIE** env vars (SECRET_KEY, passwords, API keys)
3. Zmie≈Ñ has≈Ça baz danych (POSTGRES_PASSWORD, NEO4J_PASSWORD)
4. Skonfiguruj ALLOWED_ORIGINS (tylko trusted domains)
5. Sprawd≈∫ checklist w `docker-compose.prod.yml`

### Migracje Bazy Danych (Alembic)

```bash
# Wykonaj migracje
docker-compose exec api alembic upgrade head

# Utw√≥rz nowƒÖ migracjƒô
docker-compose exec api alembic revision --autogenerate -m "opis"

# Rollback jednej migracji
docker-compose exec api alembic downgrade -1

# Historia migracji
docker-compose exec api alembic history
```

### Inicjalizacja Neo4j (WYMAGANE dla RAG)

```bash
# Utw√≥rz wymagane indeksy w Neo4j (vector + fulltext)
python scripts/init_neo4j_indexes.py

# Ten skrypt tworzy:
# 1. Vector index (rag_document_embeddings) - dla semantic search
# 2. Fulltext index (rag_fulltext_index) - dla keyword search

# WA≈ªNE: Uruchom ten skrypt PRZED pierwszym u≈ºyciem RAG!
```

### Testowanie

```bash
# Wszystkie testy
python -m pytest tests/ -v

# Z coverage
python -m pytest tests/ -v --cov=app --cov-report=html

# Konkretny plik testowy
python -m pytest tests/test_persona_generator.py -v

# Lista wszystkich test√≥w
python -m pytest tests/ --collect-only
```

### Rozw√≥j Frontendu

```bash
cd frontend

# Instalacja zale≈ºno≈õci
npm install

# Serwer deweloperski (standalone)
npm run dev

# Build produkcyjny
npm run build

# PodglƒÖd build produkcyjnego
npm run preview

# Lint TypeScript
npm run lint
```

## Architektura

### Wzorzec Service Layer (Backend)

Backend wykorzystuje **architekturƒô zorientowanƒÖ na serwisy**, gdzie logika biznesowa jest oddzielona od endpoint√≥w API:

```
Endpointy API (app/api/*.py)
    ‚Üì
Warstwa Serwis√≥w (app/services/*_langchain.py)
    ‚Üì
Modele/DB (app/models/*.py)
```

**Kluczowe Serwisy:**
- `PersonaGeneratorLangChain` - Generuje statystycznie reprezentatywne persony u≈ºywajƒÖc Gemini + statistical sampling (walidacja chi-kwadrat)
- `FocusGroupServiceLangChain` - Orkiestruje dyskusje grup fokusowych, przetwarza odpowiedzi r√≥wnolegle
- `MemoryServiceLangChain` - System event sourcing z semantic search u≈ºywajƒÖc Google embeddings
- `DiscussionSummarizerService` - Podsumowania AI u≈ºywajƒÖc Gemini Pro
- `PersonaValidator` - Walidacja statystyczna rozk≈Çad√≥w person
- `GraphService` - Analiza graf√≥w wiedzy w Neo4j (koncepty, emocje, relacje)
- `SurveyResponseGenerator` - Generator odpowiedzi na ankiety syntetyczne

### System Pamiƒôci i Kontekstu

Platforma u≈ºywa **event sourcing** dla pamiƒôci person:
1. Ka≈ºda akcja/odpowied≈∫ persony jest zapisywana jako niezmienny `PersonaEvent`
2. Eventy majƒÖ embeddingi (via Google Gemini) dla semantic search
3. Przy odpowiadaniu na pytania, pobierany jest kontekst z przesz≈Ço≈õci via similarity search
4. Zapewnia sp√≥jno≈õƒá w wielopytaniowych dyskusjach

### Architektura R√≥wnoleg≈Çego Przetwarzania

Grupy fokusowe przetwarzajƒÖ odpowiedzi person **r√≥wnolegle** u≈ºywajƒÖc asyncio:
- Ka≈ºda persona ma w≈Çasny async task
- ~20 person √ó 4 pytania = ~2-5 minut (vs 40+ minut sekwencyjnie)
- Target: <3s per persona response, <30s total focus group time

### Schemat Bazy Danych

G≈Ç√≥wne modele:
- `User` - U≈ºytkownicy systemu (autoryzacja JWT)
- `Project` - Kontener projektu badawczego
- `Persona` - Syntetyczna persona z demografiƒÖ + psychologiƒÖ (Big Five, Hofstede)
- `FocusGroup` - Sesja dyskusyjna ≈ÇƒÖczƒÖca persony z pytaniami
- `PersonaResponse` - Indywidualne odpowiedzi person
- `PersonaEvent` - Log event sourcing z embeddingami
- `Survey` - Ankiety z pytaniami (single/multiple choice, rating scale, open text)
- `SurveyResponse` - Odpowiedzi person na ankiety

## Konfiguracja i ≈örodowisko

**Wymagane Zmienne ≈örodowiskowe (.env):**

```bash
# Baza danych
DATABASE_URL=postgresql+asyncpg://market_research:password@postgres:5432/market_research_db

# AI (WYMAGANE!)
GOOGLE_API_KEY=your_gemini_api_key_here

# Modele
PERSONA_GENERATION_MODEL=gemini-2.5-flash
ANALYSIS_MODEL=gemini-2.5-pro
DEFAULT_MODEL=gemini-2.5-flash

# Redis & Neo4j
REDIS_URL=redis://redis:6379/0
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=dev_password_change_in_prod

# Bezpiecze≈Ñstwo (ZMIE≈É W PRODUKCJI!)
SECRET_KEY=change-me
ENVIRONMENT=development
DEBUG=true
```

**Wa≈ºne Ustawienia ([app/core/config.py](app/core/config.py)):**
- `TEMPERATURE=0.7` - Kreatywno≈õƒá LLM (0.0-1.0)
- `MAX_TOKENS=8000` - Maksymalna d≈Çugo≈õƒá odpowiedzi (gemini-2.5 u≈ºywa reasoning tokens!)
- `RANDOM_SEED=42` - Dla powtarzalno≈õci
- `MAX_RESPONSE_TIME_PER_PERSONA=3` - Cel wydajno≈õciowy (sekundy)
- `MAX_FOCUS_GROUP_TIME=30` - Cel czasu ca≈Çkowitego (sekundy)

**Konfiguracja RAG Hybrid Search:**
- `RAG_USE_HYBRID_SEARCH=True` - W≈ÇƒÖcz hybrid search (vector + keyword)
- `RAG_VECTOR_WEIGHT=0.7` - Waga vector search w RRF (0.0-1.0)
- `RAG_RRF_K=60` - Parametr wyg≈Çadzania Reciprocal Rank Fusion
- `RAG_TOP_K=5` - Liczba top wynik√≥w z retrieval
- `RAG_CHUNK_SIZE=2000` - Rozmiar chunk√≥w tekstowych (znaki)
- `RAG_CHUNK_OVERLAP=400` - Overlap miƒôdzy chunkami

**Konfiguracja GraphRAG Node Properties:**
- `RAG_NODE_PROPERTIES_ENABLED=True` - W≈ÇƒÖcz bogate metadane wƒôz≈Ç√≥w grafu
- `RAG_EXTRACT_SUMMARIES=True` - Ekstrakcja summary dla ka≈ºdego wƒôz≈Ça (1 zdanie)
- `RAG_EXTRACT_KEY_FACTS=True` - Ekstrakcja key_facts (lista fakt√≥w)
- `RAG_RELATIONSHIP_CONFIDENCE=True` - Ekstrakcja confidence dla relacji (0.0-1.0)

## Punkty Dostƒôpu API

- Backend API: http://localhost:8000
- API Docs (Swagger): http://localhost:8000/docs
- Frontend: http://localhost:5173
- Neo4j Browser: http://localhost:7474

## Typowe Workflow Deweloperskie

### Testowanie Po≈ÇƒÖczenia z Gemini API

```bash
# Sprawd≈∫ API key
docker-compose exec api printenv GOOGLE_API_KEY

# Testuj Gemini API bezpo≈õrednio
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=YOUR_KEY" \
  -H "Content-Type: application/json" \
  -d '{"contents":[{"parts":[{"text":"Hi"}]}]}'
```

### Tworzenie Testowych Projekt√≥w via API

```bash
# Utw√≥rz projekt
PROJECT_ID=$(curl -X POST http://localhost:8000/api/v1/projects \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test",
    "description": "Projekt testowy",
    "target_demographics": {
      "age_group": {"18-24": 0.5, "25-34": 0.5},
      "gender": {"Male": 0.5, "Female": 0.5}
    },
    "target_sample_size": 10
  }' | python3 -c "import sys,json; print(json.load(sys.stdin)['id'])")

# Generuj persony
curl -X POST "http://localhost:8000/api/v1/projects/$PROJECT_ID/personas/generate" \
  -H "Content-Type: application/json" \
  -d '{"num_personas": 10, "adversarial_mode": false}'

# Listuj persony
curl "http://localhost:8000/api/v1/projects/$PROJECT_ID/personas"
```

### Proces Generowania Person

Generowanie person u≈ºywa **hybrydowego AI + statistical sampling + RAG**:
1. Sample demografii z rozk≈Çad√≥w docelowych (walidacja chi-kwadrat)
2. Sample Big Five personality traits (rozk≈Çad normalny wok√≥≈Ç ≈õrednich populacyjnych)
3. Sample Hofstede cultural dimensions (bazowane na lokalizacji)
4. **RAG z Hybrid Search (zawsze aktywny)**:
   - **Vector search**: Semantic similarity przez Google Gemini embeddings
   - **Keyword search**: Lexical matching przez Neo4j fulltext index
   - **RRF Fusion**: Reciprocal Rank Fusion ≈ÇƒÖczy oba wyniki (k=60)
   - Pobiera najbardziej relevantny kontekst z raport√≥w o polskim spo≈Çecze≈Ñstwie
5. U≈ºyj Gemini do generacji realistycznej narracji profilu, t≈Ça, warto≈õci z kontekstem RAG
6. Waliduj dopasowanie statystyczne finalnej kohorty
7. Waliduj zgodno≈õƒá wieku z opisem (ekstrakcja wieku z background_story)

**Polskie Realia:**
- Imiona i nazwiska: 60+ polskich imion mƒôskich, 60+ ≈ºe≈Ñskich, 100+ nazwisk
- Dochody w z≈Çot√≥wkach (PLN): od <3000 z≈Ç do >15000 z≈Ç netto miesiƒôcznie
- Edukacja: polski system (podstawowe, zasadnicze zawodowe, ≈õrednie, policealne, wy≈ºsze)
- Lokalizacje: Warszawa, Krak√≥w, Wroc≈Çaw, Gda≈Ñsk, etc.
- Zawody: typowe dla polskiego rynku pracy
- Warto≈õci i zainteresowania: zgodne z polskƒÖ kulturƒÖ

**Dodatkowy Opis Grupy:**
- U≈ºytkownik mo≈ºe dodaƒá opis w AI Wizard (np. "Osoby zainteresowane ekologiƒÖ")
- Opis jest przekazywany do promptu LLM i wp≈Çywa na cechy person

**Wydajno≈õƒá:** ~30-60s dla 20 person (Gemini Flash)

**Testowanie Hybrid Search:**
```bash
# Test RAG hybrid search (wymaga uruchomionego Neo4j + zaindeksowanych dokument√≥w)
python tests/manual/test_hybrid_search.py
```

## System Analizy Grafowej (Graf Wiedzy)

Platforma zawiera **automatyczny graf wiedzy** zbudowany w Neo4j, kt√≥ry dostarcza g≈Çƒôbokich insight√≥w z dyskusji grup fokusowych. Po zako≈Ñczeniu ka≈ºdej grupy fokusowej, system automatycznie ekstraktuje koncepty, emocje i relacje u≈ºywajƒÖc LLM.

### Architektura

**Przep≈Çyw Danych:**
1. Grupa fokusowa ko≈Ñczy siƒô ‚Üí Automatyczne budowanie grafu
2. LLM (Gemini Flash) ekstraktuje koncepty, emocje, sentiment z ka≈ºdej odpowiedzi
3. Graf Neo4j tworzony z nodami: Personas, Concepts, Emotions
4. Relacje: MENTIONS, FEELS, AGREES_WITH, DISAGREES_WITH
5. Frontend pobiera i wizualizuje graf z zaawansowanƒÖ analitykƒÖ

**Kluczowe Komponenty:**
- **Backend:** [app/services/graph_service.py](app/services/graph_service.py) - Integracja Neo4j z LangChain
- **API:** [app/api/graph_analysis.py](app/api/graph_analysis.py) - Endpointy RESTful
- **Frontend:** [frontend/src/components/panels/GraphAnalysisPanel.tsx](frontend/src/components/panels/GraphAnalysisPanel.tsx) - Wizualizacja 3D + insighty

### Dostƒôpne Insighty Grafowe

**1. Kluczowe Koncepty** - Najczƒô≈õciej wspomniane tematy z sentimentem
```bash
GET /api/v1/graph/{focus_group_id}/concepts
```

**2. Kontrowersyjne Koncepty** - PolaryzujƒÖce tematy (wysoka wariancja sentymentu)
```bash
GET /api/v1/graph/{focus_group_id}/controversial
# Zwraca koncepty z podzia≈Çem na zwolennik√≥w vs krytyk√≥w
```

**3. Korelacje Trait-Opinion** - R√≥≈ºnice wiekowe/demograficzne w opiniach
```bash
GET /api/v1/graph/{focus_group_id}/correlations
# Pokazuje jak m≈Çodzi vs starsi uczestnicy czujƒÖ o konceptach
```

**4. Rozk≈Çad Emocji** - Emocjonalne odpowiedzi uczestnik√≥w
```bash
GET /api/v1/graph/{focus_group_id}/emotions
```

**5. Wp≈Çywowe Persony** - Najbardziej po≈ÇƒÖczeni uczestnicy (thought leaders)
```bash
GET /api/v1/graph/{focus_group_id}/influential
```

### Przyk≈Çad: Znajdowanie PolaryzujƒÖcych Temat√≥w

```bash
# Uruchom grupƒô fokusowƒÖ
curl -X POST http://localhost:8000/api/v1/focus-groups/{id}/run

# Graf jest automatycznie budowany po zako≈Ñczeniu

# Odpytaj kontrowersyjne koncepty
curl http://localhost:8000/api/v1/graph/{focus_group_id}/controversial
```

**Przyk≈Çadowa Odpowied≈∫:**
```json
{
  "controversial_concepts": [
    {
      "concept": "Cena",
      "avg_sentiment": 0.1,
      "polarization": 0.85,
      "supporters": ["Anna Kowalska", "Jan Nowak"],
      "critics": ["Maria Wi≈õniewska", "Piotr Zieli≈Ñski"],
      "total_mentions": 12
    }
  ]
}
```

### Zaawansowane Zapytania Cypher

System zawiera gotowe zapytania analityczne w [app/services/graph_service.py](app/services/graph_service.py):

- **Kontrowersyjne Koncepty:** `get_controversial_concepts()` - U≈ºywa odchylenia standardowego do znajdowania polaryzujƒÖcych temat√≥w
- **Korelacje Trait:** `get_trait_opinion_correlations()` - Segmentacja opinii bazowana na wieku
- **Analiza Wp≈Çywu:** `get_influential_personas()` - Liczenie po≈ÇƒÖcze≈Ñ w stylu PageRank

### U≈ºycie na Frontendzie

Zak≈Çadka Graph Analysis pojawia siƒô automatycznie po zako≈Ñczeniu grupy fokusowej:

1. Nawiguj do Focus Group ‚Üí zak≈Çadka "Graph Analysis"
2. Interaktywna wizualizacja 3D z kolorowanymi nodami:
   - üîµ Niebieski = Persony
   - üü£ Fioletowy = Koncepty
   - üü† Bursztynowy = Emocje
   - üü¢ Zielony = Pozytywny sentiment
   - üî¥ Czerwony = Negatywny sentiment
3. Sidebar pokazuje: Kluczowe Koncepty, Wp≈Çywowe Persony, Kontrowersyjne Tematy, Emocje, Korelacje Wiekowe
4. Kliknij nody aby eksplorowaƒá szczeg√≥≈Çy
5. U≈ºyj filtr√≥w: Wszystkie, Pozytywne, Negatywne, Wysoki Wp≈Çyw

### Wydajno≈õƒá i Optymalizacja

- **Ekstrakcja LLM:** ~0.5-1s per response (Gemini Flash)
- **Budowa Grafu:** ~30-60s dla 20 person √ó 4 pytania
- **Frontend:** Limit 100 najsilniejszych po≈ÇƒÖcze≈Ñ dla wydajno≈õci
- **Caching:** 5-minutowy stale time na zapytania frontendowe

### Rƒôczna Budowa Grafu (je≈õli potrzeba)

```bash
# Wymu≈õ przebudowƒô grafu
curl -X POST http://localhost:8000/api/v1/graph/build/{focus_group_id}
```

## System GraphRAG z Bogatymi Metadanymi

Platforma wykorzystuje **GraphRAG** (Graph + Retrieval-Augmented Generation) do budowy grafu wiedzy z dokument√≥w ≈∫r√≥d≈Çowych. System ekstraktuje nie tylko wƒôz≈Çy i relacje, ale tak≈ºe **bogate metadane** u≈ºywajƒÖc `LLMGraphTransformer` z LangChain.

### Architektura GraphRAG

**Serwisy:**
- [app/services/rag_service.py](app/services/rag_service.py) - G≈Ç√≥wny serwis RAG
  - `RAGDocumentService` - Ingest dokument√≥w, budowa grafu, Graph RAG queries
  - `PolishSocietyRAG` - Hybrid search dla generatora person

**Przep≈Çyw Przetwarzania Dokumentu:**
1. **LOAD** - PyPDFLoader/Docx2txtLoader wczytuje dokument
2. **SPLIT** - RecursiveCharacterTextSplitter dzieli na chunki (2000 znak√≥w, overlap 400)
3. **METADATA** - Dodanie doc_id, chunk_index, title, country
4. **GRAPH** - LLMGraphTransformer ekstraktuje graf z bogatymi w≈Ça≈õciwo≈õciami
5. **ENRICH** - `_enrich_graph_nodes()` wzbogaca metadane i waliduje jako≈õƒá
6. **VECTOR** - Zapis chunk√≥w do Neo4j Vector Store z embeddingami

### Bogate Metadane Wƒôz≈Ç√≥w (Node Properties)

Ka≈ºdy wƒôze≈Ç w grafie wiedzy zawiera nastƒôpujƒÖce w≈Ça≈õciwo≈õci:

**W≈Ça≈õciwo≈õci Tre≈õciowe:**
- `description` - Szczeg√≥≈Çowy opis kontekstu i znaczenia (2-3 zdania)
- `summary` - Jednozdaniowe streszczenie najwa≈ºniejszej informacji
- `key_facts` - Lista kluczowych fakt√≥w oddzielonych ≈õrednikami (min. 2-3 fakty)
- `source_context` - Bezpo≈õredni cytat ze ≈∫r√≥d≈Ça (20-50 s≈Ç√≥w) dla weryfikowalno≈õci

**W≈Ça≈õciwo≈õci Temporalne i Numeryczne:**
- `time_period` - Okres czasu je≈õli istnieje (format: "2020" lub "2018-2023")
- `magnitude` - Dla wska≈∫nik√≥w liczbowych, warto≈õƒá z jednostkƒÖ (np. "67%", "1.2 mln os√≥b")

**W≈Ça≈õciwo≈õci Jako≈õciowe:**
- `confidence_level` - Pewno≈õƒá danych: "high" (bezpo≈õrednie dane), "medium" (wnioski), "low" (spekulacje)

**Metadane Techniczne:**
- `doc_id` - UUID dokumentu ≈∫r√≥d≈Çowego (KRYTYCZNE dla usuwania dokument√≥w)
- `chunk_index` - Indeks fragmentu w dokumencie
- `document_title` - Tytu≈Ç dokumentu
- `document_country` - Kraj dokumentu
- `document_year` - Rok dokumentu
- `processed_at` - Timestamp przetwarzania ISO 8601

### Bogate Metadane Relacji (Relationship Properties)

Ka≈ºda relacja w grafie zawiera:

- `confidence` - Pewno≈õƒá relacji jako liczba 0.0-1.0 (string)
- `evidence` - Konkretny dow√≥d z tekstu uzasadniajƒÖcy relacjƒô
- `strength` - Si≈Ça relacji: "strong" (bezpo≈õrednia zale≈ºno≈õƒá), "moderate" (prawdopodobna), "weak" (mo≈ºliwa)
- `doc_id`, `chunk_index` - Metadane techniczne

### Typy Wƒôz≈Ç√≥w w Grafie

System u≈ºywa precyzyjnych typ√≥w wƒôz≈Ç√≥w:
- **Observation** - Konkretne obserwacje, fakty z bada≈Ñ
- **Indicator** - Wska≈∫niki liczbowe, statystyki, metryki
- **Demographic** - Grupy demograficzne, populacje
- **Trend** - Trendy czasowe, zmiany w czasie
- **Location** - Miejsca geograficzne
- **Cause** - Przyczyny zjawisk
- **Effect** - Skutki, konsekwencje

### Typy Relacji

- `DESCRIBES` - Opisuje cechƒô/w≈Ça≈õciwo≈õƒá
- `APPLIES_TO` - Dotyczy grupy/kategorii
- `SHOWS_TREND` - Pokazuje trend czasowy
- `LOCATED_IN` - Zlokalizowane w miejscu
- `CAUSED_BY` - Spowodowane przez
- `LEADS_TO` - Prowadzi do
- `COMPARES_TO` - Por√≥wnuje z

### Post-processing Metadanych

Funkcja `_enrich_graph_nodes()` automatycznie:
1. Dodaje `doc_id` i `chunk_index` do ka≈ºdego wƒôz≈Ça i relacji
2. Waliduje jako≈õƒá metadanych (sprawdza czy summary i description nie sƒÖ puste)
3. Dodaje timestamp przetwarzania
4. Normalizuje formaty danych:
   - `confidence_level`: wymusza "high", "medium", "low"
   - `confidence` w relacjach: waliduje 0.0-1.0, clamp do zakresu
   - `strength`: wymusza "strong", "moderate", "weak"
   - `magnitude`: konwertuje do string
5. Loguje ostrze≈ºenia je≈õli >30% wƒôz≈Ç√≥w nie ma pe≈Çnych metadanych

### Graph RAG Queries

System generuje zapytania Cypher u≈ºywajƒÖc LLM, kt√≥re wykorzystujƒÖ nowe w≈Ça≈õciwo≈õci:

**Przyk≈Çadowe Zapytania:**
```cypher
-- Znajd≈∫ najwiƒôksze wska≈∫niki
MATCH (n:Indicator)
WHERE n.magnitude IS NOT NULL
RETURN n.summary, n.magnitude, n.source_context
ORDER BY toFloat(split(n.magnitude, '%')[0]) DESC

-- Znajd≈∫ pewne fakty o temacie X
MATCH (n:Observation)
WHERE n.summary CONTAINS 'X' AND n.confidence_level = 'high'
RETURN n.description, n.key_facts, n.source_context

-- Jak X wp≈Çywa na Y? (silne relacje)
MATCH (cause)-[r:LEADS_TO]->(effect)
WHERE cause.summary CONTAINS 'X' AND effect.summary CONTAINS 'Y'
  AND r.strength = 'strong'
RETURN cause.summary, r.evidence, effect.summary, r.confidence

-- Trendy w latach 2020-2023
MATCH (n:Trend)
WHERE n.time_period >= '2020' AND n.time_period <= '2023'
RETURN n.summary, n.description, n.magnitude, n.time_period
ORDER BY n.time_period
```

**Funkcja `_generate_cypher_query()`:**
- LLM t≈Çumaczy pytanie u≈ºytkownika na zapytanie Cypher
- Prompt systemowy zawiera szczeg√≥≈Çowe instrukcje jak wykorzystaƒá w≈Ça≈õciwo≈õci wƒôz≈Ç√≥w
- Automatyczne filtrowanie po `confidence_level`, `strength`, `time_period`, `magnitude`
- Zawsze zwraca `source_context` dla weryfikowalno≈õci

### API Graph RAG

**Ingest Dokumentu:**
```bash
POST /api/v1/rag/documents
{
  "file": <PDF/DOCX file>,
  "title": "Raport o polskim spo≈Çecze≈Ñstwie 2023",
  "country": "Poland",
  "date": "2023"
}
```

**Odpytywanie Graph RAG:**
```bash
POST /api/v1/rag/query
{
  "question": "Jakie sƒÖ najwiƒôksze wska≈∫niki ub√≥stwa w Polsce?"
}
```

**Odpowied≈∫:**
```json
{
  "answer": "Wed≈Çug raport√≥w...",
  "graph_context": [
    {
      "indicator": "Stopa ub√≥stwa relatywnego",
      "magnitude": "17.3%",
      "summary": "Odsetek os√≥b ≈ºyjƒÖcych poni≈ºej granicy ub√≥stwa relatywnego",
      "description": "Wska≈∫nik ub√≥stwa relatywnego w Polsce wyni√≥s≈Ç 17.3% w 2022 roku...",
      "key_facts": "17.3% populacji; wzrost o 1.2% r/r; najwy≈ºszy w grupie 65+",
      "source_context": "Wed≈Çug GUS, stopa ub√≥stwa relatywnego wynios≈Ça 17.3% w 2022...",
      "confidence_level": "high",
      "time_period": "2022"
    }
  ],
  "vector_context": [...],
  "cypher_query": "MATCH (n:Indicator) WHERE n.magnitude IS NOT NULL..."
}
```

### Wydajno≈õƒá i Optymalizacja

- **Ekstrakcja LLM:** ~2-5s per chunk (Gemini Flash)
- **Budowa Grafu:** ~1-3 min dla dokumentu 50-page PDF
- **Post-processing:** ~0.5-1s (walidacja + normalizacja)
- **Graph RAG Query:** ~2-4s (Cypher generation + execution + LLM answer)

### Schemas Pydantic

[app/schemas/graph.py](app/schemas/graph.py) zawiera modele:
- `NodeProperties` - Bogate metadane wƒôz≈Ça (wszystkie w≈Ça≈õciwo≈õci)
- `RelationshipProperties` - Metadane relacji
- `GraphNode` - Rozszerzony o `properties: Optional[NodeProperties]`
- `GraphLink` - Rozszerzony o `properties: Optional[RelationshipProperties]`

### Testowanie GraphRAG

```bash
# Test pe≈Çnego pipeline ingest + Graph RAG
python -m pytest tests/test_rag_graph_properties.py -v

# Rƒôczne testowanie hybrid search
python tests/manual/test_hybrid_search.py

# Rƒôczne testowanie Graph RAG query
curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Jakie sƒÖ kluczowe trendy demograficzne w Polsce?"}'
```

## Konwencje Kodu

- Wszystkie serwisy u≈ºywajƒÖ **async/await** pattern (FastAPI + SQLAlchemy async)
- Abstrakcje LangChain u≈ºywane wszƒôdzie (`ChatGoogleGenerativeAI`, `ChatPromptTemplate`, etc.)
- Docstringi w jƒôzyku polskim (istniejƒÖca konwencja)
- Type hints wymagane dla wszystkich funkcji
- Sta≈Çe zdefiniowane w [app/core/constants.py](app/core/constants.py)

## RozwiƒÖzywanie Problem√≥w

### Backend nie startuje
```bash
docker-compose logs api  # Sprawd≈∫ b≈Çƒôdy
docker-compose restart api postgres
```

### Puste odpowiedzi person
Sprawd≈∫ [app/services/focus_group_service_langchain.py](app/services/focus_group_service_langchain.py) - upewnij siƒô ≈ºe `max_tokens` jest wystarczajƒÖco wysoki dla gemini-2.5 reasoning tokens (powinno byƒá 2048+)

### B≈Çƒôdy po≈ÇƒÖczenia z bazƒÖ
```bash
docker-compose ps  # Weryfikuj ≈ºe postgres jest healthy
docker-compose down -v && docker-compose up -d  # Opcja nuklearna (usuwa dane)
docker-compose exec api alembic upgrade head
```

### Wywo≈Çania API frontendu failujƒÖ
Sprawd≈∫ ≈ºe Vite proxy jest poprawnie skonfigurowane w [frontend/vite.config.ts](frontend/vite.config.ts) - powinno proxy `/api` do `http://api:8000`

### Neo4j nie startuje
```bash
docker-compose logs neo4j
docker-compose restart neo4j
curl http://localhost:7474  # Sprawd≈∫ po≈ÇƒÖczenie
```

## Struktura Plik√≥w

```
market-research-saas/
‚îú‚îÄ‚îÄ app/                              # Backend (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ api/                          # Endpointy REST API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py                  # Autoryzacja JWT
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ projects.py              # ZarzƒÖdzanie projektami
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ personas.py              # Generowanie person
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ focus_groups.py          # Grupy fokusowe
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ surveys.py               # Ankiety syntetyczne
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis.py              # Analizy AI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_analysis.py        # Analiza grafowa Neo4j
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.py                   # RAG endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py              # Ustawienia u≈ºytkownika i profil
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py          # Zale≈ºno≈õci FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ core/                         # Konfiguracja
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Ustawienia aplikacji
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constants.py             # Sta≈Çe
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security.py              # Bezpiecze≈Ñstwo i JWT
‚îÇ   ‚îú‚îÄ‚îÄ db/                           # Baza danych
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session.py               # Sesje SQLAlchemy
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                  # Base model
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # Modele SQLAlchemy (ORM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py                  # Model u≈ºytkownika
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.py               # Model projektu
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona.py               # Model persony
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ focus_group.py           # Model grupy fokusowej
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ survey.py                # Model ankiety
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona_events.py        # Model event√≥w
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_document.py          # Model dokument√≥w RAG
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                      # Pydantic schemas (API validation)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ focus_group.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ survey.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py              # Schemas dla ustawie≈Ñ
‚îÇ   ‚îú‚îÄ‚îÄ services/                     # Logika biznesowa
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona_generator_langchain.py       # Generator person
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ focus_group_service_langchain.py     # Orkiestracja dyskusji
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ survey_response_generator.py         # Generator odpowiedzi ankiet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discussion_summarizer.py             # AI podsumowania
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_service_langchain.py          # System pamiƒôci
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona_validator.py                 # Walidacja statystyczna
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_service.py                     # Graf wiedzy Neo4j
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_service.py                       # RAG hybrid search + GraphRAG
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # Aplikacja FastAPI
‚îú‚îÄ‚îÄ frontend/                         # Frontend (React + TypeScript)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/              # Komponenty React
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/             # Layout i nawigacja
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ panels/             # Panele funkcjonalne
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # Komponenty UI (shadcn/ui)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contexts/               # React Context (auth)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/                  # Custom hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/                    # API client & utilities
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts             # API client functions
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ avatar.ts          # Avatar utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ store/                  # Zustand store
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/                  # TypeScript types
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.ts
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ alembic/                          # Migracje bazy danych
‚îÇ   ‚îî‚îÄ‚îÄ versions/                    # Pliki migracji (12 migrations)
‚îú‚îÄ‚îÄ docs/                             # Dokumentacja techniczna
‚îÇ   ‚îú‚îÄ‚îÄ README.md                    # Indeks dokumentacji
‚îÇ   ‚îú‚îÄ‚îÄ TESTING.md                   # Dokumentacja test√≥w (208 test√≥w)
‚îÇ   ‚îî‚îÄ‚îÄ RAG.md                       # System RAG: Hybrid Search + GraphRAG
‚îú‚îÄ‚îÄ static/                           # Pliki statyczne
‚îÇ   ‚îî‚îÄ‚îÄ avatars/                     # Uploadowane avatary u≈ºytkownik√≥w
‚îú‚îÄ‚îÄ data/                             # Dane aplikacji (ignorowane w git)
‚îÇ   ‚îî‚îÄ‚îÄ documents/                   # Dokumenty RAG (PDFs)
‚îú‚îÄ‚îÄ tests/                            # Testy (208 test√≥w)
‚îÇ   ‚îú‚îÄ‚îÄ unit/                        # Testy jednostkowe (~150 test√≥w, <5s)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_core_config_security.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_persona_generator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_focus_group_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_graph_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_survey_response_generator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_memory_service_langchain.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_discussion_summarizer_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_persona_validator_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_critical_paths.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_analysis_api.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_graph_analysis_api.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_auth_api.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_main_api.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/                 # Testy integracyjne (~35 test√≥w, 10-30s)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_auth_api_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_projects_api_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_personas_api_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_focus_groups_api_integration.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_surveys_api_integration.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_settings_api_integration.py
‚îÇ   ‚îú‚îÄ‚îÄ e2e/                         # Testy end-to-end (~4 testy, 2-5 min)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_e2e_full_workflow.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_e2e_survey_workflow.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_e2e_graph_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ performance/                 # Testy wydajno≈õci (~5 test√≥w, 5-10 min)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_performance.py
‚îÇ   ‚îú‚îÄ‚îÄ error_handling/              # Testy b≈Çƒôd√≥w (~9 test√≥w, 5-10s)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_error_handling.py
‚îÇ   ‚îú‚îÄ‚îÄ manual/                      # Testy manualne (nie sƒÖ w test suite)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_hybrid_search.py   # Manual RAG hybrid search test
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py                  # Shared fixtures
‚îú‚îÄ‚îÄ scripts/                          # Skrypty pomocnicze
‚îÇ   ‚îú‚îÄ‚îÄ README.md                    # Dokumentacja skrypt√≥w
‚îÇ   ‚îú‚îÄ‚îÄ init_db.py                   # Inicjalizacja bazy danych
‚îÇ   ‚îî‚îÄ‚îÄ init_neo4j_indexes.py        # Inicjalizacja indeks√≥w Neo4j
‚îú‚îÄ‚îÄ docker-compose.yml                # Docker development environment
‚îú‚îÄ‚îÄ docker-compose.prod.yml           # Docker production environment
‚îú‚îÄ‚îÄ Dockerfile                        # Backend multi-stage Dockerfile
‚îú‚îÄ‚îÄ .dockerignore                     # Backend Docker ignore rules
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   # Frontend multi-stage Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf                   # Nginx config dla production
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore                # Frontend Docker ignore rules
‚îú‚îÄ‚îÄ docker-entrypoint.sh              # Docker entrypoint script (migrations)
‚îú‚îÄ‚îÄ start.sh                          # Quick start script
‚îú‚îÄ‚îÄ requirements.txt                  # Zale≈ºno≈õci Python
‚îú‚îÄ‚îÄ .env.example                      # Development environment template
‚îú‚îÄ‚îÄ .env.production.example           # Production environment template
‚îú‚îÄ‚îÄ .gitignore                        # Git ignore rules
‚îú‚îÄ‚îÄ pytest.ini                        # Pytest configuration
‚îú‚îÄ‚îÄ alembic.ini                       # Alembic configuration
‚îú‚îÄ‚îÄ README.md                         # Dokumentacja u≈ºytkownika
‚îî‚îÄ‚îÄ CLAUDE.md                         # Ten plik - dokumentacja deweloperska
```

## Funkcjonalno≈õci

### 0. ZarzƒÖdzanie Kontem i Ustawienia (Settings)

**Lokalizacja:**
- Backend: [app/api/settings.py](app/api/settings.py), [app/schemas/settings.py](app/schemas/settings.py)
- Frontend: [frontend/src/components/Settings.tsx](frontend/src/components/Settings.tsx)
- Utilities: [frontend/src/lib/avatar.ts](frontend/src/lib/avatar.ts)

**Funkcjonalno≈õci:**
- **Profil u≈ºytkownika** - GET/PUT `/api/v1/settings/profile`
  - Edycja: full_name, role, company
  - Model User rozszerzony o: avatar_url, role, company, plan, is_verified, last_login_at, deleted_at
- **Avatar management** - POST/DELETE `/api/v1/settings/avatar`
  - Upload: JPG, PNG, WEBP (max 2MB)
  - Walidacja: PIL Image validation, size check
  - Storage: `static/avatars/` directory (automatycznie tworzony)
  - Auto-cleanup starych avatar√≥w przy upload nowego
- **Statystyki konta** - GET `/api/v1/settings/stats`
  - Liczby: projects, personas, focus groups, surveys
  - Plan u≈ºytkownika (free/pro/enterprise)
- **Usuwanie konta** - DELETE `/api/v1/settings/account`
  - Soft delete (ustawia deleted_at, is_active=false)
  - Zachowuje dane dla compliance i audytu
- **Dark/Light mode** - frontend theme system
  - Theme toggle w Settings panel
  - Persistence w localStorage
  - System theme detection

**Notification Settings (przygotowane na przysz≈Ço≈õƒá):**
Model User zawiera pola:
- email_notifications_enabled
- discussion_complete_notifications
- weekly_reports_enabled
- system_updates_notifications

**Static Files Serving:**
```python
# app/main.py
app.mount("/static", StaticFiles(directory="static"), name="static")
```
Katalog `static/avatars/` automatycznie tworzony przy starcie ([app/api/settings.py](app/api/settings.py:37)).

**Frontend Utilities:**
```typescript
// frontend/src/lib/avatar.ts
getAvatarUrl(avatarUrl?: string): string // Konwersja relatywnych URL do pe≈Çnych
getInitials(name?: string): string       // Inicja≈Çy dla avatar fallback
```

**Wydajno≈õƒá:**
- Avatar upload: <500ms (walidacja + zapis)
- Profile update: <100ms
- Stats query: <200ms (4 count queries)

### 1. Generowanie Person
- Rozk≈Çady demograficzne (wiek, p≈Çeƒá, edukacja, doch√≥d, lokalizacja)
- Cechy psychologiczne (Big Five personality traits)
- Wymiary kulturowe (Hofstede dimensions)
- Walidacja statystyczna (test chi-kwadrat)
- Wydajno≈õƒá: ~30-60s dla 20 person

### 2. Grupy Fokusowe
- R√≥wnoleg≈Çe przetwarzanie odpowiedzi person (asyncio)
- System pamiƒôci (kontekst rozmowy, event sourcing)
- Sp√≥jno≈õƒá odpowiedzi miƒôdzy pytaniami
- Semantic search w historii (pgvector)
- Wydajno≈õƒá: ~2-5 min dla 20 person √ó 4 pytania

### 3. Ankiety Syntetyczne
- 4 typy pyta≈Ñ: Single choice, Multiple choice, Rating scale, Open text
- Drag & drop builder ankiet
- AI-powered responses (Gemini)
- R√≥wnoleg≈Çe przetwarzanie
- Analiza demograficzna (podzia≈Ç wed≈Çug wieku, p≈Çci, wykszta≈Çcenia, dochodu)
- Wizualizacje (bar charts, pie charts)
- Wydajno≈õƒá: ~1-3s per persona, <60s total

### 4. Analiza Grafowa (Neo4j)
- Graf wiedzy: Personas, Concepts, Emotions
- Relacje: MENTIONS, FEELS, AGREES_WITH, DISAGREES_WITH
- Kluczowe koncepty z sentimentem
- Kontrowersyjne tematy (wysoka polaryzacja)
- Wp≈Çywowe persony (PageRank-style)
- Korelacje demograficzne (wiek vs opinie)
- Rozk≈Çad emocji
- Wizualizacja 3D (React Three Fiber)
- Wydajno≈õƒá: ~30-60s dla 20 person √ó 4 pytania

### 5. Analizy AI
- Executive summaries (Gemini 2.5 Pro/Flash)
- Key insights i recommendations
- Sentiment analysis
- Idea score (0-100)
- Consensus level (0-1)

## Testowanie

```bash
# Wszystkie testy
python -m pytest tests/ -v

# Z coverage
python -m pytest tests/ -v --cov=app --cov-report=html

# Konkretny test
python -m pytest tests/test_persona_generator.py -v

# Critical paths
python -m pytest tests/test_critical_paths.py -v
```

**Dostƒôpne testy (134 testy):**
- `test_core_config_security.py` - konfiguracja i bezpiecze≈Ñstwo (6 test√≥w: settings singleton, password hashing, JWT, API key encryption)
- `test_persona_generator.py` - generowanie person
- `test_focus_group_service.py` - orkiestracja grup fokusowych
- `test_graph_service.py` - analiza grafowa Neo4j
- `test_survey_response_generator.py` - ankiety syntetyczne
- `test_memory_service_langchain.py` - system pamiƒôci
- `test_discussion_summarizer_service.py` - AI podsumowania
- `test_persona_validator_service.py` - walidacja statystyczna
- `test_critical_paths.py` - end-to-end critical paths (9 test√≥w: demographic distributions, Big Five traits, chi-square validation, performance metrics, event sourcing)
- `test_api_integration.py` - integracja API
- `test_auth_api.py` - autoryzacja i JWT
- `test_main_api.py` - g≈Ç√≥wne endpointy
- `test_models.py` - modele bazy danych

## Bezpiecze≈Ñstwo

- **JWT Authentication** - wszystkie chronione endpointy wymagajƒÖ tokena
- **Password hashing** - bcrypt dla hase≈Ç u≈ºytkownik√≥w
- **CORS** - konfigurowalny via ALLOWED_ORIGINS
- **Secret key** - MUSI byƒá zmieniony w produkcji
- **Environment-based config** - r√≥≈ºne ustawienia dla dev/prod

## Architektura Docker

**üìñ PE≈ÅNA DOKUMENTACJA:** [docs/DOCKER.md](docs/DOCKER.md)

### Szybki PrzeglƒÖd

**Multi-Stage Builds:**
- Backend: 850MB ‚Üí 450MB (builder + runtime stages)
- Frontend: 500MB ‚Üí 25MB production (deps + builder + dev + production stages)

**Key Features:**
- Instant frontend starty (30-60s ‚Üí <2s) - node_modules cached w image
- Named volume `frontend_node_modules` zapobiega konfliktom
- Hot reload dzia≈Ça out-of-the-box
- Development (docker-compose.yml) vs Production (docker-compose.prod.yml)

**Podstawowe Komendy:**
```bash
# Development
docker-compose up -d              # Start
docker-compose up --build -d      # Rebuild (po zmianie requirements.txt / package.json)
docker-compose logs -f api        # Logi

# Production
docker-compose -f docker-compose.prod.yml up -d --build
```

**Wiƒôcej:** Zobacz [docs/DOCKER.md](docs/DOCKER.md) dla pe≈Çnej dokumentacji architektury, troubleshooting, i best practices.

## Produkcja

### Wa≈ºne Zmiany dla Produkcji

1. **Zmie≈Ñ SECRET_KEY** - wygeneruj bezpieczny klucz
2. **Zmie≈Ñ has≈Ça baz danych** - PostgreSQL, Neo4j
3. **Skonfiguruj ALLOWED_ORIGINS** - tylko zaufane domeny
4. **Wy≈ÇƒÖcz DEBUG** - ustaw DEBUG=false
5. **U≈ºyj HTTPS** - dla wszystkich po≈ÇƒÖcze≈Ñ
6. **Backup bazy** - regularny backup PostgreSQL i Neo4j
7. **Monitoring** - logi, metryki, alerty
8. **Rate limiting** - ogranicz requests per IP
9. **Google API quota** - monitoruj u≈ºycie Gemini API

### Generowanie Secret Key

```bash
# Wygeneruj bezpieczny secret key
openssl rand -hex 32
```

## Wsparcie

W razie problem√≥w:
1. Sprawd≈∫ logi: `docker-compose logs -f api`
2. Sprawd≈∫ dokumentacjƒô API: http://localhost:8000/docs
3. Przeczytaj README.md
4. Otw√≥rz issue w repozytorium

---

# SIGHT-SPECIFIC: Zasady Deweloperskie

## Jako≈õƒá Kodu - Production-Ready Standard

### Wymagania Kodu

**1. Enterprise-Grade Architecture**
- ‚úÖ **SOLID principles** - stosuj gdzie sensowne (nie over-engineer)
- ‚úÖ **DRY** - unikaj duplikacji, ale bez przesady z abstrakcjƒÖ
- ‚úÖ **Design patterns** - u≈ºywaj gdy rozwiƒÖzujƒÖ realny problem
- ‚úÖ **Type safety** - pe≈Çne type hints we wszystkich funkcjach
- ‚úÖ **Error handling** - comprehensive exception handling z informacyjnymi messages
- ‚úÖ **Security** - input validation, sanitization, proper auth/authz
- ‚úÖ **Performance** - optymalizacje, caching, asyncio dla I/O-bound
- ‚úÖ **Maintainability** - kod czytelny dla innych developer√≥w

**2. Dokumentacja Production-Ready**
- ‚úÖ **API Documentation** - pe≈Çne docstringi w stylu Google/NumPy
- ‚úÖ **Inline comments** - wyja≈õniajƒÖ "dlaczego", nie "co"
- ‚úÖ **Type hints** - wszystkie funkcje, metody, zmienne
- ‚úÖ **Examples** - przyk≈Çady u≈ºycia w docstringach dla public API
- ‚úÖ **Edge cases** - dokumentacja corner cases
- ‚úÖ **Performance notes** - Big-O complexity dla algorytm√≥w

**3. Testowanie Enterprise**
- ‚úÖ **Unit tests** - coverage >80% dla critical paths
- ‚úÖ **Integration tests** - testowanie wsp√≥≈Çpracy komponent√≥w
- ‚úÖ **Edge cases** - nietypowe scenariusze
- ‚úÖ **Error scenarios** - b≈Çƒôdne input/wyjƒÖtki
- ‚úÖ **Performance tests** - dla krytycznych ≈õcie≈ºek (je≈õli stosowne)
- ‚úÖ **Fixtures** - reusable test data, mocks, stubs

**4. Code Review Standards**

Przed commitem upewnij siƒô ≈ºe:
- ‚úÖ Kod przechodzi linting (ruff, pylint, mypy)
- ‚úÖ Wszystkie testy przechodzƒÖ
- ‚úÖ Coverage nie spad≈Ç
- ‚úÖ Dokumentacja jest aktualna
- ‚úÖ Brak TODO/FIXME w production code
- ‚úÖ Performance jest akceptowalne
- ‚úÖ Security best practices zachowane

---

## Architecture Patterns dla Sight

### Kontekst
Sight to platforma do wirtualnych grup fokusowych z AI:
- **Backend**: FastAPI + PostgreSQL (pgvector) + Redis + Neo4j
- **Frontend**: React 18 + TypeScript + TanStack Query
- **AI**: Google Gemini (Flash/Pro) via LangChain
- **Stack**: Async-first, event sourcing, hybrid search

### 1. Service Layer Pattern

**Filozofia:** Logika biznesowa oddzielona od endpoint√≥w API.

```
API Endpoints (app/api/*.py)
    ‚Üì (thin layer: validation, routing, error handling)
Service Layer (app/services/*_langchain.py)
    ‚Üì (thick layer: business logic, orchestration)
Models/DB (app/models/*.py) + External APIs
```

**Zasady:**
- Endpoints sƒÖ cienkie - tylko validation, response formatting, error handling
- Serwisy sƒÖ grube - ca≈Ça logika biznesowa, orchestration, external calls
- Jeden serwis = jedna odpowiedzialno≈õƒá (SRP)
- Serwisy sƒÖ async - u≈ºywajƒÖ `async/await` dla I/O
- Dependency injection - serwisy dostajƒÖ dependencies przez constructor

**Przyk≈Çad:**
```python
# ‚ùå Z≈ÅE - logika w endpoincie
@router.post("/personas/generate")
async def generate_personas(request: GenerateRequest):
    # 200 linii logiki tutaj...
    pass

# ‚úÖ DOBRE - endpoint cienki, serwis gruby
@router.post("/personas/generate")
async def generate_personas(
    request: GenerateRequest,
    service: PersonaGeneratorLangChain = Depends(get_persona_service)
):
    """Generate synthetic personas for project."""
    try:
        personas = await service.generate_personas(
            demographics=request.demographics,
            sample_size=request.sample_size
        )
        return {"personas": personas, "count": len(personas)}
    except ValidationError as e:
        raise HTTPException(status_code=422, detail=str(e))
```

### 2. Async/Await Patterns

Sight robi **du≈ºo I/O** (LLM, DB, Redis, Neo4j). Async jest krytyczny dla wydajno≈õci.

**Kiedy u≈ºywaƒá async:**
- ‚úÖ LLM API calls (Gemini)
- ‚úÖ Database queries (PostgreSQL, Neo4j)
- ‚úÖ Redis operations
- ‚úÖ HTTP requests (external APIs)
- ‚úÖ File I/O (PDF loading dla RAG)

**Kiedy NIE u≈ºywaƒá:**
- ‚ùå CPU-bound operations (numpy, chi-square test)
- ‚ùå Synchronous libraries (legacy code)

**Pattern: R√≥wnoleg≈Çe Przetwarzanie**
```python
# ‚úÖ DOBRE - r√≥wnoleg≈Çe generowanie odpowiedzi
async def run_focus_group(personas: List[Persona], questions: List[str]):
    """
    Performance: 20 person √ó 4 pytania = ~2-5 min (vs 40+ min sekwencyjnie)
    Target: <3s per persona, <30s total per question
    """
    for question in questions:
        tasks = [generate_response(persona, question) for persona in personas]
        responses = await asyncio.gather(*tasks, return_exceptions=True)

        # Handle exceptions per-persona (nie fail ca≈Çej grupy)
        for persona, response in zip(personas, responses):
            if isinstance(response, Exception):
                logger.error(f"Persona {persona.id} failed: {response}")
                continue
            await save_response(persona, question, response)
```

**Pattern: Timeouts**
```python
# ‚úÖ DOBRE - timeout per persona
async def generate_response_with_timeout(persona: Persona, question: str):
    """Timeout aby jedna wolna persona nie blokowa≈Ça grupy."""
    try:
        response = await asyncio.wait_for(
            llm.ainvoke(prompt),
            timeout=settings.MAX_RESPONSE_TIME_PER_PERSONA
        )
        return response
    except asyncio.TimeoutError:
        logger.warning(f"Persona {persona.id} timeout")
        raise
```

### 3. Event Sourcing Pattern

Sight u≈ºywa **event sourcing** dla pamiƒôci person:
- Ka≈ºda akcja/odpowied≈∫ = immutable `PersonaEvent`
- Eventy majƒÖ embeddingi dla semantic search
- Przy odpowiadaniu pobieramy kontekst via similarity search

**Dlaczego?**
- ‚úÖ Audyt trail - widzimy ca≈ÇƒÖ historiƒô
- ‚úÖ Time travel - odtworzenie stanu w dowolnym momencie
- ‚úÖ Semantic search - inteligentne wyszukiwanie kontekstu
- ‚úÖ Konsystencja - persona pamiƒôta poprzednie odpowiedzi

**Pattern:**
```python
# 1. Zapisz event z embeddingiem
async def save_persona_event(
    persona_id: UUID,
    event_type: str,
    content: str,
    embedding_service: GoogleGenerativeAIEmbeddings
):
    """Zapisuje event z embeddingiem dla semantic search."""
    embedding = await embedding_service.aembed_query(content)

    event = PersonaEvent(
        persona_id=persona_id,
        event_type=event_type,
        content=content,
        embedding=embedding,  # pgvector
        timestamp=datetime.utcnow()
    )
    await db.add(event)
    await db.commit()

# 2. Pobierz releantny kontekst
async def get_relevant_context(
    persona_id: UUID,
    current_question: str,
    top_k: int = 5
) -> List[str]:
    """Semantic search w historii persony."""
    query_embedding = await embedding_service.aembed_query(current_question)

    # Semantic search (pgvector <=> operator)
    results = await db.execute(
        select(PersonaEvent)
        .where(PersonaEvent.persona_id == persona_id)
        .order_by(PersonaEvent.embedding.cosine_distance(query_embedding))
        .limit(top_k)
    )

    return [event.content for event in results.scalars()]
```

### 4. GraphRAG Pattern (Hybrid Search)

Sight u≈ºywa **hybrid search** (vector + keyword) dla RAG:
- **Vector search**: semantic similarity (embeddings)
- **Keyword search**: lexical matching (fulltext index)
- **RRF fusion**: Reciprocal Rank Fusion ≈ÇƒÖczy wyniki

**Dlaczego hybrid?**
- ‚úÖ Vector - rozumie semantykƒô, synonimy
- ‚úÖ Keyword - precyzyjne dopasowanie exact matches
- ‚úÖ RRF - best of both worlds

**Pattern:**
```python
async def hybrid_search_rag(
    query: str,
    top_k: int = 5,
    vector_weight: float = 0.7
) -> List[Document]:
    """
    Hybrid search: vector + keyword + RRF fusion.
    Performance: ~100-200ms dla 1000 docs
    """
    # 1. Vector search
    query_embedding = await embeddings.aembed_query(query)
    vector_results = await neo4j_vector_index.similarity_search(
        query_embedding, k=top_k * 2
    )

    # 2. Keyword search
    keyword_results = await neo4j_fulltext_index.search(query, limit=top_k * 2)

    # 3. RRF Fusion
    fused_results = reciprocal_rank_fusion(
        [vector_results, keyword_results],
        k=settings.RAG_RRF_K,
        weights=[vector_weight, 1 - vector_weight]
    )

    return fused_results[:top_k]
```

### 5. Long-Running Operations Pattern

Sight ma d≈Çugie operacje (20 person = 30-60s, focus group = 2-5 min).

**Opcje:**
1. Sync blocking ‚ùå - user czeka, timeout
2. Async with polling ‚úÖ - background job + frontend polling
3. WebSockets ‚úÖ - real-time updates (TODO)

**Current Pattern:**
```python
# Backend: Background task z statusem
@router.post("/focus-groups/{id}/run")
async def run_focus_group(
    focus_group_id: UUID,
    background_tasks: BackgroundTasks
):
    """Frontend polluje status via GET /focus-groups/{id}/status"""
    await update_focus_group_status(focus_group_id, "running")
    background_tasks.add_task(run_focus_group_task, focus_group_id)
    return {"status": "started", "id": focus_group_id}

# Frontend: Polling z TanStack Query
const { data } = useQuery({
  queryKey: ['focus-group-status', id],
  queryFn: () => api.getFocusGroupStatus(id),
  refetchInterval: (data) =>
    data?.status === 'running' ? 2000 : false, // Poll co 2s
  staleTime: 0
})
```

### 6. Frontend State Management

**Stack:** React Query (TanStack Query) + Zustand

- ‚úÖ **Server state** (personas, focus groups) ‚Üí React Query
- ‚úÖ **UI state** (modals, filters) ‚Üí Zustand
- ‚úÖ **Form state** ‚Üí React Hook Form

**Dlaczego React Query?**
- Automatic caching (stale-while-revalidate)
- Background refetching
- Optimistic updates
- Request deduplication

```typescript
// ‚úÖ DOBRE - React Query dla server state
const usePersonas = (projectId: string) => {
  return useQuery({
    queryKey: ['personas', projectId],
    queryFn: () => api.getPersonas(projectId),
    staleTime: 5 * 60 * 1000, // 5 min cache
  })
}

// Mutation z optimistic update
const useGeneratePersonas = () => {
  const queryClient = useQueryClient()
  return useMutation({
    mutationFn: api.generatePersonas,
    onSuccess: (data, variables) => {
      queryClient.invalidateQueries(['personas', variables.projectId])
    }
  })
}
```

### 7. Error Handling Pattern

**Hierarchia b≈Çƒôd√≥w:**
```
Domain Exceptions (app/exceptions.py)
    ‚Üì
Service Layer (catch & transform)
    ‚Üì
API Layer (FastAPI exception handlers)
    ‚Üì
Frontend (error boundaries + toast notifications)
```

**Pattern:**
```python
# 1. Custom domain exceptions
class PersonaGenerationError(Exception):
    """Rzucany gdy generowanie person failuje."""
    pass

# 2. Service layer - rzuca domain exceptions
async def generate_personas(...):
    try:
        personas = await llm.generate(...)
    except LangChainError as e:
        raise PersonaGenerationError(f"Failed: {e}")

# 3. API layer - transform do HTTP
@router.post("/personas/generate")
async def generate_personas_endpoint(...):
    try:
        personas = await service.generate_personas(...)
        return {"personas": personas}
    except PersonaGenerationError as e:
        raise HTTPException(status_code=500, detail={
            "error": "generation_failed",
            "message": str(e),
            "retry": True
        })

# 4. Frontend - structured handling
if (error?.response?.data?.error === 'generation_failed') {
  toast.error(error.response.data.message, {
    action: { label: 'Retry', onClick: () => mutate(vars) }
  })
}
```

---

## Common Pitfalls & Solutions

### 1. N+1 Queries Problem

**Problem:** ≈Åadowanie person + responses = N+1 queries

```python
# ‚ùå Z≈ÅE - N+1 queries
personas = await db.execute(select(Persona).where(...))
for persona in personas:
    responses = await db.execute(
        select(PersonaResponse).where(PersonaResponse.persona_id == persona.id)
    )

# ‚úÖ DOBRE - 2 queries total
from sqlalchemy.orm import selectinload

personas = await db.execute(
    select(Persona)
    .where(...)
    .options(selectinload(Persona.responses))
)
```

### 2. LLM Token Limit Overflow

**Problem:** Gemini ma limit token√≥w. Context mo≈ºe byƒá za d≈Çugi.

**Solution:** Truncate context inteligentnie

```python
async def prepare_context_for_llm(
    persona: Persona,
    question: str,
    max_tokens: int = 6000
):
    """
    Priorytet:
    1. Current question (zawsze)
    2. Persona profile (zawsze)
    3. Recent events (newest first, truncate if needed)
    4. RAG context (most relevant)
    """
    def count_tokens(text: str) -> int:
        return len(text) // 4  # Approximation

    context_parts = []
    token_count = 0

    # Must-have parts
    context_parts.append(f"Question: {question}")
    token_count += count_tokens(question)

    context_parts.append(f"Profile: {persona.background_story}")
    token_count += count_tokens(persona.background_story)

    # Optional: recent events (truncate if needed)
    events = await get_recent_events(persona.id, limit=10)
    for event in events:
        event_tokens = count_tokens(event.content)
        if token_count + event_tokens > max_tokens:
            break
        context_parts.append(event.content)
        token_count += event_tokens

    return "\n\n".join(context_parts)
```

### 3. Memory Leaks w Async Code

**Problem:** Nie cancelled tasks mogƒÖ leakowaƒá memory.

**Solution:** Proper cleanup z `asyncio.TaskGroup`

```python
# ‚úÖ DOBRE - automatic cleanup je≈õli jeden task failuje
async def run_focus_group_safe(personas: List[Persona], question: str):
    """TaskGroup canceluje pozosta≈Çe tasks je≈õli jeden failuje."""
    async with asyncio.TaskGroup() as tg:
        tasks = [
            tg.create_task(generate_response(persona, question))
            for persona in personas
        ]
    return [task.result() for task in tasks]
```

### 4. Race Conditions w Event Sourcing

**Problem:** Dwa r√≥wnoleg≈Çe requesty zapisujƒÖ eventy = race condition.

**Solution:** Redis lock

```python
from redis import asyncio as aioredis

async def save_event_with_lock(persona_id: UUID, event: PersonaEvent):
    """Redis lock zapobiega race conditions."""
    lock_key = f"persona_lock:{persona_id}"

    async with aioredis.from_url(settings.REDIS_URL) as redis:
        lock = redis.lock(lock_key, timeout=5)
        async with lock:
            await db.add(event)
            await db.commit()
```

### 5. Neo4j Connection Pool Exhaustion

**Problem:** Du≈ºo r√≥wnoleg≈Çych queries = pool exhaustion.

**Solution:** Connection pooling + retry logic

```python
from neo4j import AsyncGraphDatabase

class Neo4jService:
    def __init__(self):
        self._driver = None

    async def get_driver(self):
        if self._driver is None:
            self._driver = AsyncGraphDatabase.driver(
                settings.NEO4J_URI,
                auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD),
                max_connection_pool_size=50,
                connection_timeout=5.0
            )
        return self._driver

    async def close(self):
        if self._driver:
            await self._driver.close()
```

### 6. Frontend: Stale Data po Mutation

**Problem:** User generuje persony, lista nie refreshuje siƒô.

**Solution:** Invalidate queries

```typescript
const useGeneratePersonas = () => {
  const queryClient = useQueryClient()
  return useMutation({
    mutationFn: api.generatePersonas,
    onSuccess: (data, variables) => {
      queryClient.invalidateQueries({
        queryKey: ['personas', variables.projectId]
      })
    }
  })
}
```

### 7. Chi-Square Test Fails dla Ma≈Çych Pr√≥bek

**Problem:** Chi-square nie jest reliable dla n < 10.

**Solution:** Fallback + warning

```python
def validate_demographics(
    personas: List[Persona],
    target_demographics: Dict,
    sample_size: int
):
    if sample_size < 10:
        logger.warning("Sample size too small for chi-square. Using percentage match.")
        return validate_percentage_match(personas, target_demographics, tolerance=0.1)

    chi_square, p_value = calculate_chi_square(personas, target_demographics)
    if p_value < 0.05:
        raise StatisticalValidationError(f"Demographics don't match (p={p_value:.4f})")
    return True
```

---

## Production Checklist

### Pre-Deploy

**Backend:**
- [ ] Wszystkie testy przechodzƒÖ (208 tests)
- [ ] Coverage >80% dla critical paths
- [ ] Migrations up-to-date (`alembic upgrade head`)
- [ ] Neo4j indexes utworzone (`python scripts/init_neo4j_indexes.py`)
- [ ] Secrets w env vars (nie w .env!)
- [ ] CORS tylko dla prod domains
- [ ] Rate limiting w≈ÇƒÖczony
- [ ] Logging level = INFO
- [ ] Health check dzia≈Ça (`/health`)
- [ ] Connection pooling skonfigurowany
- [ ] LLM rate limits monitorowane

**Frontend:**
- [ ] Build dzia≈Ça (`npm run build`)
- [ ] No console.errors w prod
- [ ] Env vars skonfigurowane
- [ ] Error boundaries na miejscu
- [ ] Loading states dla long ops
- [ ] Toast notifications dla errors

**Infrastructure:**
- [ ] PostgreSQL backups skonfigurowane
- [ ] Redis persistence w≈ÇƒÖczona (AOF/RDB)
- [ ] Neo4j backups skonfigurowane
- [ ] SSL/TLS dla wszystkich po≈ÇƒÖcze≈Ñ
- [ ] Firewall rules ustawione
- [ ] Monitoring/alerting skonfigurowany

**Security:**
- [ ] JWT secret zmieniony
- [ ] Database passwords zmienione
- [ ] CORS tylko trusted domains
- [ ] Rate limiting per IP + user
- [ ] OWASP Top 10 checked

**Performance:**
- [ ] Database indexes utworzone
- [ ] N+1 queries fixed
- [ ] Caching skonfigurowany
- [ ] Async/await wszƒôdzie dla I/O
- [ ] Connection pooling dla external services

### Post-Deploy Verification

**Smoke tests:**
- [ ] Login dzia≈Ça
- [ ] Tworzenie projektu dzia≈Ça
- [ ] Generowanie person dzia≈Ça (test 1-2)
- [ ] Mini focus group dzia≈Ça (2 persony, 1 pytanie)
- [ ] Graph analysis dzia≈Ça
- [ ] RAG search dzia≈Ça

**Performance checks:**
- [ ] API response <500ms dla GET
- [ ] Persona generation <5s per persona
- [ ] Focus group <30s per question (20 personas)
- [ ] DB query time <100ms

**Monitoring:**
- [ ] Error rate <1%
- [ ] CPU usage <70%
- [ ] Memory stable (no leaks)
- [ ] DB connections <80% pool
- [ ] LLM calls within quota
