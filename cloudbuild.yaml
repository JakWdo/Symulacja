# ==============================================================================
# cloudbuild.yaml - Optimized CI/CD Pipeline
# ==============================================================================
# Pipeline stages:
# 1. BUILD: Docker image (frontend + backend) with layer caching
# 2. PUSH: Push to Artifact Registry
# 3. MIGRATE: Database migrations (before deploy)
# 4. DEPLOY: Cloud Run service
# 5. NEO4J INIT: Initialize vector indexes
# 6. SMOKE TESTS: Post-deployment verification (health + frontend)
#
# Total time: ~8-12 min (with BuildKit inline cache + pinned base images)
#   - First build (cold cache): ~20-25 min
#   - Incremental builds (warm cache): ~8-12 min
#   - Code-only changes (hot cache): ~5-8 min
# Optimization: BuildKit inline cache + pinned node:20.18.0/python:3.11.11
# Code quality checks: Run locally (ruff, mypy, pytest)
# ==============================================================================

steps:
  # ==========================================================================
  # PULL CACHE: Download previous image for layer caching
  # ==========================================================================
  # This step pulls the latest image from Artifact Registry to use as cache source
  # Uses 'entrypoint: bash' with '|| true' to avoid failing on first build (no cache exists yet)
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        docker pull europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest || echo "No cache image found - first build will be slow"
    id: 'pull-cache'
    waitFor: ['-']  # Start immediately (parallel with tests if any)

  # ==========================================================================
  # BUILD: Docker Image (Backend + Frontend) with BuildKit Inline Cache
  # ==========================================================================
  # BuildKit inline cache: zapisuje cache metadata WEWNƒÑTRZ image
  # To umo≈ºliwia cache multi-stage builds (frontend-builder, backend-builder, runtime)
  # --cache-from: reuse cache z poprzednich build√≥w
  # --cache-to type=inline: zapisz cache metadata dla przysz≈Çych build√≥w
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Setup BuildKit (nowszy backend Docker z lepszym cachingiem)
        export DOCKER_BUILDKIT=1

        # Build z inline cache (zapisuje cache metadata w image layers)
        docker build \
          -f Dockerfile.cloudrun \
          --cache-from europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
          --build-arg BUILDKIT_INLINE_CACHE=1 \
          -t europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
          -t europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:$COMMIT_SHA \
          .
    id: 'build'
    waitFor: ['pull-cache']  # Wait for cache image to be pulled
    env:
      - 'DOCKER_BUILDKIT=1'

  # ==========================================================================
  # PUSH: Docker Image to Artifact Registry
  # ==========================================================================
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - 'europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight'
    id: 'push'
    waitFor: ['build']

  # ==========================================================================
  # MIGRATE: Database Migrations (BEFORE deploy)
  # ==========================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Run database migrations via Cloud Run Jobs
        # This ensures schema is up-to-date BEFORE deploying new code
        echo "üîÑ Running database migrations..."

        # Check if migration job exists, create if not
        if ! gcloud run jobs describe db-migrate --region=europe-central2 2>/dev/null; then
          echo "Creating migration job..."
          gcloud run jobs create db-migrate \
            --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
            --region=europe-central2 \
            --add-cloudsql-instances=gen-lang-client-0508446677:europe-central2:sight \
            --set-secrets=DATABASE_URL=DATABASE_URL_CLOUD:latest \
            --set-env-vars=PYTHONUNBUFFERED=1,PYTHONPATH=/app \
            --command=bash \
            --args=scripts/run_migrations_cloudrun.sh \
            --max-retries=2 \
            --task-timeout=300
        else
          echo "Updating migration job image..."
          gcloud run jobs update db-migrate \
            --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
            --region=europe-central2 \
            --set-env-vars=PYTHONUNBUFFERED=1,PYTHONPATH=/app
        fi

        # Execute migrations
        echo "Executing migrations..."
        gcloud run jobs execute db-migrate --region=europe-central2 --wait

        # Check migration status
        if [ $$? -eq 0 ]; then
          echo "‚úÖ Migrations completed successfully"
        else
          echo "‚ùå Migrations failed - aborting deployment"
          exit 1
        fi
    id: 'migrate'
    waitFor: ['push']

  # ==========================================================================
  # DEPLOY: Cloud Run Service (sight)
  # ==========================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'sight'
      - '--image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest'
      - '--region=europe-central2'
      - '--platform=managed'
      - '--allow-unauthenticated'
      - '--port=8080'
      - '--memory=4Gi'  # Zwiƒôkszone z 2Gi ‚Üí 4Gi (persona gen + RAG + sentence-transformers ~2.5Gi peak)
      - '--cpu=2'  # Zwiƒôkszone do 2 vCPU dla lepszej performance (LLM + RAG)
      - '--cpu-boost'  # Startup CPU boost dla szybszego startu
      - '--timeout=300'
      - '--min-instances=0'
      - '--max-instances=5'
      - '--execution-environment=gen2'  # Gen2 runtime (nowszy, szybszy)
      - '--add-cloudsql-instances=gen-lang-client-0508446677:europe-central2:sight'
      - '--set-secrets=DATABASE_URL=DATABASE_URL_CLOUD:latest,GOOGLE_API_KEY=GOOGLE_API_KEY:latest,NEO4J_PASSWORD=NEO4J_PASSWORD:latest,NEO4J_URI=NEO4J_URI:latest,POSTGRES_PASSWORD=POSTGRES_PASSWORD:latest,REDIS_URL=REDIS_URL:latest,SECRET_KEY=SECRET_KEY:latest'
      # ALLOWED_ORIGINS removed - not needed for same-origin deployment (backend + frontend in same container)
      # See app/main.py:114-135 for explanation
      # EMBEDDING_MODEL: CRITICAL - must have "models/" prefix for LangChain Google AI integration
      # Models configuration - can be changed via GCP UI without redeploy
      # ORCHESTRATION_ENABLED: Re-enabled after Graph RAG optimizations (Redis caching + connection pooling)
      # HuggingFace optimization (2025-10-28): Reduce logging noise + disable telemetry
      # WORKFLOWS_ENABLED: Enable Workflow Builder feature (2025-11-05)
      # GCP_PROJECT_ID, GCP_REGION: Required for Cloud Tasks integration
      - '--set-env-vars=NEO4J_USER=neo4j,ENVIRONMENT=production,DEBUG=False,DEFAULT_LLM_PROVIDER=google,DEFAULT_MODEL=gemini-2.5-flash,GRAPH_MODEL=gemini-2.5-flash,PERSONA_GENERATION_MODEL=gemini-2.5-flash,ANALYSIS_MODEL=gemini-2.5-pro,EMBEDDING_MODEL=models/gemini-embedding-001,TEMPERATURE=0.7,MAX_TOKENS=6000,RAG_ENABLED=True,RAG_USE_HYBRID_SEARCH=True,RAG_USE_RERANKING=False,RAG_RERANK_CANDIDATES=5,RETRIEVAL_MODE=hybrid,RAG_CHUNK_SIZE=1000,RAG_CHUNK_OVERLAP=300,RAG_TOP_K=8,RAG_VECTOR_WEIGHT=0.7,RAG_RRF_K=60,ORCHESTRATION_ENABLED=True,ORCHESTRATION_TIMEOUT=90,TRANSFORMERS_VERBOSITY=error,HF_HUB_DISABLE_TELEMETRY=1,WORKFLOWS_ENABLED=true,GCP_PROJECT_ID=gen-lang-client-0508446677,GCP_REGION=europe-central2'
    id: 'deploy'
    waitFor: ['migrate']

  # ==========================================================================
  # NEO4J INIT: Initialize Neo4j Indexes (AFTER deploy)
  # ==========================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Initialize Neo4j indexes via Cloud Run Jobs
        # This ensures vector indexes exist for RAG system
        echo "üîÑ Initializing Neo4j indexes..."

        # Check if neo4j-init job exists, create if not
        if ! gcloud run jobs describe neo4j-init --region=europe-central2 2>/dev/null; then
          echo "Creating Neo4j init job..."
          gcloud run jobs create neo4j-init \
            --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
            --region=europe-central2 \
            --set-secrets=NEO4J_URI=NEO4J_URI:latest,NEO4J_PASSWORD=NEO4J_PASSWORD:latest \
            --set-env-vars=NEO4J_USER=neo4j \
            --command=python,scripts/init_neo4j_cloudrun.py \
            --max-retries=3 \
            --task-timeout=300
        else
          echo "Updating Neo4j init job image..."
          gcloud run jobs update neo4j-init \
            --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
            --region=europe-central2
        fi

        # Execute Neo4j initialization
        echo "Executing Neo4j index initialization..."
        gcloud run jobs execute neo4j-init --region=europe-central2 --wait

        # Check initialization status (non-fatal - RAG services have retry logic)
        if [ $$? -eq 0 ]; then
          echo "‚úÖ Neo4j indexes initialized successfully"
        else
          echo "‚ö†Ô∏è  Neo4j init failed - RAG features may be limited"
          echo "   Check logs: gcloud run jobs executions logs [EXECUTION_ID]"
          echo "   App will continue to run, but RAG functionality may be unavailable"
        fi
    id: 'neo4j-init'
    waitFor: ['deploy']

  # ==========================================================================
  # SMOKE TESTS: Post-deployment verification with retry logic
  # ==========================================================================
  # Rationale: Cloud Run services need time to initialize (RAG, Neo4j, Redis)
  # Retry logic prevents false failures from slow startups
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
    id: 'smoke-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "üî• Running smoke tests on deployed service..."

        # Get deployed service URL
        SERVICE_URL=$(gcloud run services describe sight --region=europe-central2 --format="value(status.url)")
        echo "Testing deployment at: $$SERVICE_URL"

        # Initial wait for service to start (give it time to initialize)
        echo "‚è≥ Waiting 15s for service initialization..."
        sleep 15

        # Test 1: Health endpoint (backend API) with retry
        echo ""
        echo "Test 1/2: Health check (with retry logic)..."
        HEALTH_PASSED=false
        for i in 1 2 3; do
          echo "  Attempt $$i/3..."
          HEALTH_STATUS=$(curl -f -s -o /dev/null -w "%{http_code}" --connect-timeout 10 --max-time 30 "$$SERVICE_URL/health" || echo "FAIL")

          if [ "$$HEALTH_STATUS" = "200" ]; then
            echo "‚úÖ Backend healthy (HTTP 200)"
            HEALTH_PASSED=true
            break
          else
            echo "‚ö†Ô∏è  Health check returned: $$HEALTH_STATUS"
            if [ $$i -lt 3 ]; then
              echo "  Retrying in 10s..."
              sleep 10
            fi
          fi
        done

        if [ "$$HEALTH_PASSED" != "true" ]; then
          echo ""
          echo "‚ùå Health check FAILED after 3 attempts"
          echo "   Last status: $$HEALTH_STATUS"
          echo "   This may indicate:"
          echo "   - Service crashed during startup"
          echo "   - Database connection issues"
          echo "   - Initialization timeout (check logs)"
          echo ""
          echo "   Debug commands:"
          echo "   gcloud run services logs read sight --region=europe-central2 --limit=50"
          echo "   gcloud logging read 'resource.type=cloud_run_revision AND severity>=ERROR' --limit=20"
          exit 1
        fi

        # Test 2: Frontend (React SPA) with retry
        echo ""
        echo "Test 2/2: Frontend application (with retry logic)..."
        FRONTEND_PASSED=false
        for i in 1 2 3; do
          echo "  Attempt $$i/3..."
          FRONTEND_STATUS=$(curl -f -s -o /dev/null -w "%{http_code}" --connect-timeout 10 --max-time 30 "$$SERVICE_URL/" || echo "FAIL")

          if [ "$$FRONTEND_STATUS" = "200" ]; then
            echo "‚úÖ Frontend accessible (HTTP 200)"
            FRONTEND_PASSED=true
            break
          else
            echo "‚ö†Ô∏è  Frontend check returned: $$FRONTEND_STATUS"
            if [ $$i -lt 3 ]; then
              echo "  Retrying in 10s..."
              sleep 10
            fi
          fi
        done

        if [ "$$FRONTEND_PASSED" != "true" ]; then
          echo ""
          echo "‚ùå Frontend check FAILED after 3 attempts"
          echo "   Last status: $$FRONTEND_STATUS"
          echo "   This may indicate:"
          echo "   - Static file serving issues"
          echo "   - Frontend build problems"
          echo "   - Routing configuration errors"
          exit 1
        fi

        # All tests passed
        echo ""
        echo "üéâ Smoke tests PASSED!"
        echo "   ‚úÖ Backend API healthy"
        echo "   ‚úÖ Frontend accessible"
        echo "   üìç Service URL: $$SERVICE_URL"
        echo ""
        echo "Deployment verified and ready for production traffic!"
    waitFor: ['neo4j-init']

  # ==========================================================================
  # ROLLBACK: Automatic rollback if smoke tests failed
  # ==========================================================================
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:slim'
    id: 'rollback-on-failure'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # This step only runs if previous step (smoke-tests) failed
        # Note: Cloud Build doesn't have native "on_failure" hooks, so we use a workaround:
        # If smoke tests passed, this step does nothing (exit 0)
        # If smoke tests failed, build already stopped (exit 1)
        #
        # For now, manual rollback is needed if deployment is broken
        # Future: Implement blue/green deployment with traffic splitting
        echo "‚ö†Ô∏è  Smoke tests failed - manual rollback may be needed"
        echo "   To rollback: gcloud run services update-traffic sight --to-revisions=PREVIOUS=100"
        exit 0
    waitFor: ['-']  # Run independently (manual trigger only)

# Output images
images:
  - 'europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest'

# Build options
options:
  machineType: 'E2_HIGHCPU_8'  # Fast build (frontend + backend multi-stage)
  logging: CLOUD_LOGGING_ONLY

timeout: '3600s'
