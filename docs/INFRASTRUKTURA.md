# Infrastruktura i Deployment - Sight Platform

**Ostatnia aktualizacja:** 2025-11-12
**Wersja:** 2.2
**Status:** Production-ready (+ Staging + Health Checks + Automatic Rollback)

---

## Spis Tre≈õci

1. [PrzeglƒÖd Infrastruktury](#przeglƒÖd-infrastruktury)
2. [Architektura Docker](#architektura-docker)
3. [Local Development](#local-development)
4. [Cloud Run Production](#cloud-run-production)
5. [CI/CD Pipeline](#cicd-pipeline)
6. [Staging Environment](#staging-environment)
7. [Health Checks & Automatic Rollback](#health-checks--automatic-rollback)
8. [External Services](#external-services)
9. [Monitoring & Observability](#monitoring--observability)

---

## PrzeglƒÖd Infrastruktury

Platforma Sight zosta≈Ça zaprojektowana z my≈õlƒÖ o nowoczesnej architekturze kontenerowej, kt√≥ra zapewnia sp√≥jno≈õƒá miƒôdzy ≈õrodowiskiem deweloperskim a produkcyjnym. System opiera siƒô na piƒôciu kluczowych serwisach uruchamianych w kontenerach Docker: PostgreSQL z rozszerzeniem pgvector dla wektorowych operacji AI, Redis jako warstwa cache'owania i zarzƒÖdzania sesjami, Neo4j z pluginami APOC i Graph Data Science dla zaawansowanych analiz grafowych, backend FastAPI z asynchronicznym przetwarzaniem oraz frontend React z TypeScript.

Nasza infrastruktura przesz≈Ça przez znaczƒÖce optymalizacje w ostatnich miesiƒÖcach. Uda≈Ço siƒô zmniejszyƒá rozmiar obraz√≥w Docker o 84% (z 55GB do 11GB), zredukowaƒá czas budowania o 67%, oraz naprawiƒá 54 CVE zwiƒÖzanych z bezpiecze≈Ñstwem. Deployment zosta≈Ç w pe≈Çni zautomatyzowany - od push do GitHub do dzia≈ÇajƒÖcej aplikacji w Cloud Run zajmuje obecnie 8-12 minut, z automatycznymi migracjami bazy danych i inicjalizacjƒÖ indeks√≥w Neo4j.

### Kluczowe Cele Architektury

Infrastruktura Sight realizuje cztery nadrzƒôdne cele. Pierwszym z nich jest **consistency across environments** - kod kt√≥ry dzia≈Ça lokalnie musi dzia≈Çaƒá identycznie w produkcji. Dlatego u≈ºywamy tych samych obraz√≥w Docker, tych samych wersji dependencies i tej samej konfiguracji sieciowej zar√≥wno na maszynach deweloperskich jak i w Cloud Run. Drugi cel to **developer experience** - deweloper powinien m√≥c uruchomiƒá pe≈Çny stack jednƒÖ komendƒÖ (`docker-compose up -d`) i natychmiast zaczƒÖƒá kodowaƒá z hot reload. Trzeci cel to **cost optimization** - Cloud Run scale-uje do zera instancji gdy nie ma ruchu, Redis cache redukuje wywo≈Çania LLM o 80%, a aggressive Docker layer caching oszczƒôdza czas i pieniƒÖdze w CI/CD. Czwarty cel to **observability** - ka≈ºda operacja jest logowana ze structured fields, metryki wydajno≈õciowe sƒÖ ≈õledzone w real-time, a alerts informujƒÖ zesp√≥≈Ç o anomaliach zanim wp≈ÇynƒÖ na u≈ºytkownik√≥w ko≈Ñcowych.

### Stack Technologiczny

**Backend Infrastructure:**
- FastAPI 0.110+ (async Python web framework)
- SQLAlchemy 2.0 (async ORM z connection pooling)
- PostgreSQL 15 z pgvector (wektorowa baza danych)
- Redis 7 (cache, rate limiting, distributed locking)
- Neo4j 5.x (grafowa baza wiedzy dla RAG)
- Uvicorn (ASGI server z multiple workers)

**Frontend Infrastructure:**
- React 18 + TypeScript (komponentowa architektura)
- Vite 5.x (ultra-fast dev server + build tool)
- TanStack Query (server state management z automatic caching)
- Zustand (lightweight UI state management)
- Nginx (static file serving w produkcji)

**Deployment Infrastructure:**
- Docker Compose (local development orchestration)
- Google Cloud Run (serverless container platform)
- Google Artifact Registry (Docker image storage)
- Google Cloud Build (CI/CD automation)
- Google Secret Manager (secure credentials storage)
- Google Cloud SQL (managed PostgreSQL w produkcji)

**External Services (Production):**
- Neo4j AuraDB Free (50,000 nodes, Europe West 1)
- Upstash Redis Free (10,000 requests/day, Europe West 1)
- Google Gemini API (LLM provider - Flash i Pro modele)

---

## Architektura Docker

### Multi-Stage Builds

Ka≈ºdy serwis wykorzystuje wieloetapowe buildy Docker, kt√≥re drastycznie redukujƒÖ rozmiar finalnych obraz√≥w. Backend FastAPI przechodzi przez trzy etapy: builder (instalacja dependencies z pip wheel compilation), runtime (kopiowanie aplikacji i config files), oraz production (minimalistyczny obraz z tylko niezbƒôdnymi zale≈ºno≈õciami). Frontend React r√≥wnie≈º korzysta z czterech etap√≥w: deps (node_modules installation), builder (Vite build do /dist), dev (serwer deweloperski z hot reload), oraz prod (statyczny Nginx serwujƒÖcy zbudowane pliki).

**Dockerfile.cloudrun - Production Image:**

Produkcyjny Dockerfile ≈ÇƒÖczy frontend i backend w jeden obraz, co upraszcza deployment i eliminuje CORS issues. Pierwszy stage builduje frontend React u≈ºywajƒÖc Vite - wszystkie statyczne assety trafiajƒÖ do `/dist` folderu z hash suffixes dla cache busting. Drugi stage instaluje Python dependencies u≈ºywajƒÖc pip z wheel compilation dla native extensions (numpy, scipy dla embeddings). Trzeci stage kopiuje zbudowany frontend do `/app/static`, instaluje backend Python code, i konfiguruje uvicorn jako entry point. Finalny obraz wa≈ºy oko≈Ço 2.8GB (poprzednio 5.5GB przed optymalizacjami), co przek≈Çada siƒô na szybsze deploymenty i ni≈ºsze koszty network egress.

**Docker Compose - Local Development:**

Konfiguracja `docker-compose.yml` definiuje siedem serwis√≥w (postgres, redis, neo4j, migrate, neo4j-init, api, frontend) z precyzyjnie skonfigurowanymi health checks i dependency chains. Health checks zapewniajƒÖ ≈ºe serwisy startujƒÖ w poprawnej kolejno≈õci - PostgreSQL musi byƒá healthy zanim migrate uruchomi alembic, a Neo4j musi byƒá healthy zanim neo4j-init utworzy indeksy. Wszystkie serwisy sƒÖ po≈ÇƒÖczone do jednej sieci `backend` dla internal communication, co pozwala im komunikowaƒá siƒô po nazwach host√≥w (np. `postgres:5432`, `redis:6379`) zamiast IP addresses.

### Resource Limits

Ka≈ºdy serwis ma zdefiniowane limity CPU i RAM zar√≥wno dla ≈õrodowiska deweloperskiego jak i produkcyjnego. Backend API w development wykorzystuje 1 CPU core i 512MB RAM, podczas gdy w produkcji otrzymuje 2 CPU cores i 1.5GB RAM dla lepszej wydajno≈õci przy obs≈Çudze r√≥wnoleg≈Çych wywo≈Ça≈Ñ LLM. Frontend w development jest ograniczony do 0.5 CPU i 256MB, co wystarcza dla hot reload, natomiast w produkcji (Nginx) potrzebuje 1 CPU i 512MB.

PostgreSQL z pgvector alokuje 1 CPU i 1GB RAM w development, ale w produkcji skaluje siƒô do 2 CPU i 4GB dla obs≈Çugi embeddings i wektorowych zapyta≈Ñ. Redis, bƒôdƒÖcy in-memory database, otrzymuje 256MB w dev i 1GB w prod. Neo4j, najbardziej resource-hungry serwis, wymaga 2GB w development i a≈º 8GB w produkcji dla przetwarzania z≈Ço≈ºonych graf√≥w i Graph Data Science algorithms.

**docker-compose.yml - Resource Configuration:**

```yaml
services:
  api:
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  neo4j:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1G
```

Reservations okre≈õlajƒÖ minimalny guaranteed resource allocation, podczas gdy limits definiujƒÖ maksymalny burst capacity. To pozwala na elastyczne zarzƒÖdzanie resources - serwisy mogƒÖ burst powy≈ºej reservations gdy host ma wolne zasoby, ale nigdy nie przekroczƒÖ limits.

### Volume Management

Docker volumes zapewniajƒÖ persistence dla danych miƒôdzy restartami kontener√≥w. Mamy piƒôƒá named volumes: `postgres_data` dla bazy danych, `redis_data` dla Redis persistence (AOF enabled), `neo4j_data` i `neo4j_logs` dla Neo4j, oraz `frontend_node_modules` aby uniknƒÖƒá reinstalacji node_modules przy ka≈ºdym rebuild kontenera frontend.

Named volumes sƒÖ zarzƒÖdzane przez Docker daemon i przetrwajƒÖ `docker-compose down`. Aby ca≈Çkowicie wyczy≈õciƒá ≈õrodowisko (fresh start), trzeba u≈ºyƒá `docker-compose down -v` kt√≥ry usuwa volumes, lub manualnie `docker volume rm sight_postgres_data`. Bind mounts (`./:/app` dla hot reload) montujƒÖ lokalne foldery bezpo≈õrednio do kontenera, co pozwala na natychmiastowe odbicie zmian w kodzie bez rebuildu.

### Networking

Wszystkie serwisy sƒÖ po≈ÇƒÖczone do custom network `backend` (bridge driver). To zapewnia izolacjƒô od innych Docker containers na ho≈õcie oraz pozwala na automatic DNS resolution - ka≈ºdy serwis jest dostƒôpny po nazwie (np. `postgres`, `redis`, `neo4j`) z automatycznym load balancing je≈õli skalujemy replicas. Port publishing (`ports: - "8000:8000"`) eksponuje serwisy na ho≈õcie dla dostƒôpu z lokalnej maszyny, ale internal communication u≈ºywa Docker network bez port mappings.

---

## Local Development

### Quick Start

Uruchomienie pe≈Çnego ≈õrodowiska deweloperskiego wymaga jedynie Docker Compose. Pierwsze co trzeba zrobiƒá to skonfigurowaƒá zmienne ≈õrodowiskowe. Kopiujemy `.env.example` do `.env` i wype≈Çniamy wymagane warto≈õci: `GOOGLE_API_KEY` (Gemini API key z Google AI Studio), `SECRET_KEY` (32-char random hex wygenerowany przez `openssl rand -hex 32`), oraz credentials do PostgreSQL, Redis i Neo4j (defaults w docker-compose sƒÖ OK dla developmentu, ale production wymaga silniejszych hase≈Ç).

**Komendy startowe:**

```bash
# 1. Konfiguracja ≈õrodowiska
cp .env.example .env
# Edytuj .env - ustaw GOOGLE_API_KEY i SECRET_KEY

# 2. Uruchom wszystkie serwisy
docker-compose up -d

# 3. Sprawd≈∫ logi startup (opcjonalnie)
docker-compose logs -f

# 4. Weryfikuj ≈ºe wszystko dzia≈Ça
curl http://localhost:8000/health
# {"status": "healthy", "postgres": "connected", "redis": "connected", "neo4j": "connected"}
```

Po pierwszym uruchomieniu migrate i neo4j-init service'y wykonajƒÖ siƒô automatycznie dziƒôki dependency chain w docker-compose. Migrate uruchamia `alembic upgrade head` aby zastosowaƒá wszystkie migracje bazy danych. Neo4j-init uruchamia `scripts/init_neo4j_indexes.py` kt√≥ry tworzy trzy kluczowe indeksy: `document_id_idx` (B-tree na Document.id), `chunk_embedding_idx` (property index na Chunk.embedding), oraz `chunk_vector_idx` (vector index z 768 wymiarami dla Gemini embeddings). Te indeksy sƒÖ wymagane dla systemu RAG - bez nich hybrid search failuje z `VectorIndexNotFoundError`.

### Dostƒôpne Endpointy

Aplikacja po starcie jest dostƒôpna pod kilkoma endpointami. Backend API odpowiada na `http://localhost:8000`, z interaktywnƒÖ dokumentacjƒÖ Swagger UI pod `/docs` i ReDoc pod `/redoc`. Frontend dev server dzia≈Ça na `http://localhost:5173` z hot reload - ka≈ºda zmiana w plikach `.tsx` lub `.ts` automatycznie rebuilds i refreshuje przeglƒÖdarkƒô. Neo4j Browser, u≈ºyteczny do debugowania graf√≥w, znajduje siƒô pod `http://localhost:7474` (credentials: neo4j/dev_password_change_in_prod). PostgreSQL nas≈Çuchuje na porcie 5433 (nie standardowy 5432, aby uniknƒÖƒá konflikt√≥w z lokalnymi instalacjami), a Redis na standardowym 6379.

**Przydatne endpointy API:**

- `GET /health` - Health check all dependencies
- `GET /startup` - Detailed startup probe (z latencjami DB connections)
- `GET /docs` - Swagger UI (interactive API docs)
- `GET /metrics` - Prometheus metrics (opcjonalny, wymaga w≈ÇƒÖczenia)
- `POST /api/v1/projects/{id}/personas/generate` - Generuj 20 person
- `POST /api/v1/focus-groups` - Utw√≥rz grupƒô fokusowƒÖ

### Hot Reload i Rebuilds

System jest zoptymalizowany dla developer experience. Zmiany w kodzie Python (backend) lub TypeScript/React (frontend) sƒÖ natychmiast widoczne dziƒôki volume mounts i hot reload - nie wymaga to rebuildu kontener√≥w. Backend u≈ºywa uvicorn z flagƒÖ `--reload` kt√≥ra ≈õledzi zmiany w `app/` i automatycznie restartuje worker processes. Frontend u≈ºywa Vite dev server z ultra-fast HMR (Hot Module Replacement) kt√≥ry preserves application state podczas reload.

Jedynie zmiany w `requirements.txt` lub `package.json` wymagajƒÖ przebudowania odpowiedniego serwisu. Dla backendu: `docker-compose up --build -d api`, dla frontendu: `docker-compose up --build -d frontend`. Rebuild zajmuje oko≈Ço 30-60 sekund dziƒôki Docker layer caching - tylko zmienione layers sƒÖ rebuilowane, reszta jest reused z cache.

**Migracje bazy danych:**

Po zmianach w modelach ORM (`app/models/`) trzeba wygenerowaƒá i zastosowaƒá migracjƒô Alembic. Proces jest p√≥≈Çautomatyczny - Alembic wykrywa zmiany w SQLAlchemy models i generuje odpowiednie DDL SQL, ale nale≈ºy zawsze przejrzeƒá wygenerowanƒÖ migracjƒô przed zastosowaniem.

```bash
# 1. Auto-generuj migracjƒô ze zmian w modelach
docker-compose exec api alembic revision --autogenerate -m "Add kpi_snapshot field to personas"

# 2. Przejrzyj wygenerowanƒÖ migracjƒô
cat alembic/versions/XXXX_add_kpi_snapshot_field_to_personas.py

# 3. Zastosuj migracjƒô
docker-compose exec api alembic upgrade head

# 4. Weryfikuj schema
docker-compose exec postgres psql -U sight -d sight_db -c "\d personas"
```

**WA≈ªNE:** Alembic mo≈ºe pominƒÖƒá niekt√≥re zmiany - szczeg√≥lnie indeksy, custom SQL operations, data migrations. Zawsze reviewuj wygenerowanƒÖ migracjƒô i dodaj brakujƒÖce operacje manualnie.

### Debugging

Gdy co≈õ nie dzia≈Ça, kluczowe sƒÖ logi. Komenda `docker-compose logs -f api` streamuje logi backendu w real-time, co pozwala ≈õledziƒá requesty HTTP, b≈Çƒôdy Python, oraz wywo≈Çania LLM. Dla frontendu analogicznie `docker-compose logs -f frontend` pokazuje output Vite dev server. Dla wszystkich serwis√≥w jednocze≈õnie: `docker-compose logs -f` (mo≈ºe byƒá overwhelming).

**Filtrowanie log√≥w:**

```bash
# Tylko b≈Çƒôdy (ERROR level)
docker-compose logs api | grep ERROR

# Ostatnie 100 linii
docker-compose logs --tail=100 api

# Konkretny timestamp range (wymaga jq)
docker-compose logs --timestamps api | grep "2025-11-03"

# Follow logs z konkretnego serwisu
docker-compose logs -f postgres redis neo4j
```

W przypadku powa≈ºniejszych problem√≥w mo≈ºna wej≈õƒá do wnƒôtrza kontenera przez `docker exec -it sight_api bash`. Pozwala to na inspekcjƒô plik√≥w, uruchomienie shell Python (`python -c "from app.core.config import get_settings; print(get_settings())"` - wait, to ju≈º nie dzia≈Ça, teraz u≈ºywamy `from config import app`), czy sprawdzenie zmiennych ≈õrodowiskowych (`env | grep DATABASE`). Komenda `docker stats` wy≈õwietla real-time u≈ºycie CPU, RAM i network dla wszystkich kontener√≥w - przydatne przy debugowaniu performance issues.

**Typowe problemy local development:**

**Problem 1: Port already in use**
Symptom: `Error starting userland proxy: listen tcp4 0.0.0.0:8000: bind: address already in use`
Przyczyna: Inny proces (lokalna instalacja FastAPI, Jupyter notebook) u≈ºywa portu 8000
RozwiƒÖzanie: `lsof -ti:8000 | xargs kill -9` lub zmie≈Ñ port w docker-compose.yml

**Problem 2: PostgreSQL connection refused**
Symptom: `OperationalError: could not connect to server: Connection refused`
Przyczyna: Postgres container nie wystartowa≈Ç (failed health check) lub DATABASE_URL ma z≈Çe credentials
RozwiƒÖzanie: `docker-compose logs postgres` sprawd≈∫ logi, weryfikuj DATABASE_URL w .env

**Problem 3: Neo4j timeout**
Symptom: `ServiceUnavailable: Failed to establish connection`
Przyczyna: Neo4j jest wolny do startu (2-3 minuty przy pierwszym uruchomieniu)
RozwiƒÖzanie: Poczekaj 2-3 minuty, sprawd≈∫ `docker-compose logs neo4j` czy wystartowa≈Ç

**Problem 4: Frontend hot reload nie dzia≈Ça**
Symptom: Zmiany w .tsx nie sƒÖ widoczne w przeglƒÖdarce
Przyczyna: Volume mount nie dzia≈Ça (Windows WSL2 issue) lub Vite cache corruption
RozwiƒÖzanie: `docker-compose restart frontend` lub `docker-compose exec frontend rm -rf node_modules/.vite`

**Problem 5: Out of memory**
Symptom: Containers crashujƒÖ z exit code 137 (OOM killed)
Przyczyna: Docker Desktop ma za ma≈Ço RAM alokowanego (default 2GB)
RozwiƒÖzanie: Docker Desktop ‚Üí Settings ‚Üí Resources ‚Üí Memory: zwiƒôksz do minimum 8GB

### Database Management

**PostgreSQL:**

```bash
# Connect do bazy
docker-compose exec postgres psql -U sight -d sight_db

# Sprawd≈∫ tabele
\dt

# Sprawd≈∫ schema konkretnej tabeli
\d personas

# Wykonaj query
SELECT COUNT(*) FROM personas WHERE is_active = true;

# Export danych do CSV
\copy (SELECT * FROM personas) TO '/tmp/personas.csv' CSV HEADER

# Backup ca≈Çej bazy
docker-compose exec postgres pg_dump -U sight sight_db > backup_$(date +%Y%m%d).sql

# Restore z backupu
cat backup_20251103.sql | docker-compose exec -T postgres psql -U sight -d sight_db
```

**Redis:**

```bash
# Connect do Redis
docker-compose exec redis redis-cli

# Sprawd≈∫ wszystkie keys (DEV ONLY - nie u≈ºywaj w produkcji!)
KEYS *

# Sprawd≈∫ konkretny key
GET segment_brief:25-34:wy≈ºsze:warszawa:kobieta

# Sprawd≈∫ TTL (time to live)
TTL segment_brief:25-34:wy≈ºsze:warszawa:kobieta

# Flush cache (DEV ONLY)
FLUSHALL

# Sprawd≈∫ memory usage
INFO memory
```

**Neo4j:**

Otw√≥rz Neo4j Browser w przeglƒÖdarce: `http://localhost:7474`
Credentials: `neo4j / dev_password_change_in_prod`

```cypher
// Sprawd≈∫ ile jest dokument√≥w RAG
MATCH (d:Document) RETURN count(d)

// Sprawd≈∫ ile jest chunk√≥w
MATCH (c:RAGChunk) RETURN count(c)

// Sprawd≈∫ graph nodes (Wska≈∫nik, Obserwacja, Trend, Demografia)
MATCH (n) WHERE n:Wskaznik OR n:Obserwacja OR n:Trend OR n:Demografia
RETURN labels(n) as type, count(n) as count

// Sprawd≈∫ przyk≈Çadowy graph node
MATCH (w:Wskaznik) RETURN w LIMIT 5

// Sprawd≈∫ vector index
CALL db.indexes()

// Test vector search
CALL db.index.vector.queryNodes('chunk_vector_idx', 10, [0.1, 0.2, ...])
```

---

## Cloud Run Production

### Architektura Single Service

W przeciwie≈Ñstwie do tradycyjnego podej≈õcia z osobnymi serwisami dla frontendu i backendu, Sight deployuje siƒô jako jedna us≈Çuga Cloud Run. Dockerfile.cloudrun wykorzystuje multi-stage build: najpierw buduje frontend React z Vite (generujƒÖc statyczne pliki w `/dist`), nastƒôpnie instaluje Python dependencies dla backendu, a finalny stage ≈ÇƒÖczy oba - FastAPI serwuje zar√≥wno API endpoints (`/api/v1/*`) jak i statyczne pliki frontendu (`/`, `/assets/*`).

To rozwiƒÖzanie ma kilka zalet. Po pierwsze, **prostota** - jedna us≈Çuga Cloud Run zamiast dw√≥ch oznacza mniej konfiguracji, mniej secrets do zarzƒÖdzania, i ni≈ºsze koszty (jedna instancja zamiast dw√≥ch). Po drugie, **brak CORS issues** - frontend i backend sƒÖ pod tym samym origin, wiƒôc nie ma potrzeby konfiguracji CORS headers ani preflight OPTIONS requests. Po trzecie, **≈Çatwiejsze routing** - Cloud Run Load Balancer kieruje ca≈Çy traffic do jednego serwisu, a FastAPI internal router dystrybuuje requesty do API vs static files.

**app/main.py - Static Files Mounting:**

```python
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles

app = FastAPI()

# API routes
app.include_router(api_router, prefix="/api/v1")

# Static files (frontend build) - MUST be after API routes
app.mount("/", StaticFiles(directory="static", html=True), name="static")
```

Kolejno≈õƒá jest krytyczna - API routes muszƒÖ byƒá zarejestrowane PRZED static files mount, inaczej wszystkie requesty trafi≈Çyby do static files handler i API nie dzia≈Ça≈Çoby. StaticFiles z `html=True` automatycznie serwuje `index.html` dla wszystkich ≈õcie≈ºek kt√≥re nie pasujƒÖ do API routes, co zapewnia poprawne dzia≈Çanie React Router (client-side routing).

### Google Cloud Platform Setup

Deployment wymaga najpierw skonfigurowania GCP. Projekt `gen-lang-client-0508446677` ma w≈ÇƒÖczone piƒôƒá kluczowych API: Cloud Run (uruchamianie kontener√≥w), Cloud Build (CI/CD pipeline), Artifact Registry (storage dla Docker images), Secret Manager (bezpieczne przechowywanie credentials), oraz Cloud SQL Admin (zarzƒÖdzanie bazƒÖ PostgreSQL).

**W≈ÇƒÖczanie API (jednorazowe):**

```bash
# Zaloguj siƒô do GCP
gcloud auth login

# Ustaw projekt
gcloud config set project gen-lang-client-0508446677

# W≈ÇƒÖcz wymagane API
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
gcloud services enable artifactregistry.googleapis.com
gcloud services enable secretmanager.googleapis.com
gcloud services enable sqladmin.googleapis.com
```

Cloud SQL instancja `sight` zosta≈Ça utworzona w regionie `europe-central2` (Warsaw) na tier `db-f1-micro` (0.6GB RAM, shared CPU) z 10GB SSD storage. To wystarczajƒÖce dla ma≈Çych i ≈õrednich obciƒÖ≈ºe≈Ñ - instancja kosztuje oko≈Ço 10-15 USD miesiƒôcznie. Backup automatyczny wykonuje siƒô codziennie o 3:00 AM, z retencjƒÖ 7 dni. Maintenance window ustawiony jest na niedziele o 4:00 AM, minimalizujƒÖc wp≈Çyw na u≈ºytkownik√≥w.

**Tworzenie Cloud SQL instancji (jednorazowe):**

```bash
# Utw√≥rz Cloud SQL instancjƒô
gcloud sql instances create sight \
    --database-version=POSTGRES_15 \
    --tier=db-f1-micro \
    --region=europe-central2 \
    --storage-type=SSD \
    --storage-size=10GB \
    --backup-start-time=03:00 \
    --maintenance-window-day=SUN \
    --maintenance-window-hour=4

# Utw√≥rz bazƒô danych
gcloud sql databases create sight_db --instance=sight

# Utw√≥rz u≈ºytkownika
gcloud sql users create sight --instance=sight --password=STRONG_PASSWORD_HERE

# Sprawd≈∫ connection name (potrzebny dla DATABASE_URL_CLOUD)
gcloud sql instances describe sight --format="value(connectionName)"
# Output: gen-lang-client-0508446677:europe-central2:sight
```

**Artifact Registry:**

```bash
# Utw√≥rz repository dla Docker images
gcloud artifacts repositories create sight-containers \
    --repository-format=docker \
    --location=europe-central2 \
    --description="Docker images for Sight platform"

# Skonfiguruj Docker authentication
gcloud auth configure-docker europe-central2-docker.pkg.dev
```

---

## Staging Environment

### PrzeglƒÖd

≈örodowisko staging jest oddzielnym deployment aplikacji Sight, u≈ºywanym do testowania migracji baz danych, nowych funkcji i zmian konfiguracyjnych przed wdro≈ºeniem na produkcjƒô. Staging jest identyczny pod wzglƒôdem architektury z produkcjƒÖ (Cloud Run + Cloud SQL + Neo4j + Redis), ale z mniejszymi zasobami i oddzielnymi credentials.

**Kluczowe cele staging:**
- **Migration Testing**: Testowanie migracji Alembic na prawdziwej bazie danych przed produkcjƒÖ
- **Integration Testing**: Weryfikacja integracji z zewnƒôtrznymi serwisami (Gemini API, Neo4j Aura, Upstash Redis)
- **Performance Testing**: Testowanie pod obciƒÖ≈ºeniem z realistycznymi danymi
- **Configuration Validation**: Weryfikacja zmiennych ≈õrodowiskowych i secrets przed produkcjƒÖ

### Infrastruktura Staging

**Cloud Run Service:**
- Nazwa: `sight-staging`
- Region: `europe-central2` (Warsaw)
- Resources: 2Gi RAM, 1 CPU (po≈Çowa produkcji)
- Max instances: 2 (produkcja: 5)
- Auto-scaling: Scale to zero when idle

**Cloud SQL Database:**
- Instance: `sight-staging-db`
- Region: `europe-central2`
- Type: PostgreSQL 15 z pgvector
- Storage: 10GB SSD
- Backups: Automated daily (7-day retention)

**External Services:**
- Neo4j: Oddzielna instancja AuraDB Free (50k nodes)
- Redis: Oddzielna instancja Upstash Free (10k requests/day)
- Gemini API: Osobny API key z limitami dla testowania

### CI/CD Pipeline - Staging

Pipeline staging jest zdefiniowany w `.github/workflows/deploy-staging.yml` i uruchamia siƒô automatycznie przy push do brancha `staging`:

**Workflow Steps:**
1. **Checkout Code**: Pobranie kodu z brancha `staging`
2. **Authenticate to GCP**: Workload Identity Federation
3. **Pull Cache**: Pobranie poprzedniego image dla cachingu
4. **Build Docker Image**: Build z BuildKit inline cache
5. **Push to Registry**: Tag `sight-staging:latest` i `sight-staging:$SHA`
6. **Run Migrations**: Alembic upgrade head na staging DB
7. **Deploy to Cloud Run**: Deploy `sight-staging` service
8. **Smoke Tests**: Health check + Frontend accessibility
9. **Summary**: Wy≈õwietlenie URL i statusu deploymentu

**Przyk≈Çadowy workflow trigger:**

```bash
# 1. Utw√≥rz branch staging z main
git checkout main
git pull origin main
git checkout -b staging
git push -u origin staging

# 2. Push zmian do staging (auto-deploy)
git checkout staging
git merge main  # Lub cherry-pick specific commits
git push origin staging

# 3. Pipeline automatycznie:
#    - Builduje image
#    - Testuje migracje
#    - Deployuje do sight-staging
#    - Weryfikuje smoke tests
```

**Total time:** ~8-10 minut (z cache'owaniem)

### Deployment Staging

Manual deployment (bez GitHub Actions):

```bash
# 1. Build local image
docker build -f Dockerfile.cloudrun -t sight-staging:local .

# 2. Tag i push do Artifact Registry
docker tag sight-staging:local \
  europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight-staging:latest

docker push europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight-staging:latest

# 3. Run migrations (BEFORE deploy)
gcloud run jobs execute db-migrate-staging --region=europe-central2 --wait

# 4. Deploy to Cloud Run
gcloud run deploy sight-staging \
  --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight-staging:latest \
  --region=europe-central2 \
  --platform=managed \
  --memory=2Gi \
  --cpu=1 \
  --max-instances=2 \
  --set-secrets=DATABASE_URL=DATABASE_URL_STAGING:latest,GOOGLE_API_KEY=GOOGLE_API_KEY_STAGING:latest \
  --set-env-vars=ENVIRONMENT=staging,DEBUG=True

# 5. Verify deployment
curl https://sight-staging-xxxxx.a.run.app/health
```

### Konfiguracja Environment Variables

Staging u≈ºywa oddzielnych secrets w Google Secret Manager:

**Required Secrets (staging-specific):**
- `DATABASE_URL_STAGING`: Connection string do Cloud SQL staging
- `GOOGLE_API_KEY_STAGING`: Osobny Gemini API key
- `NEO4J_URI_STAGING`: Neo4j Aura staging instance
- `NEO4J_PASSWORD_STAGING`: Neo4j staging password
- `REDIS_URL_STAGING`: Upstash Redis staging
- `SECRET_KEY_STAGING`: JWT signing key (DIFFERENT from production!)

**Tworzenie secrets:**

```bash
# Database URL
echo -n "postgresql+asyncpg://sight:PASSWORD@/sight_staging_db?host=/cloudsql/PROJECT:REGION:INSTANCE" | \
  gcloud secrets create DATABASE_URL_STAGING --data-file=-

# API Keys
echo -n "YOUR_STAGING_GEMINI_KEY" | \
  gcloud secrets create GOOGLE_API_KEY_STAGING --data-file=-

# Secret Key (generate new!)
openssl rand -hex 32 | \
  gcloud secrets create SECRET_KEY_STAGING --data-file=-
```

### Testing Workflow - Staging ‚Üí Production

**Typowy workflow testowania:**

1. **Develop Locally**: Implementacja i testy jednostkowe lokalnie
2. **Push to Staging**: Merge do brancha `staging`, auto-deploy
3. **Test on Staging**: Manualne testy, smoke tests, performance tests
4. **Verify Migrations**: Sprawdzenie ≈ºe migracje dzia≈ÇajƒÖ poprawnie
5. **Push to Production**: Merge `staging` ‚Üí `main`, auto-deploy produkcji

**Migration Testing (kluczowy krok):**

```bash
# 1. Deploy do staging (auto-runs migrations)
git push origin staging

# 2. Verify migration succeeded
gcloud run jobs executions list --job=db-migrate-staging --region=europe-central2 --limit=1

# 3. Check migration logs
gcloud run jobs executions logs EXECUTION_ID

# 4. Test application with new schema
curl https://sight-staging-xxxxx.a.run.app/health
# Manual testing w UI

# 5. If migrations OK, push to production
git checkout main
git merge staging
git push origin main  # Auto-deploys to production
```

### Monitoring Staging

**Cloud Console URLs:**
- Cloud Run: https://console.cloud.google.com/run/detail/europe-central2/sight-staging
- Logs: https://console.cloud.google.com/logs (filter: `resource.labels.service_name="sight-staging"`)
- Metrics: Cloud Run Metrics dashboard
- SQL: https://console.cloud.google.com/sql/instances/sight-staging-db

**Useful Commands:**

```bash
# Tail logs
gcloud run services logs tail sight-staging --region=europe-central2

# Get service URL
gcloud run services describe sight-staging --region=europe-central2 --format="value(status.url)"

# Check revisions
gcloud run revisions list --service=sight-staging --region=europe-central2

# Rollback to previous revision
gcloud run services update-traffic sight-staging --to-revisions=PREVIOUS=100 --region=europe-central2
```

### Cost Optimization

Staging jest skonfigurowany z mniejszymi zasobami ni≈º produkcja:

| Resource | Production | Staging | Savings |
|----------|-----------|---------|---------|
| RAM | 4Gi | 2Gi | 50% |
| CPU | 2 cores | 1 core | 50% |
| Max instances | 5 | 2 | 60% |
| Cloud SQL | db-n1-standard-2 | db-f1-micro | 80% |

**Estimated costs (staging):**
- Cloud Run: ~$5-10/month (scale to zero + limited traffic)
- Cloud SQL: ~$10-15/month (db-f1-micro + 10GB storage)
- Egress: ~$2-5/month
- **Total: ~$20-30/month**

Production costs: ~$150-200/month (10x wiƒôcej traffic, wiƒôksze resources)

### Cleanup Staging (je≈õli niepotrzebny)

```bash
# Delete Cloud Run service
gcloud run services delete sight-staging --region=europe-central2

# Delete Cloud SQL instance (CAUTION: irreversible!)
gcloud sql instances delete sight-staging-db

# Delete migration job
gcloud run jobs delete db-migrate-staging --region=europe-central2

# Delete secrets
gcloud secrets delete DATABASE_URL_STAGING
gcloud secrets delete GOOGLE_API_KEY_STAGING
gcloud secrets delete SECRET_KEY_STAGING
```

---

## External Services

### Neo4j AuraDB

Opr√≥cz Cloud SQL, aplikacja integruje siƒô z dwoma managed services zewnƒôtrznymi. Neo4j AuraDB Free tier (50,000 nodes, 0 USD/miesiƒÖc) hostuje graf dla systemu RAG. Instancja znajduje siƒô w regionie `europe-west1` (Belgium), co daje latencjƒô oko≈Ço 20ms z Cloud Run w Warsaw. Connection string ma format `neo4j+s://xxxxx.databases.neo4j.io` - protok√≥≈Ç `neo4j+s` jest wymagany dla AuraDB (nie `bolt://` jak w lokalnym Neo4j).

**Setup AuraDB (jednorazowe):**

1. Zarejestruj siƒô na https://neo4j.com/cloud/aura/
2. Utw√≥rz instancjƒô Free tier w regionie Europe West 1
3. Zapisz connection URI i has≈Ço (pokazane tylko raz!)
4. Skonfiguruj IP allowlist - dodaj `0.0.0.0/0` dla Cloud Run (dynamic IPs)
5. Dodaj credentials do Secret Manager (NEO4J_URI, NEO4J_PASSWORD)

**Wa≈ºne:** AuraDB u≈ºywa `neo4j+s://` (secure WebSocket) zamiast `bolt://` (binary protocol). Aplikacja automatycznie detektuje protok√≥≈Ç i u≈ºywa odpowiedniego drivera.

### Upstash Redis

Upstash Redis w Free tier (10,000 requests/day) pe≈Çni rolƒô cache'a dla segment briefs i KPI snapshots. Region r√≥wnie≈º `europe-west1` dla niskiej latencji. Connection string: `redis://default:PASSWORD@region.upstash.io:PORT`. Upstash automatycznie evictuje najmniej u≈ºywane keys gdy limit jest bliski przekroczenia (LRU eviction policy).

**Setup Upstash (jednorazowe):**

1. Zarejestruj siƒô na https://upstash.com/
2. Utw√≥rz Redis database w regionie Europe West 1
3. Wybierz Free tier (10k requests/day, 256MB storage)
4. Skopiuj REST URL i konwertuj na Redis URL format
5. Dodaj REDIS_URL do Secret Manager

**Cache strategy:**

- Segment briefs: TTL 7 dni (604800s)
- Graph RAG context: TTL 7 dni
- KPI snapshots: TTL 5 minut (300s)
- Expected hit rate: 70-90% dla segment briefs, 80-95% dla graph context

### Secrets Management

Wszystkie wra≈ºliwe dane (API keys, passwords, connection strings) sƒÖ przechowywane w GCP Secret Manager, nie w zmiennych ≈õrodowiskowych czy plikach .env. Mamy siedem secrets:

- `GOOGLE_API_KEY` - Gemini API key dla LLM operations
- `NEO4J_URI` i `NEO4J_PASSWORD` - credentials do AuraDB
- `REDIS_URL` - pe≈Çny connection string do Upstash
- `DATABASE_URL_CLOUD` - PostgreSQL connection string przez Unix socket
- `POSTGRES_PASSWORD` - has≈Ço u≈ºytkownika postgres
- `SECRET_KEY` - FastAPI session signing key (32-char random hex)

**Tworzenie secrets (jednorazowe):**

```bash
# 1. Wygeneruj SECRET_KEY
openssl rand -hex 32

# 2. Utw√≥rz secrets
echo -n "YOUR_GEMINI_API_KEY" | gcloud secrets create GOOGLE_API_KEY --data-file=-
echo -n "neo4j+s://xxxxx.databases.neo4j.io" | gcloud secrets create NEO4J_URI --data-file=-
echo -n "YOUR_NEO4J_PASSWORD" | gcloud secrets create NEO4J_PASSWORD --data-file=-
echo -n "redis://default:PASSWORD@region.upstash.io:PORT" | gcloud secrets create REDIS_URL --data-file=-
echo -n "STRONG_POSTGRES_PASSWORD" | gcloud secrets create POSTGRES_PASSWORD --data-file=-
echo -n "$(openssl rand -hex 32)" | gcloud secrets create SECRET_KEY --data-file=-

# 3. Zbuduj DATABASE_URL_CLOUD (Unix socket dla Cloud SQL)
echo -n "postgresql+asyncpg://sight:POSTGRES_PASSWORD@/sight_db?host=/cloudsql/gen-lang-client-0508446677:europe-central2:sight" | gcloud secrets create DATABASE_URL_CLOUD --data-file=-

# 4. Nadaj uprawnienia Cloud Run service account
PROJECT_NUMBER=$(gcloud projects describe gen-lang-client-0508446677 --format="value(projectNumber)")
SERVICE_ACCOUNT="${PROJECT_NUMBER}-compute@developer.gserviceaccount.com"

for SECRET in GOOGLE_API_KEY NEO4J_URI NEO4J_PASSWORD REDIS_URL DATABASE_URL_CLOUD POSTGRES_PASSWORD SECRET_KEY; do
    gcloud secrets add-iam-policy-binding $SECRET \
        --member="serviceAccount:${SERVICE_ACCOUNT}" \
        --role="roles/secretmanager.secretAccessor"
done
```

Secrets sƒÖ automatycznie montowane do Cloud Run przez parametr `--set-secrets` w deploy command. Cloud Run service account ma rolƒô `roles/secretmanager.secretAccessor` dla ka≈ºdego secretu. Warto≈õci sƒÖ dostƒôpne w kontenerze jako zmienne ≈õrodowiskowe, ale nigdy nie sƒÖ wy≈õwietlane w logach czy Cloud Console UI.

**Aktualizacja secrets:**

```bash
# Utw√≥rz nowƒÖ wersjƒô secretu
echo -n "NEW_VALUE" | gcloud secrets versions add SECRET_NAME --data-file=-

# Cloud Run automatycznie u≈ºyje latest version przy nastƒôpnym deploy
# Mo≈ºna te≈º wymusiƒá nowƒÖ rewizjƒô bez deploy:
gcloud run services update sight --region=europe-central2
```

---

## CI/CD Pipeline

### Overview

Pe≈Çny deployment pipeline jest zdefiniowany w `cloudbuild.yaml` i sk≈Çada siƒô z siedmiu sekwencyjnych krok√≥w: pull cache, Docker build, push to registry, database migrations, Cloud Run deploy, Neo4j initialization, oraz smoke tests. Pipeline uruchamia siƒô automatycznie przy ka≈ºdym push do branch `main` przez Cloud Build trigger podpiƒôty do GitHub repo `JakWdo/Symulacja`.

Ca≈Çkowity czas wykonania wynosi **8-12 minut** dla incremental builds (z cache'owaniem Docker layers), lub **20-25 minut** dla first build bez cache. Code-only changes (bez zmian w dependencies) kompletujƒÖ w **5-8 minut** dziƒôki aggressive layer caching. Pipeline u≈ºywa explicit `--cache-from` oraz BuildKit inline cache dla maximum cache hit rate.

**Optimizations applied (October 2024):**

- BuildKit inline cache: zapisuje cache metadata wewnƒÖtrz image layers
- Pinned base images: `node:20.18.0`, `python:3.11.11` (prevents cache invalidation)
- Multi-stage caching: ka≈ºdy stage (frontend-builder, backend-builder, runtime) jest cache'owany osobno
- Machine type E2_HIGHCPU_8: szybszy build (8 vCPU vs 1 vCPU default)
- Parallel quality checks: usuniƒôte z cloudbuild.yaml (przenoszone do pre-commit hooks lokalnie)

### Step 1: Pull Cache

Pipeline zaczyna siƒô od pobrania poprzedniego image z Artifact Registry aby u≈ºyƒá go jako cache source. U≈ºywamy `entrypoint: bash` z `|| true` aby uniknƒÖƒá failowania na first build (no cache exists yet). Docker automatycznie u≈ºyje downloaded image jako cache source w nastƒôpnym kroku.

```bash
docker pull europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest || echo "No cache image found - first build will be slow"
```

### Step 2: Build & Push

Build Docker image z `Dockerfile.cloudrun` u≈ºywajƒÖc BuildKit dla lepszego cachingu. Multi-stage build zajmuje 3-5 minut dla code-only changes lub 15-20 minut dla zmian w dependencies. Image jest tagowany dwoma tagami: `latest` (zawsze wskazuje na najnowszy build) oraz `$COMMIT_SHA` (konkretny git commit dla rollback).

```bash
export DOCKER_BUILDKIT=1

docker build \
  -f Dockerfile.cloudrun \
  --cache-from europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
  --build-arg BUILDKIT_INLINE_CACHE=1 \
  -t europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
  -t europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:$COMMIT_SHA \
  .

docker push --all-tags europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight
```

Push do Artifact Registry nastƒôpuje natychmiast po build. Registry automatycznie skanuje image pod kƒÖtem CVEs i wy≈õwietla wyniki w Cloud Console. Critical CVEs powinny byƒá naprawione przed deploy do produkcji.

### Step 3: Database Migrations (CRITICAL)

**Najwa≈ºniejszy krok ca≈Çego pipeline.** Przed wdro≈ºeniem nowego kodu aplikacji, schema bazy danych musi byƒá up-to-date. Cloud Run Job `db-migrate` uruchamia komendƒô `alembic upgrade head` wewnƒÖtrz tego samego Docker image kt√≥ry bƒôdzie deployowany.

Job ma dostƒôp do Cloud SQL przez Unix socket (`--add-cloudsql-instances`) i u≈ºywa `DATABASE_URL_CLOUD` secret. Je≈õli migracja failuje (np. syntax error w migration script, constraint violation), build siƒô przerywa. To zapobiega deployment broken code kt√≥ry nie mo≈ºe siƒô po≈ÇƒÖczyƒá z bazƒÖ.

```bash
# Create or update migration job
gcloud run jobs create db-migrate \
  --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
  --region=europe-central2 \
  --add-cloudsql-instances=gen-lang-client-0508446677:europe-central2:sight \
  --set-secrets=DATABASE_URL=DATABASE_URL_CLOUD:latest \
  --command=alembic,upgrade,head \
  --max-retries=2 \
  --task-timeout=300

# Execute migrations
gcloud run jobs execute db-migrate --region=europe-central2 --wait

# Check exit code
if [ $? -eq 0 ]; then
  echo "‚úÖ Migrations completed successfully"
else
  echo "‚ùå Migrations failed - aborting deployment"
  exit 1
fi
```

Migracje sƒÖ wykonywane jako Cloud Run Job (nie exec w dzia≈ÇajƒÖcym kontenerze) z dw√≥ch powod√≥w. Po pierwsze, **isolation** - job dzia≈Ça w czystym environment z maksymalnie 300s timeout, bez ryzyka interference z running application. Po drugie, **retry logic** - job automatycznie retry-uje do 2 razy przy transient failures (network blips, Cloud SQL restarts).

### Step 4: Cloud Run Deploy

Deployment do Cloud Run u≈ºywa `gcloud run deploy` z parametrami zoptymalizowanymi dla FastAPI + LLM workload:

```bash
gcloud run deploy sight \
  --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
  --region=europe-central2 \
  --platform=managed \
  --allow-unauthenticated \
  --port=8080 \
  --memory=4Gi \
  --cpu=2 \
  --cpu-boost \
  --timeout=300 \
  --min-instances=0 \
  --max-instances=5 \
  --execution-environment=gen2 \
  --add-cloudsql-instances=gen-lang-client-0508446677:europe-central2:sight \
  --set-secrets=DATABASE_URL=DATABASE_URL_CLOUD:latest,GOOGLE_API_KEY=GOOGLE_API_KEY:latest,NEO4J_PASSWORD=NEO4J_PASSWORD:latest,NEO4J_URI=NEO4J_URI:latest,POSTGRES_PASSWORD=POSTGRES_PASSWORD:latest,REDIS_URL=REDIS_URL:latest,SECRET_KEY=SECRET_KEY:latest \
  --set-env-vars=NEO4J_USER=neo4j,ENVIRONMENT=production,DEBUG=False,DEFAULT_LLM_PROVIDER=google,DEFAULT_MODEL=gemini-2.5-flash,EMBEDDING_MODEL=models/gemini-embedding-001,RAG_ENABLED=True,ORCHESTRATION_ENABLED=True
```

**Kluczowe parametry:**

- `--memory=4Gi` - wystarczajƒÖce dla FastAPI + Redis client + Neo4j driver + sentence-transformers (~2.5GB peak)
- `--cpu=2` - dwa vCPU pozwalajƒÖ na parallel processing LLM requests
- `--cpu-boost` - temporary CPU boost podczas startu kontenera (cold start optimization, reduces cold start z 10s ‚Üí 5s)
- `--timeout=300` - 5 minut timeout dla d≈Çugich LLM operations (focus groups z 20 person √ó 4 pytania ~2 min)
- `--min-instances=0` - scale to zero gdy brak traffic (cost optimization)
- `--max-instances=5` - auto-scale do 5 instancji przy heavy load (prevents runaway costs)
- `--execution-environment=gen2` - nowszy runtime z lepszƒÖ performance i security

Secrets sƒÖ montowane jako environment variables (`--set-secrets=DATABASE_URL=DATABASE_URL_CLOUD:latest,...`). Cloud Run automatycznie pobiera najnowsze wersje secrets - nie trzeba manualnie aktualizowaƒá deployment po zmianie secretu.

Deployment zajmuje 1-2 minuty. Cloud Run czeka a≈º nowa rewizja przejdzie health check (`/health` endpoint musi zwr√≥ciƒá 200 OK przez 10 sekund), dopiero wtedy kieruje traffic. Je≈õli health check failuje przez 4 minuty, deployment jest rollbackowany automatycznie do poprzedniej rewizji.

### Step 5: Neo4j Initialization

Po deployment aplikacji, osobny Cloud Run Job `neo4j-init` uruchamia `python scripts/init_neo4j_cloudrun.py`. Skrypt tworzy trzy kluczowe indeksy w Neo4j:

- `document_id_idx` - B-tree index na `Document.id` dla szybkich lookup√≥w
- `chunk_embedding_idx` - property index na `Chunk.embedding` (metadata)
- `chunk_vector_idx` - **vector index** na `Chunk.embedding` z 768 wymiarami (Gemini embeddings), cosine similarity

Vector index jest wymagany dla hybrid search RAG. Bez niego queries `db.index.vector.queryNodes()` failujƒÖ z `VectorIndexNotFoundError`. Tworzenie indeksu zajmuje 30-60 sekund dla typowej bazy z oko≈Ço 10,000 chunks.

```bash
# Create or update Neo4j init job
gcloud run jobs create neo4j-init \
  --image=europe-central2-docker.pkg.dev/gen-lang-client-0508446677/sight-containers/sight:latest \
  --region=europe-central2 \
  --set-secrets=NEO4J_URI=NEO4J_URI:latest,NEO4J_PASSWORD=NEO4J_PASSWORD:latest \
  --set-env-vars=NEO4J_USER=neo4j \
  --command=python,scripts/init_neo4j_cloudrun.py \
  --max-retries=3 \
  --task-timeout=300

# Execute initialization
gcloud run jobs execute neo4j-init --region=europe-central2 --wait

# Check status (non-fatal)
if [ $? -eq 0 ]; then
  echo "‚úÖ Neo4j indexes initialized successfully"
else
  echo "‚ö†Ô∏è Neo4j init failed - RAG features may be limited"
fi
```

Ten krok jest **non-blocking** - je≈õli failuje (np. Neo4j timeout, network issues), build siƒô nie przerywa. Aplikacja dzia≈Ça normalnie, ale RAG features sƒÖ limited dop√≥ki indeksy nie zostanƒÖ utworzone. Background task w FastAPI retry-uje po≈ÇƒÖczenie z Neo4j co 5 minut.

### Step 6: Smoke Tests

Ostatni krok wykonuje cztery smoke tests na fresh deployowanej aplikacji:

1. **Health check** - `GET /health` musi zwr√≥ciƒá 200 OK z JSON payload `{"status": "healthy"}`
2. **Startup probe** - `GET /startup` weryfikuje po≈ÇƒÖczenia do PostgreSQL, Redis, Neo4j
3. **API docs** - `GET /docs` sprawdza czy Swagger UI jest dostƒôpne
4. **Frontend** - `GET /` zwraca React SPA (nie 404)

```bash
# Get deployed service URL
SERVICE_URL=$(gcloud run services describe sight --region=europe-central2 --format="value(status.url)")

# Test 1: Health check
HEALTH_STATUS=$(curl -f -s -o /dev/null -w "%{http_code}" "$SERVICE_URL/health")
if [ "$HEALTH_STATUS" != "200" ]; then
  echo "‚ùå Health check FAILED"
  exit 1
fi

# Test 2: Frontend
FRONTEND_STATUS=$(curl -f -s -o /dev/null -w "%{http_code}" "$SERVICE_URL/")
if [ "$FRONTEND_STATUS" != "200" ]; then
  echo "‚ùå Frontend FAILED"
  exit 1
fi

echo "üéâ Smoke tests PASSED!"
```

Je≈õli kt√≥rykolwiek test failuje, build jest oznaczony jako failed. To **blocking step** - informuje zesp√≥≈Ç ≈ºe deployment siƒô nie powi√≥d≈Ç mimo ≈ºe Cloud Run deploy sukceeded. W przysz≈Ço≈õci planujemy automatic rollback do poprzedniej rewizji przy failed smoke tests.

### Monitoring Builds

Logi z ka≈ºdego build sƒÖ dostƒôpne w Cloud Console lub przez CLI:

```bash
# Lista ostatnich build√≥w
gcloud builds list --limit=5

# Stream logs konkretnego build
gcloud builds log BUILD_ID --stream

# Szczeg√≥≈Çy buildu (JSON)
gcloud builds describe BUILD_ID --format=json

# Status poszczeg√≥lnych krok√≥w
gcloud builds describe BUILD_ID --format="json" | jq '.steps[] | {id, status, timing}'
```

Ka≈ºdy krok pipeline ma assigned ID (np. `pull-cache`, `build`, `deploy`). Mo≈ºna sprawdziƒá kt√≥ry krok failowa≈Ç i ile czasu zajƒÖ≈Ç. To jest przydatne do debugowania slow builds czy identyfikacji bottlenecks w pipeline.

**Setup Cloud Build trigger (jednorazowe):**

```bash
# Utw√≥rz trigger na push do main branch
gcloud builds triggers create github \
  --name="sight-deploy-main" \
  --repo-name="Symulacja" \
  --repo-owner="JakWdo" \
  --branch-pattern="^main$" \
  --build-config="cloudbuild.yaml"
```

---

## Health Checks & Automatic Rollback

### PrzeglƒÖd

System health checks zapewnia automatic monitoring kluczowych serwis√≥w infrastruktury i umo≈ºliwia automatic rollback w przypadku wykrycia problem√≥w. Health endpoint (`/health`) sprawdza po≈ÇƒÖczenia do PostgreSQL, Redis i Neo4j, zwracajƒÖc szczeg√≥≈Çowe statusy ka≈ºdego serwisu.

**Kluczowe cele:**
- **Fast failure detection**: Wykrycie problem√≥w w <10s (health check co 10s)
- **Automatic rollback**: Przywr√≥cenie poprzedniej wersji je≈õli 2+ serwisy down
- **Low MTTR**: Mean Time To Recovery <2 min (manual rollback)
- **Zero-downtime deployments**: Health checks zapobiegajƒÖ routing ruchu do unhealthy instances

### Health Endpoint

**URL**: `/health`

**Sprawdzane serwisy:**
1. **PostgreSQL (database)**: Simple query `SELECT 1` z timeout 2s
2. **Redis (cache)**: Ping command z timeout 2s
3. **Neo4j (graph database)**: Connection verification z timeout 2s

**Response format:**

```json
{
  "status": "healthy" | "degraded" | "unhealthy",
  "environment": "production" | "staging",
  "checks": {
    "database": {
      "status": "healthy",
      "latency_ms": 12.5,
      "error": null
    },
    "redis": {
      "status": "healthy",
      "latency_ms": 8.3,
      "error": null
    },
    "neo4j": {
      "status": "healthy",
      "latency_ms": 45.2,
      "error": null
    }
  },
  "latency_total_ms": 65.8
}
```

**Status codes:**
- `200 OK`: All healthy lub degraded (1 service down)
- `503 Service Unavailable`: Unhealthy (2+ services down)

**Status logic:**
- **healthy**: All 3 services up (database, redis, neo4j)
- **degraded**: 1 service down, application still functional
- **unhealthy**: 2+ services down, triggers rollback

### Cloud Run Health Check Configuration

Cloud Run automatycznie monitoruje health endpoint i usuwa unhealthy instances z traffic routing.

**Konfiguracja:**

```bash
gcloud run services update sight \
  --region=europe-central2 \
  --health-checks-path=/health \
  --health-checks-interval=10s \
  --health-checks-timeout=3s \
  --health-checks-unhealthy-threshold=3 \
  --health-checks-healthy-threshold=1
```

**Parametry:**
- `health-checks-interval`: 10s (sprawdzanie co 10 sekund)
- `health-checks-timeout`: 3s (timeout per check)
- `unhealthy-threshold`: 3 failures ‚Üí mark unhealthy
- `healthy-threshold`: 1 success ‚Üí mark healthy

**Behavior:**
- Unhealthy instances are automatically removed from load balancer
- New instances are not routed traffic until health check passes
- Rolling updates wait for health checks before proceeding

### Automatic Rollback Policy

**Rollback triggers:**

1. **Health check failures**: 3 consecutive failures (30s total)
2. **5xx error rate**: >5% errors for 2 minutes
3. **High latency**: p95 latency >2000ms for 2 minutes

**Rollback procedure:**

```bash
# Manual rollback to previous revision
gcloud run services update-traffic sight \
  --to-revisions=PREVIOUS=100 \
  --region=europe-central2

# Or specific revision
gcloud run services update-traffic sight \
  --to-revisions=sight-00042-abc=100 \
  --region=europe-central2
```

**Gradual rollout (canary deployment):**

```bash
# Deploy new version to 10% traffic
gcloud run services update-traffic sight \
  --to-revisions=LATEST=10,PREVIOUS=90 \
  --region=europe-central2

# If stable after 30 min, promote to 100%
gcloud run services update-traffic sight \
  --to-revisions=LATEST=100 \
  --region=europe-central2

# If issues detected, instant rollback
gcloud run services update-traffic sight \
  --to-revisions=PREVIOUS=100 \
  --region=europe-central2
```

### Monitoring Alerts

**Setup alerts w Cloud Monitoring dla automatic notifications:**

**1. High Error Rate Alert:**

```yaml
Display Name: "Cloud Run - High 5xx Rate"
Metric: cloud_run_revision/request_count
Filter: response_code_class="5xx"
Condition: 5xx rate > 5% for 2 minutes
Notification: Slack #alerts + Email
```

**2. High Latency Alert:**

```yaml
Display Name: "Cloud Run - High P95 Latency"
Metric: cloud_run_revision/request_latencies
Aggregation: 95th percentile
Condition: p95 > 2000ms for 2 minutes
Notification: Slack #alerts + Email
```

**3. Health Check Failures:**

```yaml
Display Name: "Cloud Run - Health Check Failures"
Metric: cloud_run_revision/container/startup_latencies
Condition: Startup failures > 3 in 5 minutes
Notification: Slack #alerts + Email
```

### Setup Script

**Automated configuration:**

```bash
# Production
./scripts/configure_cloud_run_health_check.sh production

# Staging
./scripts/configure_cloud_run_health_check.sh staging
```

**Script actions:**
1. Configure health check endpoint (`/health`)
2. Set health check parameters (interval, timeout, thresholds)
3. Verify health endpoint responds correctly
4. Display manual rollback commands
5. Generate monitoring alert setup instructions

### Testing Health Checks

**Test health endpoint:**

```bash
# Production
curl https://sight-xxxxx.a.run.app/health | jq

# Expected response (healthy)
{
  "status": "healthy",
  "environment": "production",
  "checks": {
    "database": {"status": "healthy", "latency_ms": 15.2},
    "redis": {"status": "healthy", "latency_ms": 8.5},
    "neo4j": {"status": "healthy", "latency_ms": 42.1}
  },
  "latency_total_ms": 65.8
}
```

**Test unhealthy response (database down):**

```bash
# Simulate database failure (don't do in production!)
# Stop PostgreSQL: docker-compose stop postgres

curl https://sight-xxxxx.a.run.app/health | jq

# Expected response (unhealthy, HTTP 503)
{
  "status": "unhealthy",
  "environment": "staging",
  "checks": {
    "database": {
      "status": "unhealthy",
      "latency_ms": 2000,
      "error": "Database timeout (>2s)"
    },
    "redis": {"status": "healthy", "latency_ms": 9.1},
    "neo4j": {"status": "unhealthy", "latency_ms": 0, "error": "Connection refused"}
  },
  "latency_total_ms": 2012.3
}
```

### Rollback Testing (Staging Only!)

**Test rollback procedure na staging:**

```bash
# 1. Deploy new version with intentional error
git checkout staging
# Edit code to introduce error (e.g., crash endpoint)
git commit -m "test: intentional crash for rollback testing"
git push origin staging

# 2. Wait for deployment (~8 min)
# Monitor logs for health check failures
gcloud run services logs tail sight-staging --region=europe-central2

# 3. Health checks should fail after 30s (3 failures √ó 10s)
# Check revision status
gcloud run revisions list --service=sight-staging --region=europe-central2 --limit=5

# 4. Manual rollback (simulate automatic)
gcloud run services update-traffic sight-staging \
  --to-revisions=PREVIOUS=100 \
  --region=europe-central2

# 5. Verify rollback completed <2 minutes
# Check service is healthy again
curl https://sight-staging-xxxxx.a.run.app/health

# 6. Cleanup: fix code and redeploy
git revert HEAD
git push origin staging
```

### MTTR (Mean Time To Recovery)

**Target: <2 minutes**

**Timeline:**
- t+0s: Health check failure detected
- t+10s: Second health check failure
- t+20s: Third health check failure ‚Üí mark unhealthy
- t+30s: Alert fired (Slack/Email)
- t+45s: Engineer acknowledges alert
- t+60s: Engineer executes rollback command
- t+90s: Rollback deployment in progress
- t+120s: Previous revision serving traffic, service healthy ‚úÖ

**Optimization:**
- Pre-configured rollback commands in runbook
- Slack bot for one-click rollback (future)
- Automatic rollback via Cloud Functions + Monitoring (future)

### Troubleshooting

**Health check fails but service works:**

```bash
# Check if health endpoint is accessible
curl https://sight-xxxxx.a.run.app/health -v

# Check service logs for health check errors
gcloud run services logs tail sight --region=europe-central2 | grep "/health"

# Verify database/redis/neo4j connections
# Check Cloud SQL status: https://console.cloud.google.com/sql
# Check Upstash Redis status: https://console.upstash.com
# Check Neo4j Aura status: https://console.neo4j.io
```

**Rollback doesn't fix issue:**

```bash
# Issue may be in data/infrastructure, not code
# Check previous revisions health
gcloud run revisions describe REVISION_NAME --region=europe-central2

# If all revisions unhealthy, check infrastructure:
# 1. Cloud SQL connection issues
# 2. Redis/Neo4j downtime
# 3. Network connectivity
# 4. Secret Manager access

# Temporary mitigation: Scale to zero
gcloud run services update sight \
  --min-instances=0 \
  --max-instances=0 \
  --region=europe-central2

# Fix infrastructure, then scale back up
gcloud run services update sight \
  --min-instances=0 \
  --max-instances=5 \
  --region=europe-central2
```

### Best Practices

1. **Always test on staging first**: Never test rollback on production
2. **Monitor after deployment**: Watch health checks for 30 min after deploy
3. **Gradual rollouts**: Use canary deployments (10% ‚Üí 50% ‚Üí 100%) for risky changes
4. **Document rollback commands**: Keep runbook updated with latest revision names
5. **Regular drills**: Practice rollback quarterly to ensure team readiness
6. **Alert fatigue**: Tune thresholds to avoid false positives (5% error rate, not 1%)

---

## Monitoring & Observability

### Cloud Logging

Wszystkie logi z Cloud Run sƒÖ automatycznie przekazywane do Cloud Logging. Query language pozwala na precyzyjne filtrowanie.

**Przyk≈Çady queries:**

```bash
# Tylko b≈Çƒôdy z ostatnich 50 wpis√≥w
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=sight AND severity>=ERROR" --limit=50

# LLM operations z u≈ºyciem token√≥w
gcloud logging read "resource.type=cloud_run_revision AND jsonPayload.operation=persona_generation" --limit=20 --format=json

# Slow queries (latency > 1s)
gcloud logging read "resource.type=cloud_run_revision AND jsonPayload.latency_ms>1000" --limit=20

# Requests z konkretnego user_id
gcloud logging read "resource.type=cloud_run_revision AND jsonPayload.user_id=USER_UUID" --limit=50
```

Logi zawierajƒÖ structured fields: timestamp, severity (DEBUG/INFO/WARNING/ERROR/CRITICAL), textPayload (message), httpRequest (dla HTTP logs), oraz labels (custom metadata). FastAPI automatycznie loguje ka≈ºdy request z method, path, status code i latency.

**Structured logging w aplikacji:**

```python
import logging

logger = logging.getLogger(__name__)

# Log LLM call z kontekstem
logger.info(
    "LLM generation completed",
    extra={
        "operation": "persona_generation",
        "model": "gemini-2.5-flash",
        "input_tokens": 1234,
        "output_tokens": 567,
        "latency_ms": 2800,
        "cost_usd": 0.00026,
        "user_id": str(user_id),
        "project_id": str(project_id)
    }
)
```

### Key Metrics to Track

**LLM Performance:**
- Tokens per operation (input/output)
- Cost per operation ($USD)
- Latency (p50, p90, p95, p99)
- Error rate (% failed calls)
- Retry rate (% calls requiring retry)

**RAG Performance:**
- Cache hit rate (hybrid search, graph RAG)
- Retrieval latency (vector, keyword, graph)
- Context size (chars, tokens)
- Relevance score (user feedback)

**Quality Metrics:**
- Persona quality score (0-100)
- Demographic accuracy (chi-square p-value)
- Consistency score (% personas passing checks)
- Hallucination rate (% outputs with facts not in RAG)

**Infrastructure Metrics:**
- API latency (p50, p90, p95, p99)
- Database query time (p95)
- Memory usage (MB, % of limit)
- CPU usage (%, throttling events)
- Active instances count
- Cold start frequency
- Error rate (HTTP 5xx)

### Cloud Monitoring Dashboard

Target metrics dla produkcji:

- **API latency** - P95 < 500ms dla prostych endpoints, < 3s dla LLM-powered
- **Persona generation** - 20 person < 60s (obecnie oko≈Ço 45s dziƒôki parallel processing)
- **Focus group** - 20 person √ó 4 pytania < 3 minuty (obecnie oko≈Ço 2 min)
- **Cold start** - < 10s dla pierwszego request po scale-to-zero (dziƒôki `--cpu-boost`)
- **Memory usage** - < 3GB sustained (4GB limit daje buffer dla peaks)
- **Database query** - P95 < 100ms (obecnie oko≈Ço 65ms)
- **Hybrid search** - P95 < 350ms (obecnie oko≈Ço 280ms)

Metrics sƒÖ monitorowane przez Cloud Monitoring. Dashboard pokazuje request count, latency percentiles (P50/P90/P95/P99), error rate, CPU/memory utilization, oraz active instances count.

**Setup alerting policies:**

```bash
# Alert na error rate > 1%
gcloud alpha monitoring policies create \
  --notification-channels=CHANNEL_ID \
  --display-name="High Error Rate" \
  --condition-display-name="Error rate > 1%" \
  --condition-threshold-value=0.01 \
  --condition-threshold-duration=300s

# Alert na latency P95 > 5s
gcloud alpha monitoring policies create \
  --notification-channels=CHANNEL_ID \
  --display-name="High Latency" \
  --condition-display-name="P95 latency > 5s" \
  --condition-threshold-value=5000 \
  --condition-threshold-duration=300s
```

### Common Production Issues

**Problem 1: Service timeout podczas startu**
Symptom: Cloud Run deployment sukceeded ale /health zwraca 504 Gateway Timeout
Przyczyna: Aplikacja startuje >4 minuty (Cloud Run limit)
RozwiƒÖzanie: Zwiƒôkszyƒá `--timeout` lub zoptymalizowaƒá startup (lazy initialization zamiast eager)

**Problem 2: Database connection failed**
Symptom: Logi pokazujƒÖ `OperationalError: could not connect to server`
Przyczyna: ≈πle skonfigurowany `DATABASE_URL_CLOUD` secret lub brak uprawnienia do Cloud SQL
RozwiƒÖzanie: Zweryfikowaƒá format connection string (`postgresql+asyncpg://...?host=/cloudsql/...`) i sprawdziƒá czy service account ma rolƒô `roles/cloudsql.client`

**Problem 3: Neo4j timeout**
Symptom: `/startup` endpoint pokazuje `"neo4j": "connection_failed"`
Przyczyna: Neo4j AuraDB wymaga `neo4j+s://` URI (nie `bolt://`), lub firewall blokuje Cloud Run IP
RozwiƒÖzanie: Zaktualizowaƒá `NEO4J_URI` secret i dodaƒá `0.0.0.0/0` do allowlist w AuraDB Console (Cloud Run ma dynamiczne IPs)

**Problem 4: Frontend 404**
Symptom: `GET /` zwraca 404 Not Found, API dzia≈Ça
Przyczyna: Statyczne pliki frontendu nie zosta≈Çy skopiowane do Docker image (b≈ÇƒÖd w Dockerfile.cloudrun)
RozwiƒÖzanie: Zweryfikowaƒá `COPY --from=frontend-builder /app/dist /app/static` w Dockerfile i sprawdziƒá czy `app.mount("/", StaticFiles(directory="static", html=True))` jest w main.py

**Problem 5: Slow LLM responses**
Symptom: Timeout errors przy generowaniu person lub focus groups
Przyczyna: NiewystarczajƒÖce CPU/RAM lub Gemini API throttling
RozwiƒÖzanie: Zwiƒôkszyƒá `--cpu=4 --memory=8Gi` lub zaimplementowaƒá rate limiting + request queuing

**Problem 6: Out of memory (OOM)**
Symptom: Cloud Run logs pokazujƒÖ `Memory limit exceeded`, instancja crashuje
Przyczyna: Memory leak, zbyt du≈ºe embeddings w pamiƒôci, lub niewystarczajƒÖcy limit
RozwiƒÖzanie: Zwiƒôkszyƒá `--memory=8Gi` lub zoptymalizowaƒá memory usage (batch processing embeddings, garbage collection)

### Cost Optimization

Dla ma≈Çego projektu (oko≈Ço 100 users, 1000 requests/day) miesiƒôczne koszty wynoszƒÖ oko≈Ço **16-30 USD**:

- Cloud Run (sight): $5-10 - zale≈ºne od request count i compute time
- Cloud SQL (db-f1-micro): $10-15 - sta≈Çy koszt za instancjƒô + storage
- Neo4j AuraDB Free: $0 - darmowy tier do 50k nodes
- Upstash Redis Free: $0 - darmowy tier do 10k requests/day
- Cloud Build: $0-2 - pierwsze 120 minut/dzie≈Ñ sƒÖ free
- Artifact Registry: $1-3 - storage + egress

Najwiƒôkszym kosztem jest Cloud SQL. Dla jeszcze ni≈ºszych koszt√≥w mo≈ºna rozwa≈ºyƒá Cloud SQL Serverless (pay-per-use) lub migracjƒô do managed PostgreSQL od innego providera (Supabase, Neon).

**Cost optimization tips:**

1. **Cloud Run auto-scaling** - dziƒôki `--min-instances=0` aplikacja scale-uje do zero instancji gdy brak traffic. P≈Çacimy tylko za actual compute time, nie za idle instances. Dla oko≈Ço 1000 requests/day (≈õrednio 500ms/request) to oko≈Ço 8 minut compute time dziennie = $0.20/dzie≈Ñ = $6/miesiƒÖc.

2. **Gemini Flash zamiast Pro** - Flash model kosztuje $0.075/1M input tokens (Pro: $1.25 = 17x dro≈ºej). Dla wiƒôkszo≈õci operacji (generowanie person, focus group responses) Flash daje wystarczajƒÖcƒÖ jako≈õƒá. Pro u≈ºywamy tylko dla complex analysis i summarization.

3. **Redis cache hits** - segment briefs sƒÖ cache'owane w Redis na 7 dni. Cache hit rate oko≈Ço 80% oznacza 80% mniej wywo≈Ça≈Ñ Gemini API = oszczƒôdno≈õƒá oko≈Ço $15-20/miesiƒÖc dla aktywnego u≈ºytkowania.

4. **Docker layer caching** - Cloud Build cache'uje Docker layers miƒôdzy buildami z explicit `--cache-from` source. Je≈õli `requirements.txt` i `package.json` siƒô nie zmieni≈Çy, instalacja dependencies jest skipped = build zajmuje 5-8 minut zamiast 20-25. Mniej compute time = ni≈ºsze koszty Cloud Build (oko≈Ço $0.50-1.00 oszczƒôdno≈õci per build).

---

**Autorzy:** DevOps & Infrastructure Team
**Kontakt:** Slack #infrastructure
**Ostatnia aktualizacja:** 2025-11-03
