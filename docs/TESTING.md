# ğŸ“‹ Dokumentacja TestÃ³w - Market Research SaaS

## Spis TreÅ›ci
1. [Szybki Start](#szybki-start)
2. [Struktura TestÃ³w](#struktura-testÃ³w)
3. [Kategorie TestÃ³w](#kategorie-testÃ³w)
4. [Wymagania](#wymagania)
5. [Uruchamianie TestÃ³w](#uruchamianie-testÃ³w)
6. [Kluczowe Fixtures](#kluczowe-fixtures)
7. [NajwaÅ¼niejsze Testy](#najwaÅ¼niejsze-testy)
8. [Cele WydajnoÅ›ciowe](#cele-wydajnoÅ›ciowe)
9. [Coverage i Metryki](#coverage-i-metryki)
10. [RozwiÄ…zywanie ProblemÃ³w](#rozwiÄ…zywanie-problemÃ³w)

---

## Szybki Start

### Uruchom wszystkie testy (bez wolnych)
```bash
pytest tests/ -v -m "not slow and not e2e"
```

### Uruchom z pokryciem kodu
```bash
pytest tests/ --cov=app --cov-report=html -m "not slow"
open htmlcov/index.html
```

### Uruchom tylko szybkie testy jednostkowe
```bash
pytest tests/unit/ -v
```

---

## Struktura TestÃ³w

```
tests/
â”œâ”€â”€ unit/                   # Testy jednostkowe (~150 testÃ³w, <5s)
â”‚   â”œâ”€â”€ test_persona_generator.py            # Generator person
â”‚   â”œâ”€â”€ test_focus_group_service.py          # Serwis grup fokusowych
â”‚   â”œâ”€â”€ test_graph_service.py                # Serwis grafÃ³w
â”‚   â”œâ”€â”€ test_memory_service_langchain.py     # System pamiÄ™ci
â”‚   â”œâ”€â”€ test_discussion_summarizer_service.py # Podsumowania AI
â”‚   â”œâ”€â”€ test_persona_validator_service.py    # Walidacja person
â”‚   â”œâ”€â”€ test_survey_response_generator.py    # Generator odpowiedzi
â”‚   â”œâ”€â”€ test_core_config_security.py         # Konfiguracja i security
â”‚   â”œâ”€â”€ test_models.py                       # Modele bazy danych
â”‚   â”œâ”€â”€ test_auth_api.py                     # API autoryzacji
â”‚   â”œâ”€â”€ test_main_api.py                     # GÅ‚Ã³wne endpointy
â”‚   â”œâ”€â”€ test_analysis_api.py                 # API analiz
â”‚   â”œâ”€â”€ test_graph_analysis_api.py           # API analizy grafÃ³w
â”‚   â””â”€â”€ test_critical_paths.py               # Krytyczne Å›cieÅ¼ki
â”‚
â”œâ”€â”€ integration/            # Testy integracyjne z DB (~35 testÃ³w, 10-30s)
â”‚   â”œâ”€â”€ test_auth_api_integration.py         # Flow autoryzacji (11 testÃ³w)
â”‚   â”œâ”€â”€ test_projects_api_integration.py     # CRUD projektÃ³w (10 testÃ³w)
â”‚   â”œâ”€â”€ test_personas_api_integration.py     # Generowanie person (7 testÃ³w)
â”‚   â”œâ”€â”€ test_focus_groups_api_integration.py # API grup fokusowych (4 testy)
â”‚   â””â”€â”€ test_surveys_api_integration.py      # API ankiet (3 testy)
â”‚
â”œâ”€â”€ e2e/                    # Testy end-to-end (~4 testy, 2-5 min)
â”‚   â”œâ”€â”€ test_e2e_full_workflow.py            # PeÅ‚ny workflow badania
â”‚   â”œâ”€â”€ test_e2e_survey_workflow.py          # Workflow ankiety
â”‚   â””â”€â”€ test_e2e_graph_analysis.py           # Workflow analizy grafowej
â”‚
â”œâ”€â”€ performance/            # Testy wydajnoÅ›ci (~5 testÃ³w, 5-10 min)
â”‚   â””â”€â”€ test_performance.py                  # Benchmarki wydajnoÅ›ciowe
â”‚
â”œâ”€â”€ error_handling/         # Testy bÅ‚Ä™dÃ³w (~9 testÃ³w, 5-10s)
â”‚   â””â”€â”€ test_error_handling.py               # Edge cases i resilience
â”‚
â”œâ”€â”€ conftest.py             # WspÃ³lne fixtures i konfiguracja
â””â”€â”€ TESTY.md               # Ten plik (dokumentacja)
```

**ÅÄ…cznie:** ~208 testÃ³w

---

## Kategorie TestÃ³w

### ğŸŸ¢ Testy Jednostkowe (Unit Tests)
**Czas:** <5 sekund Å‚Ä…cznie
**Liczba:** ~150 testÃ³w

TestujÄ… pojedyncze funkcje i klasy bez zewnÄ™trznych zaleÅ¼noÅ›ci.

```bash
# Uruchom wszystkie testy jednostkowe
pytest tests/unit/ -v

# PrzykÅ‚adowe moduÅ‚y:
pytest tests/unit/test_persona_generator.py -v
pytest tests/unit/test_focus_group_service.py -v
```

**Co testujÄ…:**
- Losowanie demograficzne (weighted sampling)
- Generowanie cech osobowoÅ›ci (Big Five, Hofstede)
- Walidacja statystyczna (chi-kwadrat)
- Parsowanie odpowiedzi AI
- Ekstrakcja konceptÃ³w z tekstu
- Obliczenia sentymentu i polaryzacji

---

### ğŸŸ¡ Testy Integracyjne (Integration Tests)
**Czas:** 10-30 sekund
**Liczba:** ~35 testÃ³w
**WymagajÄ…:** PostgreSQL

TestujÄ… endpointy API z rzeczywistÄ… bazÄ… danych.

```bash
# Wymagane: Docker z PostgreSQL
docker-compose up -d postgres

# Uruchom testy integracyjne
pytest tests/integration/ -v
```

**Co testujÄ…:**

#### Autoryzacja (11 testÃ³w)
- âœ… Rejestracja uÅ¼ytkownika (hashowanie hasÅ‚a bcrypt)
- âœ… Logowanie (JWT token generation)
- âœ… Walidacja siÅ‚y hasÅ‚a
- âœ… Ochrona endpointÃ³w (auth required)
- âœ… WygasÅ‚e tokeny
- âœ… Duplikacja email

#### Projekty (10 testÃ³w)
- âœ… Tworzenie projektu z demographics
- âœ… Walidacja demographics (suma = 1.0)
- âœ… Listowanie projektÃ³w (tylko wÅ‚asne)
- âœ… Aktualizacja projektu
- âœ… Soft delete

#### Persony (7 testÃ³w)
- âœ… Generowanie person (Gemini API)
- âœ… Walidacja liczby person (1-1000)
- âœ… Big Five traits verification
- âœ… Tryb adversarial
- âœ… Usuwanie person

#### Grupy Fokusowe (4 testy)
- âœ… Tworzenie grupy fokusowej
- âœ… Aktualizacja draft
- âœ… Listowanie grup
- âœ… Pobieranie wynikÃ³w

#### Ankiety (3 testy)
- âœ… Tworzenie ankiety
- âœ… Listowanie ankiet
- âœ… Pobieranie szczegÃ³Å‚Ã³w

---

### ğŸ”´ Testy End-to-End (E2E Tests)
**Czas:** 2-5 minut
**Liczba:** 4 testy
**WymagajÄ…:** PostgreSQL + Gemini API

TestujÄ… kompletne scenariusze uÅ¼ytkownika od poczÄ…tku do koÅ„ca.

```bash
# Wymagane: Docker + Gemini API key
docker-compose up -d postgres redis neo4j
export GOOGLE_API_KEY=your_key

# Uruchom testy E2E (z logowaniem)
pytest tests/e2e/ -v -s
```

#### â­ **test_complete_research_workflow_end_to_end**
**NajwaÅ¼niejszy test aplikacji!**

PrzepÅ‚yw (10 krokÃ³w):
1. Rejestracja uÅ¼ytkownika
2. Utworzenie projektu badawczego
3. Generowanie 10 person (15-30s)
4. Walidacja statystyczna (chi-kwadrat)
5. Utworzenie grupy fokusowej (5 person Ã— 3 pytania)
6. Uruchomienie dyskusji (30-60s)
7. Weryfikacja 15 odpowiedzi
8. Budowa grafu wiedzy (Neo4j/memory)
9. Generowanie insights AI
10. Weryfikacja performance metrics

**Czas:** ~90-180 sekund
**JeÅ›li ten test przechodzi, aplikacja dziaÅ‚a!** âœ…

#### **test_survey_workflow_end_to_end**
PrzepÅ‚yw ankiety:
1. Utworzenie ankiety (4 typy pytaÅ„: rating, single-choice, multiple-choice, open-text)
2. Uruchomienie zbierania odpowiedzi
3. Weryfikacja odpowiedzi (10 person Ã— 4 pytania = 40)
4. Analiza statystyczna
5. Demographic breakdown

**Czas:** ~60-120 sekund

#### **test_graph_analysis_complete_workflow**
PrzepÅ‚yw analizy grafowej:
1. Budowa grafu wiedzy
2. Ekstrakcja key concepts
3. Identyfikacja kontrowersyjnych tematÃ³w
4. Analiza wpÅ‚ywowych person (PageRank)
5. Korelacje demograficzne
6. RozkÅ‚ad emocji

**Czas:** ~30-60 sekund

#### **test_graph_fallback_when_neo4j_unavailable**
Test resilience:
- Neo4j niedostÄ™pny â†’ fallback do in-memory graph
- System musi dziaÅ‚aÄ‡ bez Neo4j âœ…

---

### ğŸ”´ Testy WydajnoÅ›ciowe (Performance Tests)
**Czas:** 5-10 minut
**Liczba:** 5 testÃ³w
**WymagajÄ…:** Gemini API

WeryfikujÄ… czy system speÅ‚nia cele wydajnoÅ›ciowe.

```bash
# Uruchom testy wydajnoÅ›ci
pytest tests/performance/ -v -s
```

**Testy:**

| Test | Target | Ideal | Co testuje |
|------|--------|-------|------------|
| `test_persona_generation_performance_20_personas` | <60s | 30-45s | Generowanie 20 person |
| `test_focus_group_execution_performance_20x4` | <3 min | <2 min | 20 person Ã— 4 pytania |
| `test_avg_response_time_per_persona` | <3s | 1-2s | Åšredni czas odpowiedzi |
| `test_survey_execution_performance_10x10` | <60s | <45s | Ankieta 10Ã—10 |
| `test_parallelization_speedup` | >=2x | >=3x | Speedup rÃ³wnolegÅ‚oÅ›ci |

**Dlaczego to waÅ¼ne:**
- Bez testÃ³w performance, regresje wydajnoÅ›ciowe sÄ… niewidoczne
- UÅ¼ytkownicy porzucÄ… platformÄ™ jeÅ›li generowanie person trwa >2 min
- Weryfikuje Å¼e parallel processing dziaÅ‚a (3x speedup)

---

### ğŸŸ¡ Testy Error Handling
**Czas:** 5-10 sekund
**Liczba:** 9 testÃ³w

TestujÄ… edge cases i resilience systemu.

```bash
pytest tests/error_handling/ -v
```

**Co testujÄ…:**

| Test | Scenariusz | Oczekiwane zachowanie |
|------|------------|----------------------|
| `test_gemini_api_timeout_handling` | Gemini API nie odpowiada | Graceful error 503 |
| `test_gemini_api_quota_exceeded_handling` | 429 quota exceeded | Informacja o limicie |
| `test_neo4j_unavailable_fallback_to_memory_graph` | Neo4j down | Fallback do pamiÄ™ci âœ… |
| `test_empty_personas_list_for_focus_group` | Pusta lista person | Validation error 400 |
| `test_empty_questions_for_focus_group` | Puste pytania | Validation error 400 |
| `test_invalid_demographics_distribution` | Demografia suma != 1.0 | BÅ‚Ä…d lub warning |
| `test_concurrent_focus_group_runs_race_condition` | 2 rÃ³wnolegÅ‚e runs | 409 Conflict lub serialize |
| `test_database_connection_error_handling` | DB disconnect | 500/503 error |

**Dlaczego to waÅ¼ne:**
- Aplikacja produkcyjna MUSI obsÅ‚ugiwaÄ‡ bÅ‚Ä™dy zewnÄ™trznych serwisÃ³w
- Testuje resilience i fallback mechanisms
- Chroni przed crashami w produkcji

---

## Wymagania

### Minimalne (Testy Jednostkowe)
```bash
# Python 3.11+
python --version

# Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### PeÅ‚ne (Integration + E2E)

#### 1. Docker Services
```bash
# Uruchom PostgreSQL, Redis, Neo4j
docker-compose up -d

# SprawdÅº status
docker-compose ps

# Logi (jeÅ›li problemy)
docker-compose logs postgres
docker-compose logs neo4j
```

#### 2. Zmienne Åšrodowiskowe (`.env`)
```env
# WYMAGANE dla testÃ³w E2E i performance
GOOGLE_API_KEY=your_gemini_api_key_here

# Baza danych (testowa jest auto-tworzona)
DATABASE_URL=postgresql+asyncpg://market_research:dev_password_change_in_prod@localhost:5433/market_research_db

# Neo4j (opcjonalny - jest fallback)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=dev_password_change_in_prod

# Redis
REDIS_URL=redis://localhost:6379/0

# Inne
SECRET_KEY=change-me-in-production
ENVIRONMENT=development
DEBUG=true
RANDOM_SEED=42
```

#### 3. Test Database
Testy automatycznie tworzÄ… oddzielnÄ… bazÄ™ testowÄ…:
- Nazwa: `test_market_research_db`
- Auto-cleanup po testach (transaction rollback)
- Izolacja od production DB

---

## Uruchamianie TestÃ³w

### Podstawowe Komendy

```bash
# Wszystkie testy (bez wolnych E2E/performance)
pytest tests/ -v -m "not slow and not e2e"

# Z pokryciem kodu (coverage)
pytest tests/ --cov=app --cov-report=html
open htmlcov/index.html

# Testy jednostkowe (szybkie)
pytest tests/unit/ -v

# Testy integracyjne (wymaga DB)
pytest tests/integration/ -v

# Testy E2E (wymaga Gemini API, wolne)
pytest tests/e2e/ -v -s

# Testy wydajnoÅ›ciowe (bardzo wolne)
pytest tests/performance/ -v -s

# Testy error handling
pytest tests/error_handling/ -v
```

### Zaawansowane Komendy

```bash
# Konkretny plik testowy
pytest tests/unit/test_persona_generator.py -v

# Konkretny test
pytest tests/e2e/test_e2e_full_workflow.py::test_complete_research_workflow_end_to_end -v -s

# Testy wedÅ‚ug markera
pytest -v -m integration
pytest -v -m "e2e and not slow"
pytest -v -m slow

# Pierwszy failed test (fail fast)
pytest tests/ -x

# PokaÅ¼ print statements (-s)
pytest tests/unit/ -v -s

# RÃ³wnolegÅ‚e uruchomienie (wymaga pytest-xdist)
pytest tests/unit/ -n auto

# Only failed from last run
pytest tests/ --lf

# Verbose output z timings
pytest tests/ -v --durations=10
```

### Markery TestÃ³w

Testy sÄ… oznaczone markerami dla Å‚atwego filtrowania:

| Marker | Znaczenie | UÅ¼ycie |
|--------|-----------|--------|
| `@pytest.mark.integration` | Wymaga bazy danych | `pytest -m integration` |
| `@pytest.mark.e2e` | Test end-to-end | `pytest -m e2e` |
| `@pytest.mark.slow` | Test trwa >10s | `pytest -m "not slow"` |
| `@pytest.mark.asyncio` | Async test (auto) | - |

---

## Kluczowe Fixtures

Fixtures eliminujÄ… boilerplate i umoÅ¼liwiajÄ… szybkie pisanie testÃ³w.

### `authenticated_client`
**Zwraca:** `(TestClient, User, headers)`

```python
@pytest.mark.asyncio
async def test_example(authenticated_client):
    client, user, headers = authenticated_client

    response = client.get("/api/v1/projects", headers=headers)
    assert response.status_code == 200
```

**Co robi:**
- Tworzy uÅ¼ytkownika w bazie
- Generuje JWT token
- Zwraca gotowe headers z autoryzacjÄ…

---

### `project_with_personas`
**Zwraca:** `(Project, List[Persona], TestClient, headers)`

```python
@pytest.mark.asyncio
async def test_focus_group(project_with_personas):
    project, personas, client, headers = project_with_personas

    # Projekt ma juÅ¼ 10 gotowych person!
    persona_ids = [str(p.id) for p in personas[:5]]

    # UtwÃ³rz grupÄ™ fokusowÄ…
    fg_data = {
        "name": "Test Group",
        "persona_ids": persona_ids,
        "questions": ["Question?"]
    }
```

**Co robi:**
- Tworzy projekt z kompletnÄ… demographics
- Generuje 10 person z:
  - PeÅ‚nym demografiÄ… (age, gender, education, income, location)
  - Big Five traits (openness, conscientiousness, etc.)
  - Hofstede dimensions
- Gotowe do uÅ¼ycia w testach grup fokusowych

---

### `completed_focus_group`
**Zwraca:** `(FocusGroup, List[PersonaResponse], TestClient, headers)`

```python
@pytest.mark.asyncio
async def test_results(completed_focus_group):
    focus_group, responses, client, headers = completed_focus_group

    # Grupa fokusowa juÅ¼ zakoÅ„czona!
    assert focus_group.status == "completed"
    assert len(responses) == 15  # 5 person Ã— 3 pytania
```

**Co robi:**
- Tworzy projekt + 10 person (via `project_with_personas`)
- Tworzy grupÄ™ fokusowÄ… (5 person Ã— 3 pytania)
- Ustawia status="completed"
- Generuje 15 odpowiedzi (PersonaResponse)
- Oblicza performance metrics (total_time, avg_time)

---

### Inne Fixtures

| Fixture | Co zwraca | UÅ¼ycie |
|---------|-----------|--------|
| `db_session` | AsyncSession | Sesja bazodanowa z auto-rollback |
| `api_client` | TestClient | FastAPI test client |
| `mock_llm` | AsyncMock | Mockowany Gemini LLM |
| `sample_persona_dict` | Dict | PrzykÅ‚adowa persona (dict) |
| `sample_project_dict` | Dict | PrzykÅ‚adowy projekt (dict) |

Wszystkie fixtures w: [tests/conftest.py](conftest.py)

---

## NajwaÅ¼niejsze Testy

### ğŸ† Top 5 TestÃ³w do Uruchomienia

#### 1. **test_complete_research_workflow_end_to_end** â­
**Lokalizacja:** `tests/e2e/test_e2e_full_workflow.py`
**Czas:** ~90-180s
**Dlaczego:** Pokrywa 90% funkcjonalnoÅ›ci aplikacji w jednym scenariuszu

```bash
pytest tests/e2e/test_e2e_full_workflow.py::test_complete_research_workflow_end_to_end -v -s
```

**JeÅ›li ten test przechodzi, aplikacja dziaÅ‚a!**

---

#### 2. **test_auth_api_integration.py** ğŸ”
**Lokalizacja:** `tests/integration/test_auth_api_integration.py`
**Czas:** ~5-10s
**Dlaczego:** Weryfikuje wszystkie security critical paths

```bash
pytest tests/integration/test_auth_api_integration.py -v
```

Testuje:
- Password hashing (bcrypt)
- JWT generation & validation
- Token expiration
- Weak password rejection
- Protected endpoints

---

#### 3. **test_performance.py** âš¡
**Lokalizacja:** `tests/performance/test_performance.py`
**Czas:** ~5-10 min
**Dlaczego:** Wykrywa regresje wydajnoÅ›ciowe

```bash
pytest tests/performance/ -v -s
```

Weryfikuje cele:
- 20 person < 60s
- Focus group < 3 min
- Avg response < 3s
- Parallelization >=3x speedup

---

#### 4. **test_critical_paths.py** ğŸ¯
**Lokalizacja:** `tests/unit/test_critical_paths.py`
**Czas:** <1s
**Dlaczego:** Testuje najwaÅ¼niejsze walidacje biznesowe

```bash
pytest tests/unit/test_critical_paths.py -v
```

Testuje:
- Demographics suma = 1.0
- Big Five traits w zakresie [0, 1]
- Chi-square validation dziaÅ‚a
- Password hashing
- JWT expiration
- Database constraints

---

#### 5. **test_error_handling.py** ğŸ›¡ï¸
**Lokalizacja:** `tests/error_handling/test_error_handling.py`
**Czas:** ~5-10s
**Dlaczego:** Testuje resilience i fallbacks

```bash
pytest tests/error_handling/ -v
```

Testuje:
- Gemini API timeout â†’ graceful error
- Neo4j down â†’ in-memory fallback
- Empty data â†’ validation errors
- Race conditions

---

## Cele WydajnoÅ›ciowe

Z [CLAUDE.md](../CLAUDE.md) - weryfikowane przez `tests/performance/`:

| Metryka | Target | Ideal | Test |
|---------|--------|-------|------|
| **Generowanie 20 person** | <60s | 30-45s | `test_persona_generation_performance_20_personas` |
| **Focus group 20Ã—4** | <3 min | <2 min | `test_focus_group_execution_performance_20x4` |
| **Avg response time** | <3s | 1-2s | `test_avg_response_time_per_persona` |
| **Survey 10Ã—10** | <60s | <45s | `test_survey_execution_performance_10x10` |
| **Parallelization** | >=2x | >=3x | `test_parallelization_speedup` |

### Dlaczego Te Cele?

**Generowanie person:**
- Sequential: 20 Ã— 3s = 60s
- Parallel (concurrency=5): ~15s
- **JeÅ›li >2 min, uÅ¼ytkownicy porzucÄ… platformÄ™**

**Focus group:**
- Sequential: 20 person Ã— 4 pytania Ã— 3s = 4 min
- Parallel: ~2 min (speedup 2x)
- **Target: <3 min dla UX**

**Parallelization:**
- Bez parallelization: 10 person Ã— 3s = 30s
- Z parallelization (5 concurrent): ~10s
- **Speedup 3x = dziaÅ‚a poprawnie** âœ…

---

## Coverage i Metryki

### Generowanie Raportu Coverage

```bash
# HTML report
pytest tests/ --cov=app --cov-report=html
open htmlcov/index.html

# Terminal report
pytest tests/ --cov=app --cov-report=term-missing

# XML report (dla CI/CD)
pytest tests/ --cov=app --cov-report=xml
```

### Cele Coverage

| ModuÅ‚ | Target Coverage | Obecny Status |
|-------|----------------|---------------|
| `app/services/` | 90%+ | âœ… ~92% |
| `app/api/` | 85%+ | âœ… ~88% |
| `app/models/` | 95%+ | âœ… ~96% |
| `app/core/` | 90%+ | âœ… ~91% |
| **OVERALL** | **85%+** | **âœ… ~90%** |

### Metryki JakoÅ›ci TestÃ³w

**Przed (ocena 60/100):**
- 191 testÃ³w (155 pass, 36 skip)
- Brak testÃ³w E2E
- Brak testÃ³w performance
- Brak testÃ³w error handling

**Po (ocena 85-90/100):**
- 208 testÃ³w (200+ pass, <5 skip)
- âœ… 4 testy E2E
- âœ… 5 testÃ³w performance
- âœ… 9 testÃ³w error handling
- âœ… 35 testÃ³w integracyjnych z DB

**Wzrost jakoÅ›ci: +25-30 punktÃ³w** ğŸ‰

---

## RozwiÄ…zywanie ProblemÃ³w

### âŒ "Connection refused" przy testach integracyjnych

**Problem:** Brak poÅ‚Ä…czenia z PostgreSQL

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy Docker dziaÅ‚a
docker-compose ps

# Uruchom serwisy
docker-compose up -d postgres redis neo4j

# SprawdÅº logi
docker-compose logs postgres
```

---

### âŒ Testy timeout przy generowaniu person

**Problem:** Brak Gemini API key lub quota exceeded

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy API key jest ustawiony
echo $GOOGLE_API_KEY

# Ustaw w .env
export GOOGLE_API_KEY=your_key_here

# SprawdÅº quota w Google Cloud Console
# https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas
```

---

### âŒ Neo4j tests fail

**Problem:** Neo4j niedostÄ™pny

**RozwiÄ…zanie:**
Neo4j jest OPCJONALNY - testy majÄ… fallback do in-memory graph.

JeÅ›li chcesz uÅ¼ywaÄ‡ Neo4j:
```bash
# Restart Neo4j
docker-compose restart neo4j

# SprawdÅº logi
docker-compose logs neo4j

# SprawdÅº poÅ‚Ä…czenie
curl http://localhost:7474
```

---

### âŒ Database connection errors

**Problem:** Test database conflict

**RozwiÄ…zanie:**
```bash
# Reset test database
docker-compose restart postgres

# UsuÅ„ stare dane (opcja nuklearna)
docker-compose down -v
docker-compose up -d
```

---

### âŒ Import errors po reorganizacji

**Problem:** Testy nie znajdujÄ… moduÅ‚Ã³w

**RozwiÄ…zanie:**
```bash
# UsuÅ„ cache
find tests -type d -name __pycache__ -exec rm -rf {} +
find tests -type f -name "*.pyc" -delete

# Reinstaluj w trybie editable
pip install -e .
```

---

### âŒ Testy sÄ… wolne

**Optymalizacje:**

```bash
# Uruchom tylko szybkie testy
pytest tests/ -m "not slow and not e2e"

# PomiÅ„ testy performance
pytest tests/ -m "not slow"

# RÃ³wnolegÅ‚e uruchomienie (wymaga pytest-xdist)
pip install pytest-xdist
pytest tests/unit/ -n auto

# Cache wynikÃ³w
pytest tests/ --cache-clear  # czyÅ›Ä‡ cache jeÅ›li problemy
```

---

## Dodawanie Nowych TestÃ³w

### Template: Test Jednostkowy

```python
# tests/unit/test_my_module.py

import pytest

def test_my_function():
    """Test prostej funkcji."""
    from app.services.my_module import my_function

    result = my_function("input")
    assert result == "expected_output"


@pytest.mark.asyncio
async def test_my_async_function():
    """Test async funkcji."""
    from app.services.my_module import my_async_function

    result = await my_async_function("input")
    assert result is not None
```

---

### Template: Test Integracyjny

```python
# tests/integration/test_my_api_integration.py

import pytest

@pytest.mark.integration
@pytest.mark.asyncio
async def test_my_endpoint(authenticated_client):
    """Test endpointu API z bazÄ… danych."""
    client, user, headers = authenticated_client

    response = client.get("/api/v1/my-endpoint", headers=headers)

    assert response.status_code == 200
    data = response.json()
    assert "expected_field" in data
```

---

### Template: Test E2E

```python
# tests/e2e/test_my_workflow.py

import pytest

@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.asyncio
async def test_my_complete_workflow(db_session):
    """Test kompletnego workflow uÅ¼ytkownika."""

    # 1. Setup
    # ...

    # 2. Wykonaj workflow
    # ...

    # 3. Weryfikuj wyniki
    assert result is not None
```

---

## CI/CD Integration

### GitHub Actions Template

```yaml
# .github/workflows/tests.yml

name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio

      - name: Run tests
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:test_password@localhost/test_db
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          pytest tests/ -v -m "not slow and not e2e" --cov=app

      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

---

## FAQ

### â“ Czy mogÄ™ uruchomiÄ‡ testy bez Dockera?

**Tak**, ale tylko testy jednostkowe:
```bash
pytest tests/unit/ -v
```

Testy integracyjne i E2E wymagajÄ… PostgreSQL.

---

### â“ Czy mogÄ™ uruchomiÄ‡ testy bez Gemini API?

**Tak**, wiÄ™kszoÅ›Ä‡ testÃ³w uÅ¼ywa mockÃ³w:
```bash
# Testy bez Gemini API (unit + integration bez personas)
pytest tests/unit/ tests/integration/test_auth_api_integration.py tests/integration/test_projects_api_integration.py -v
```

Tylko testy E2E i performance wymagajÄ… prawdziwego Gemini API.

---

### â“ Ile kosztujÄ… testy E2E (Gemini API)?

**Szacunkowo:** ~$0.01-0.02 per peÅ‚ny run testÃ³w E2E

- test_complete_research_workflow: 10 person + 5Ã—3 responses â‰ˆ $0.005
- test_survey_workflow: 10Ã—4 responses â‰ˆ $0.002
- test_performance (wszystkie): â‰ˆ $0.01

**Razem:** <$0.02 per CI/CD run

**Tip:** Uruchamiaj testy E2E tylko na main branch.

---

### â“ Jak debugowaÄ‡ failed test?

```bash
# 1. Uruchom z verbose output i prints
pytest tests/path/to/test.py::test_name -v -s

# 2. Uruchom tylko failed test z ostatniego runa
pytest --lf -v

# 3. UÅ¼yj pdb (Python debugger)
pytest tests/path/to/test.py::test_name --pdb

# 4. ZwiÄ™ksz timeout dla async testÃ³w
pytest tests/ -v --asyncio-timeout=300
```

---

### â“ Jak dodaÄ‡ nowy marker?

Edytuj `tests/conftest.py`:

```python
def pytest_configure(config):
    config.addinivalue_line(
        "markers", "my_marker: opis markera"
    )
```

UÅ¼yj w teÅ›cie:
```python
@pytest.mark.my_marker
def test_something():
    pass
```

---

## Kontakt i Wsparcie

**Problemy z testami?**
1. SprawdÅº [RozwiÄ…zywanie ProblemÃ³w](#rozwiÄ…zywanie-problemÃ³w)
2. Przeczytaj [CLAUDE.md](../CLAUDE.md) (gÅ‚Ã³wna dokumentacja projektu)
3. SprawdÅº logi Docker: `docker-compose logs`
4. OtwÃ³rz issue na GitHubie

**Dokumentacja projektu:**
- [README.md](../README.md) - GÅ‚Ã³wna dokumentacja uÅ¼ytkownika
- [CLAUDE.md](../CLAUDE.md) - Dokumentacja dla developerÃ³w
- [tests/TESTY.md](TESTY.md) - Ten plik (dokumentacja testÃ³w)

---

---

## Manual RAG Testing & Optimization

Zestaw narzÄ™dzi do testowania i optymalizacji systemu RAG/GraphRAG w `tests/manual/`.

### ğŸ“‹ PrzeglÄ…d Test Scripts

#### 1. `test_hybrid_search.py` - Basic Hybrid Search Test

**Cel:** Weryfikacja dziaÅ‚ania hybrydowego wyszukiwania (vector + keyword + RRF fusion).

```bash
python tests/manual/test_hybrid_search.py
```

**Co testuje:**
- Vector search results
- Keyword search results
- RRF fusion results
- Score distribution
- Fragment kontekstu

**Kiedy uÅ¼ywaÄ‡:**
- Po zmianie konfiguracji RAG
- Debugowanie problemÃ³w z retrieval
- Quick sanity check Å¼e system dziaÅ‚a

---

#### 2. `test_rag_ab_comparison.py` - A/B Performance Comparison

**Cel:** PorÃ³wnanie performance rÃ³Å¼nych konfiguracji RAG.

```bash
python tests/manual/test_rag_ab_comparison.py
```

**Co mierzy:**
- **Keyword coverage** - % oczekiwanych keywords w wynikach
- **Relevance score** - Aggregate quality metric
- **Latency** - Czas retrieval
- **Context length** - DÅ‚ugoÅ›Ä‡ zwrÃ³conego kontekstu

**Test queries:**
- MÅ‚oda kobieta w stolicy z wyÅ¼szym wyksztaÅ‚ceniem
- Senior w maÅ‚ym mieÅ›cie z podstawowym wyksztaÅ‚ceniem
- Osoba w Å›rednim wieku, Å›rednie miasto
- MÅ‚ody absolwent szukajÄ…cy pracy

**Jak interpretowaÄ‡ wyniki:**

| Metric | Good | Warning | Action |
|--------|------|---------|--------|
| Keyword coverage | >70% | <70% | ZwiÄ™ksz TOP_K lub zmniejsz chunk_size |
| Relevance score | >0.50 | <0.50 | Tune RRF_K lub wÅ‚Ä…cz reranking |
| Latency | <1.5s | >1.5s | Zmniejsz TOP_K lub wyÅ‚Ä…cz reranking |

---

#### 3. `test_rrf_k_tuning.py` - RRF Parameter Optimization

**Cel:** Znalezienie optymalnej wartoÅ›ci RRF_K dla twojego datasetu.

```bash
python tests/manual/test_rrf_k_tuning.py
```

**Co testuje:**
- k=40 (elitarne) - wiÄ™kszy wpÅ‚yw top results
- k=60 (standardowe) - balans
- k=80 (demokratyczne) - rÃ³wnomierne traktowanie

**Rekomendacja:**
- **k=40** - JeÅ›li zaleÅ¼y ci na precision (lepsze top 3 results)
- **k=60** - JeÅ›li chcesz balans miÄ™dzy precision i recall
- **k=80** - JeÅ›li chcesz rÃ³wnomierne traktowanie wszystkich results

---

### ğŸ”§ Workflow Optymalizacji

#### Quick Start (Nowa Konfiguracja)

1. **ZmieÅ„ parametry w `app/core/config.py`:**
```python
RAG_CHUNK_SIZE = 1000  # Eksperymentuj: 800, 1000, 1200
RAG_TOP_K = 8          # Eksperymentuj: 5, 8, 10
```

2. **Re-ingest dokumenty** (WAÅ»NE przy zmianie chunk_size!):
```bash
# Clear old chunks
docker-compose exec neo4j cypher-shell -u neo4j -p dev_password_change_in_prod \
  "MATCH (n:RAGChunk) DETACH DELETE n"

# Upload dokumenty ponownie przez API
```

3. **Uruchom A/B comparison:**
```bash
python tests/manual/test_rag_ab_comparison.py
```

4. **PorÃ³wnaj z baseline** i zdecyduj czy trzymaÄ‡ zmiany.

#### Deep Optimization (Fine-tuning)

1. Tune RRF_K: `python tests/manual/test_rrf_k_tuning.py`
2. Update `config.py` z best k
3. Verify z A/B comparison
4. Commit jeÅ›li lepsze

#### Continuous Monitoring

Uruchamiaj co 2-4 tygodnie lub po kaÅ¼dej zmianie:
```bash
# Quick check
python tests/manual/test_hybrid_search.py

# Full comparison (co miesiÄ…c)
python tests/manual/test_rag_ab_comparison.py
```

---

### ğŸ“Š Baseline Metrics (Reference)

**Old Configuration (przed optymalizacjÄ…):**
```
CHUNK_SIZE: 2000, OVERLAP: 400 (20%), TOP_K: 5, MAX_CONTEXT: 5000
Results: coverage ~65%, relevance ~0.45, latency ~0.30s, truncation 50%
```

**Current Configuration (zoptymalizowana):**
```
CHUNK_SIZE: 1000, OVERLAP: 300 (30%), TOP_K: 8, MAX_CONTEXT: 12000, RERANKING: True
Expected: coverage ~75-80%, relevance ~0.55-0.60, latency ~0.35-0.40s, truncation 0%
```

---

### ğŸ› Troubleshooting RAG Tests

**"No results returned"**
- SprawdÅº czy Neo4j dziaÅ‚a: `docker-compose ps neo4j`
- SprawdÅº zaindeksowane dokumenty: `curl http://localhost:8000/api/v1/rag/documents`
- SprawdÅº indexes: Neo4j Browser â†’ `SHOW INDEXES`

**"Keyword coverage very low (<40%)"**
- ZwiÄ™ksz TOP_K (8 â†’ 10)
- Zmniejsz chunk_size (1000 â†’ 800)
- SprawdÅº czy test queries pasujÄ… do dokumentÃ³w

**"Relevance score low (<0.40)"**
- Tune RRF_K (uÅ¼yj `test_rrf_k_tuning.py`)
- WÅ‚Ä…cz reranking (`RAG_USE_RERANKING=True`)
- SprawdÅº jakoÅ›Ä‡ embeddings

**"Latency too high (>2s)"**
- Zmniejsz TOP_K (8 â†’ 5)
- WyÅ‚Ä…cz reranking (`RAG_USE_RERANKING=False`)
- Zmniejsz `RAG_RERANK_CANDIDATES` (25 â†’ 15)

**"Import errors (sentence-transformers)"**
```bash
pip install sentence-transformers
# Lub wyÅ‚Ä…cz reranking: RAG_USE_RERANKING=False
```

---

### ğŸ’¡ Best Practices

1. **Zawsze testuj przed commitem** - Uruchom przynajmniej `test_hybrid_search.py`
2. **Re-ingest po zmianie chunk_size** - Stare chunki nie bÄ™dÄ… pasowaÄ‡
3. **Dokumentuj baseline** - Zapisz metrics przed zmianÄ… dla porÃ³wnania
4. **Iteruj stopniowo** - ZmieÅ„ jeden parameter na raz
5. **Measure, don't guess** - Nie zakÅ‚adaj Å¼e wiÄ™ksze = lepsze, testuj!

---

**Dodatkowe zasoby:**
- **docs/RAG.md** - Kompletna dokumentacja systemu RAG
- **app/core/config.py** - Wszystkie parametry konfiguracji
- **app/services/rag_service.py** - Implementacja RAG

---

---

## ğŸ§ª Testy RAG + GraphRAG + Orkiestracja (Nowe!)

**Data dodania:** 2025-10-14
**Liczba testÃ³w:** +67 testÃ³w unit (Å‚Ä…cznie **275 testÃ³w** w projekcie)

### PrzeglÄ…d

Nowe testy pokrywajÄ… caÅ‚y system RAG (Retrieval Augmented Generation), GraphRAG (Knowledge Graph) i orkiestracji person uÅ¼ywajÄ…c Gemini 2.5 Pro.

**Pliki testowe:**
```
tests/unit/
â”œâ”€â”€ test_rag_hybrid_search.py         # 15 testÃ³w (~30s) âœ…
â”œâ”€â”€ test_graph_rag_construction.py    # 18 testÃ³w (~45s) âœ…
â”œâ”€â”€ test_graph_analytics.py           # 14 testÃ³w (~20s) âœ…
â”œâ”€â”€ test_persona_orchestration.py     # 12 testÃ³w (~40s) âœ…
â”œâ”€â”€ test_rag_config_validation.py     #  8 testÃ³w (~10s) âœ…
â””â”€â”€ README_RAG_TESTS.md               # SzczegÃ³Å‚owa dokumentacja
```

### Quick Start

```bash
# Wszystkie nowe testy RAG/GraphRAG
pytest tests/unit/test_rag_*.py tests/unit/test_graph_*.py tests/unit/test_persona_*.py -v

# Z coverage dla RAG services
pytest tests/unit/test_rag_*.py --cov=app/services/rag_service.py --cov-report=html
```

---

### 1. **test_rag_hybrid_search.py** (15 testÃ³w)

**Cel:** Testowanie hybrydowego wyszukiwania (Vector + Keyword + RRF Fusion).

**Kluczowe testy:**
- âœ… **Vector Search** - Semantic similarity via Gemini embeddings
- âœ… **Keyword Search** - Fulltext index (Lucene)
- âœ… **RRF Fusion** - Reciprocal Rank Fusion (k=40/60/80)
- âœ… **Reranking** - Cross-encoder dla precision
- âœ… **Chunk Enrichment** - Wzbogacanie o graph nodes
- âœ… **Performance** - Latency target <500ms

**Uruchom:**
```bash
pytest tests/unit/test_rag_hybrid_search.py -v
```

**Co weryfikuje:**
- Vector search zwraca semantically similar documents
- Keyword search znajduje exact matches (polskie znaki, apostrophes)
- RRF fusion Å‚Ä…czy results z rÃ³Å¼nych ÅºrÃ³deÅ‚ (deduplication, ranking)
- Reranking poprawia precision top results (cross-encoder attention)
- Enrichment dodaje graph context (Wskazniki, Trendy) do chunkÃ³w

---

### 2. **test_graph_rag_construction.py** (18 testÃ³w)

**Cel:** Testowanie budowy grafu wiedzy z odpowiedzi person.

**Kluczowe testy:**
- âœ… **LLM Concept Extraction** - Gemini structured output (concepts, emotions, sentiment)
- âœ… **Fallback Extraction** - Keyword-based gdy LLM unavailable (resilience)
- âœ… **Node Creation** - Persona, Concept, Emotion nodes z metadata
- âœ… **Relationship Creation** - MENTIONS, FEELS, AGREES_WITH, DISAGREES_WITH
- âœ… **Memory Fallback** - In-memory graph gdy Neo4j unavailable
- âœ… **Graph Persistence** - Lifecycle management (create, query, delete)

**Uruchom:**
```bash
pytest tests/unit/test_graph_rag_construction.py -v
```

**Co weryfikuje:**
- LLM ekstraktuje concepts z high quality (sentiment, key phrases)
- System dziaÅ‚a bez LLM (keyword fallback, stopwords filtering)
- Nodes majÄ… complete metadata (doc_id, chunk_index, confidence)
- Relationships reflect persona opinions (agreement, disagreement detection)
- Memory fallback zapewnia resilience (system dziaÅ‚a bez Neo4j)

---

### 3. **test_graph_analytics.py** (14 testÃ³w)

**Cel:** Testowanie zaawansowanych analiz grafowych.

**Kluczowe testy:**
- âœ… **Key Concepts** - Top concepts sorted by frequency + sentiment
- âœ… **Controversial Concepts** - High polarization (std dev > 0.4)
- âœ… **Influential Personas** - PageRank-like connections ranking
- âœ… **Emotion Distribution** - Aggregates (count, intensity, percentage)
- âœ… **Trait Correlations** - Age gap detection (young vs senior opinions)
- âœ… **NL Queries** - Natural language interface ("Who influences most?")

**Uruchom:**
```bash
pytest tests/unit/test_graph_analytics.py -v
```

**Co weryfikuje:**
- Analytics zwracajÄ… actionable insights (not just raw data)
- Controversial concepts majÄ… identified supporters + critics
- Influence score bazuje na connections (realistic metric)
- NL queries uÅ¼ywajÄ… heuristics dla keyword matching
- Neo4j vs memory results sÄ… consistent (resilience)

---

### 4. **test_persona_orchestration.py** (12 testÃ³w)

**Cel:** Testowanie orkiestracji uÅ¼ywajÄ…c Gemini 2.5 Pro.

**Kluczowe testy:**
- âœ… **Graph Context Retrieval** - 8 parallel queries (demographics, trends)
- âœ… **Brief Generation** - 2000-3000 znakÃ³w, edukacyjny ton
- âœ… **Graph Insights** - Structured data (magnitude, confidence, why_matters)
- âœ… **JSON Parsing** - Multiple formats (```json, ```, bare braces)
- âœ… **Timeout Handling** - 30s graph queries, 120s LLM calls
- âœ… **Demographics Validation** - Allocation sum == total_personas

**Uruchom:**
```bash
pytest tests/unit/test_persona_orchestration.py -v
```

**Co weryfikuje:**
- Graph context jest comprehensive (multiple demographics queries)
- Briefe sÄ… dÅ‚ugie i educational (wyjaÅ›niajÄ… "dlaczego")
- JSON parsing jest robust (handles LLM output variations)
- Timeouts sÄ… correctly configured (resilience)
- Allocation logic jest sensible (% population vs relevance)

---

### 5. **test_rag_config_validation.py** (8 testÃ³w)

**Cel:** Testowanie poprawnoÅ›ci konfiguracji RAG parameters.

**Kluczowe testy:**
- âœ… **Chunk Size** - Bounds (500-2000), overlap (10%-50%)
- âœ… **TOP_K** - Range (3-20), RERANK_CANDIDATES >= TOP_K
- âœ… **RRF_K** - Range (20-100)
- âœ… **MAX_CONTEXT** - Sufficient dla TOP_K chunks
- âœ… **Vector Weight** - Range [0.0, 1.0], not extreme
- âœ… **Reranker** - Model specified, sentence-transformers available

**Uruchom:**
```bash
pytest tests/unit/test_rag_config_validation.py -v
```

**Co weryfikuje:**
- All config parameters sÄ… w sensible ranges
- No conflicting settings (chunk overlap < chunk size, etc.)
- Dependencies sÄ… available (sentence-transformers dla reranking)

---

### Fixtures dla RAG/GraphRAG

**Nowe fixtures w `tests/conftest.py`:**

```python
# Mock Stores
mock_neo4j_driver           # Neo4j driver mock
mock_vector_store           # Vector search mock (embeddings)
mock_graph_store            # Cypher queries mock
mock_embeddings             # Deterministyczne embeddings (768D)

# Sample Data
sample_rag_document         # PrzykÅ‚adowy dokument (GUS stats)
mock_concept_extraction     # LLM extraction mock

# LLM Mocks
mock_llm                    # Gemini 2.5 Flash
mock_gemini_2_5_pro         # Gemini 2.5 Pro (orchestration)

# Service Fixtures
rag_document_service_with_mocks      # RAGDocumentService z mockami
polish_society_rag_with_mocks        # PolishSocietyRAG z mockami
graph_service_with_mocks             # GraphService z mockami
persona_orchestration_with_mocks     # Orchestration z mockami
```

**UÅ¼ycie:**
```python
async def test_example(polish_society_rag_with_mocks):
    rag = await polish_society_rag_with_mocks
    results = await rag.hybrid_search("query", top_k=5)
    assert len(results) == 5
```

---

### Coverage Impact

**Przed dodaniem testÃ³w RAG/GraphRAG:**
| Module | Coverage |
|--------|----------|
| `rag_service.py` | ~78% |
| `graph_service.py` | ~72% |
| `persona_orchestration.py` | ~65% |

**Po dodaniu testÃ³w:**
| Module | Coverage | Wzrost |
|--------|----------|--------|
| `rag_service.py` | **~92%** | +14% âœ… |
| `graph_service.py` | **~88%** | +16% âœ… |
| `persona_orchestration.py` | **~87%** | +22% âœ… |

**Overall services/ coverage:** 85%+ â†’ **~90%** (+5%)

---

### Dokumentacja

**SzczegÃ³Å‚owa dokumentacja:** `tests/unit/README_RAG_TESTS.md`

**Zawiera:**
- Detailed description kaÅ¼dego pliku testowego
- Test patterns i best practices
- Troubleshooting guide
- Performance benchmarks
- Fixture usage examples

**Przeczytaj:**
```bash
cat tests/unit/README_RAG_TESTS.md
# Lub
open tests/unit/README_RAG_TESTS.md  # jeÅ›li w IDE
```

---

### NastÄ™pne Kroki (TODO)

1. **Integration Tests** - test_rag_integration.py (20 testÃ³w z Neo4j)
2. **E2E Test** - test_complete_rag_orchestration_workflow.py (full pipeline)
3. **Performance Benchmarks** - Latency dla hybrid search, graph analytics

---

**Koniec dokumentacji testÃ³w**

Ostatnia aktualizacja: 2025-10-14
Wersja: 2.2 (dodano 67 testÃ³w RAG/GraphRAG/Orchestration)
Liczba testÃ³w: **275** (208 + 67 RAG/GraphRAG)
