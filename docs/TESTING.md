# ğŸ“‹ Dokumentacja TestÃ³w - Market Research SaaS

## Spis TreÅ›ci
1. [Szybki Start](#szybki-start)
2. [Struktura TestÃ³w](#struktura-testÃ³w)
3. [Kategorie TestÃ³w](#kategorie-testÃ³w)
4. [Wymagania](#wymagania)
5. [Uruchamianie TestÃ³w](#uruchamianie-testÃ³w)
6. [Kluczowe Fixtures](#kluczowe-fixtures)
7. [NajwaÅ¼niejsze Testy](#najwaÅ¼niejsze-testy)
8. [Cele WydajnoÅ›ciowe](#cele-wydajnoÅ›ciowe)
9. [Coverage i Metryki](#coverage-i-metryki)
10. [RozwiÄ…zywanie ProblemÃ³w](#rozwiÄ…zywanie-problemÃ³w)

---

## Szybki Start

> DomyÅ›lnie pomijamy testy oznaczone jako `slow`, `external`, `performance` i `manual`.  
> Aby je wÅ‚Ä…czyÄ‡ uÅ¼yj odpowiednich flag (`--run-slow`, `--run-external`, ...).

### 1. DomyÅ›lny zestaw (CI smoke + unit/integration)
```bash
python -m pytest -v
```

### 2. Raport pokrycia
```bash
python -m pytest -v --cov=app --cov-report=html
open htmlcov/index.html  # macOS
```

### 3. End-to-end smoke (bez usÅ‚ug zewnÄ™trznych)
```bash
python -m pytest tests/e2e/test_e2e_ci_smoke.py -v
```

### 4. PeÅ‚ne testy z usÅ‚ugami zewnÄ™trznymi
```bash
python -m pytest -v --run-slow --run-external
```

---

## Struktura TestÃ³w

```
tests/
â”œâ”€â”€ conftest.py                 # minimalne bootstrapowanie (pytest_plugins = fixtures)
â”œâ”€â”€ fixtures/                   # Modularne fixtury (asyncio_loop, config, api, rag, utils, â€¦)
â”œâ”€â”€ factories/                  # Fabryki danych/payloadÃ³w (project_payload, focus_group_payload, â€¦)
â”œâ”€â”€ unit/                       # Testy jednostkowe (~240 testÃ³w, <10s)
â”œâ”€â”€ integration/                # Testy HTTP + DB (~70 testÃ³w, 20-40s)
â”œâ”€â”€ e2e/                        # Scenariusze end-to-end (w tym smoke i testy wymagajÄ…ce API)
â”œâ”€â”€ performance/                # Benchmarki wydajnoÅ›ci (wolne, opt-in)
â”œâ”€â”€ error_handling/             # Testy odpornoÅ›ci na awarie
â”œâ”€â”€ manual/                     # Skrypty diagnostyczne (uruchamiane rÄ™cznie, oznaczone markerem `manual`)
â””â”€â”€ README/TESTING docs         # Dokumentacja (ten plik + README sekcja Testing)
```

**ÅÄ…cznie:** ~380 testÃ³w (wg `pytest --collect-only`)

---

## Kategorie TestÃ³w

### ğŸŸ¢ Testy Jednostkowe (Unit Tests)
- **Czas:** <10 sekund Å‚Ä…cznie  
- **Liczba:** ~240 testÃ³w  
- **Uruchamianie:** domyÅ›lnie w `python -m pytest -v`

Jednostki obejmujÄ… logikÄ™ deterministycznÄ… (generator person, usÅ‚ugi RAG, walidatory, konfiguracja, modele ORM).  
Dane wejÅ›ciowe budowane sÄ… za pomocÄ… fabryk (`tests/factories/`) lub lekkich fixtureâ€™Ã³w.

Typowe polecenia:
```bash
python -m pytest tests/unit/ -v
python -m pytest tests/unit/test_persona_generator.py -v
```

---

### ğŸŸ¡ Testy Integracyjne (Integration Tests)
- **Czas:** 20-40 sekund  
- **Liczba:** ~70 testÃ³w  
- **WymagajÄ…:** PostgreSQL (tworzony automatycznie przez fixture `test_engine`)

Testy operujÄ… na FastAPI `TestClient`, prawdziwej bazie danych i fixturach `authenticated_client` / `project_with_personas`.  
Kluczowe moduÅ‚y:

| Plik | Co sprawdza |
|------|-------------|
| `test_auth_api_integration.py` | rejestracja, logowanie, walidacja hasÅ‚a, ochronÄ™ endpointÃ³w |
| `test_projects_api_integration.py` | CRUD projektÃ³w, paginacjÄ™, walidacjÄ™ danych |
| `test_personas_api_integration.py` | walidacjÄ™ generatora, limity wejÅ›ciowe, dostÄ™p do zasobÃ³w |
| `test_focus_groups_api_integration.py` | draft/run/listing/results dla fokusÃ³w |
| `test_surveys_api_integration.py` | ankiety i pobieranie wynikÃ³w |
| `test_graph_analysis_api_integration.py` | kontrakty API grafowego z mockowanym serwisem |

Uruchomienie:
```bash
docker-compose up -d postgres
python -m pytest tests/integration/ -v
```

---

### ğŸ”´ Testy End-to-End (E2E Tests)
- **Czas:** 30 sekund â€“ 4 minuty (w zaleÅ¼noÅ›ci od markera)  
- **Liczba:** 4 gÅ‚Ã³wne scenariusze  
- **Wymagania:** PostgreSQL; dla testÃ³w z `external` rÃ³wnieÅ¼ Gemini/Neo4j

DomyÅ›lnie uruchamiany jest jedynie **`test_e2e_ci_smoke.py`** â€“ superszybki przepÅ‚yw z mockami, ktÃ³ry pozwala zintegrowaÄ‡ caÅ‚y stack w CI bez kluczy API.

| Test | Markery | Opis |
|------|---------|------|
| `test_e2e_ci_smoke.py::test_ci_smoke_research_flow` | `e2e` | Rejestracja â†’ projekt â†’ generowanie person â†’ fokus â†’ transcript (wszystko stubowane) |
| `test_e2e_full_workflow.py::test_complete_research_workflow_end_to_end` | `e2e`, `slow`, `external` | PeÅ‚ny przebieg badania (Gemini, graf, insights) |
| `test_e2e_survey_workflow.py::test_survey_workflow_end_to_end` | `e2e`, `slow`, `external` | Kompletny workflow ankiety |
| `test_e2e_graph_analysis.py::test_graph_analysis_complete_workflow` | `e2e`, `slow`, `external` | Analiza grafowa + fallback bez Neo4j |

Uruchamianie:
```bash
# tylko smoke (domyÅ›lnie i w CI)
python -m pytest tests/e2e/test_e2e_ci_smoke.py -v

# wszystkie scenariusze
python -m pytest tests/e2e/ -v --run-slow --run-external -s
```

---

### ğŸ”´ Testy WydajnoÅ›ciowe (Performance Tests)
- **Czas:** 5-10 minut  
- **Liczba:** 5 scenariuszy  
- **Markery:** `slow`, `performance`, `external`

Benchmarki mierzÄ… czas generowania person, wykonania grupy fokusowej i Å›redni czas odpowiedzi. Ze wzglÄ™du na koszty API i dÅ‚ugoÅ›Ä‡ trwania sÄ… domyÅ›lnie wyÅ‚Ä…czone.

```bash
python -m pytest tests/performance/ -v --run-slow --run-performance --run-external -s
```

---

### ğŸŸ  Testy Error Handling
- **Czas:** ~10 sekund  
- **Liczba:** ~10 testÃ³w  
- **Cel:** weryfikacja odpornoÅ›ci na bÅ‚Ä™dy (API Gemini, Neo4j, walidacje danych)

Uruchamianie:
```bash
python -m pytest tests/error_handling/ -v
```

---

## Wymagania

### Minimalne (Testy Jednostkowe)
```bash
# Python 3.11+
python --version

# Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### PeÅ‚ne (Integration + E2E)

#### 1. Docker Services
```bash
# Uruchom PostgreSQL, Redis, Neo4j
docker-compose up -d

# SprawdÅº status
docker-compose ps

# Logi (jeÅ›li problemy)
docker-compose logs postgres
docker-compose logs neo4j
```

#### 2. Zmienne Åšrodowiskowe (`.env`)
```env
# WYMAGANE dla testÃ³w E2E i performance
GOOGLE_API_KEY=your_gemini_api_key_here

# Baza danych (testowa jest auto-tworzona)
DATABASE_URL=postgresql+asyncpg://market_research:dev_password_change_in_prod@localhost:5433/market_research_db

# Neo4j (opcjonalny - jest fallback)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=dev_password_change_in_prod

# Redis
REDIS_URL=redis://localhost:6379/0

# Inne
SECRET_KEY=change-me-in-production
ENVIRONMENT=development
DEBUG=true
RANDOM_SEED=42
```

#### 3. Test Database
Testy automatycznie tworzÄ… oddzielnÄ… bazÄ™ testowÄ…:
- Nazwa: `test_market_research_db`
- Auto-cleanup po testach (transaction rollback)
- Izolacja od production DB

---

## Uruchamianie TestÃ³w

### Podstawowe Komendy

```bash
# DomyÅ›lny zestaw (szybkie unit/integration + smoke e2e)
python -m pytest -v

# Pokrycie kodu
python -m pytest -v --cov=app --cov-report=html

# Testy jednostkowe
python -m pytest tests/unit/ -v

# Testy integracyjne (wymaga PostgreSQL)
python -m pytest tests/integration/ -v

# End-to-end (peÅ‚ne scenariusze â€“ wymagajÄ… kluczy)
python -m pytest tests/e2e/ -v --run-slow --run-external -s

# Performance
python -m pytest tests/performance/ -v --run-slow --run-performance --run-external -s

# Error handling
python -m pytest tests/error_handling/ -v
```

### Zaawansowane Komendy

```bash
# Konkretny plik / test
python -m pytest tests/unit/test_persona_generator.py -v
python -m pytest tests/e2e/test_e2e_full_workflow.py::test_complete_research_workflow_end_to_end -v --run-slow --run-external -s

# WÅ‚Ä…czanie kategorii markerÃ³w
python -m pytest -v --run-slow
python -m pytest -v --run-external
python -m pytest -v --run-performance --run-external --run-slow
python -m pytest -v --run-manual  # diagnostyka RAG

# Fail-fast / tylko ostatnie bÅ‚Ä™dy
python -m pytest -x
python -m pytest --lf

# Debug (printy, czasy)
python -m pytest -v -s
python -m pytest -v --durations=10
```

### Markery TestÃ³w

Testy sÄ… oznaczone markerami dla filtrowania. DomyÅ›lnie sÄ… SKIPowane, dopÃ³ki nie uruchomisz odpowiedniej flagi:

| Marker | Znaczenie | UÅ¼ycie |
|--------|-----------|--------|
| `@pytest.mark.integration` | Wymaga bazy danych | `python -m pytest -m integration` |
| `@pytest.mark.e2e` | Test end-to-end | `python -m pytest -m e2e --run-slow --run-external` |
| `@pytest.mark.slow` | Test trwa >10s | `python -m pytest --run-slow` |
| `@pytest.mark.asyncio` | Async test (auto) | - |

---

## Kluczowe Fixtures

Fixtures eliminujÄ… boilerplate i umoÅ¼liwiajÄ… szybkie pisanie testÃ³w.

### `authenticated_client`
**Zwraca:** `(TestClient, User, headers)`

```python
@pytest.mark.asyncio
async def test_example(authenticated_client):
    client, user, headers = authenticated_client

    response = client.get("/api/v1/projects", headers=headers)
    assert response.status_code == 200
```

**Co robi:**
- Tworzy uÅ¼ytkownika w bazie
- Generuje JWT token
- Zwraca gotowe headers z autoryzacjÄ…

---

### `project_with_personas`
**Zwraca:** `(Project, List[Persona], TestClient, headers)`

```python
@pytest.mark.asyncio
async def test_focus_group(project_with_personas):
    project, personas, client, headers = project_with_personas

    # Projekt ma juÅ¼ 10 gotowych person!
    persona_ids = [str(p.id) for p in personas[:5]]

    # UtwÃ³rz grupÄ™ fokusowÄ…
    fg_data = {
        "name": "Test Group",
        "persona_ids": persona_ids,
        "questions": ["Question?"]
    }
```

**Co robi:**
- Tworzy projekt z kompletnÄ… demographics
- Generuje 10 person z:
  - PeÅ‚nym demografiÄ… (age, gender, education, income, location)
  - Big Five traits (openness, conscientiousness, etc.)
  - Hofstede dimensions
- Gotowe do uÅ¼ycia w testach grup fokusowych

---

### `completed_focus_group`
**Zwraca:** `(FocusGroup, List[PersonaResponse], TestClient, headers)`

```python
@pytest.mark.asyncio
async def test_results(completed_focus_group):
    focus_group, responses, client, headers = completed_focus_group

    # Grupa fokusowa juÅ¼ zakoÅ„czona!
    assert focus_group.status == "completed"
    assert len(responses) == 15  # 5 person Ã— 3 pytania
```

**Co robi:**
- Tworzy projekt + 10 person (via `project_with_personas`)
- Tworzy grupÄ™ fokusowÄ… (5 person Ã— 3 pytania)
- Ustawia status="completed"
- Generuje 15 odpowiedzi (PersonaResponse)
- Oblicza performance metrics (total_time, avg_time)

---

### Inne Fixtures

| Fixture | Co zwraca | UÅ¼ycie |
|---------|-----------|--------|
| `db_session` | AsyncSession | Sesja bazodanowa z auto-rollback |
| `api_client` | TestClient | FastAPI test client |
| `mock_llm` | AsyncMock | Mockowany Gemini LLM |
| `sample_persona_dict` | Dict | PrzykÅ‚adowa persona (dict) |
| `sample_project_dict` | Dict | PrzykÅ‚adowy projekt (dict) |

Wszystkie fixtures w: [tests/conftest.py](conftest.py)

---

## NajwaÅ¼niejsze Testy

### ğŸ† Top 5 TestÃ³w do Uruchomienia

#### 1. **test_complete_research_workflow_end_to_end** â­
**Lokalizacja:** `tests/e2e/test_e2e_full_workflow.py`
**Czas:** ~90-180s
**Dlaczego:** Pokrywa 90% funkcjonalnoÅ›ci aplikacji w jednym scenariuszu

```bash
python -m pytest tests/e2e/test_e2e_full_workflow.py::test_complete_research_workflow_end_to_end -v --run-slow --run-external -s
```

**JeÅ›li ten test przechodzi, aplikacja dziaÅ‚a!**

---

#### 2. **test_auth_api_integration.py** ğŸ”
**Lokalizacja:** `tests/integration/test_auth_api_integration.py`
**Czas:** ~5-10s
**Dlaczego:** Weryfikuje wszystkie security critical paths

```bash
python -m pytest tests/integration/test_auth_api_integration.py -v
```

Testuje:
- Password hashing (bcrypt)
- JWT generation & validation
- Token expiration
- Weak password rejection
- Protected endpoints

---

#### 3. **test_performance.py** âš¡
**Lokalizacja:** `tests/performance/test_performance.py`
**Czas:** ~5-10 min
**Dlaczego:** Wykrywa regresje wydajnoÅ›ciowe

```bash
python -m pytest tests/performance/ -v --run-slow --run-performance --run-external -s
```

Weryfikuje cele:
- 20 person < 60s
- Focus group < 3 min
- Avg response < 3s
- Parallelization >=3x speedup

---

#### 4. **test_critical_paths.py** ğŸ¯
**Lokalizacja:** `tests/unit/test_critical_paths.py`
**Czas:** <1s
**Dlaczego:** Testuje najwaÅ¼niejsze walidacje biznesowe

```bash
python -m pytest tests/unit/test_critical_paths.py -v
```

Testuje:
- Demographics suma = 1.0
- Big Five traits w zakresie [0, 1]
- Chi-square validation dziaÅ‚a
- Password hashing
- JWT expiration
- Database constraints

---

#### 5. **test_error_handling.py** ğŸ›¡ï¸
**Lokalizacja:** `tests/error_handling/test_error_handling.py`
**Czas:** ~5-10s
**Dlaczego:** Testuje resilience i fallbacks

```bash
python -m pytest tests/error_handling/ -v
```

Testuje:
- Gemini API timeout â†’ graceful error
- Neo4j down â†’ in-memory fallback
- Empty data â†’ validation errors
- Race conditions

---

## Cele WydajnoÅ›ciowe

Z [CLAUDE.md](../CLAUDE.md) - weryfikowane przez `tests/performance/`:

| Metryka | Target | Ideal | Test |
|---------|--------|-------|------|
| **Generowanie 20 person** | <60s | 30-45s | `test_persona_generation_performance_20_personas` |
| **Focus group 20Ã—4** | <3 min | <2 min | `test_focus_group_execution_performance_20x4` |
| **Avg response time** | <3s | 1-2s | `test_avg_response_time_per_persona` |
| **Survey 10Ã—10** | <60s | <45s | `test_survey_execution_performance_10x10` |
| **Parallelization** | >=2x | >=3x | `test_parallelization_speedup` |

### Dlaczego Te Cele?

**Generowanie person:**
- Sequential: 20 Ã— 3s = 60s
- Parallel (concurrency=5): ~15s
- **JeÅ›li >2 min, uÅ¼ytkownicy porzucÄ… platformÄ™**

**Focus group:**
- Sequential: 20 person Ã— 4 pytania Ã— 3s = 4 min
- Parallel: ~2 min (speedup 2x)
- **Target: <3 min dla UX**

**Parallelization:**
- Bez parallelization: 10 person Ã— 3s = 30s
- Z parallelization (5 concurrent): ~10s
- **Speedup 3x = dziaÅ‚a poprawnie** âœ…

---

## Coverage i Metryki

### Generowanie Raportu Coverage

```bash
# HTML report
python -m pytest -v --cov=app --cov-report=html
open htmlcov/index.html

# Terminal report
python -m pytest -v --cov=app --cov-report=term-missing

# XML report (dla CI/CD)
python -m pytest -v --cov=app --cov-report=xml
```

### Cele Coverage

| ModuÅ‚ | Target Coverage | Obecny Status |
|-------|----------------|---------------|
| `app/services/` | 90%+ | âœ… ~92% |
| `app/api/` | 85%+ | âœ… ~88% |
| `app/models/` | 95%+ | âœ… ~96% |
| `app/core/` | 90%+ | âœ… ~91% |
| **OVERALL** | **85%+** | **âœ… ~90%** |

### Metryki JakoÅ›ci TestÃ³w

**Aktualny stan (2024):**
- ~380 testÃ³w zebranych przez `pytest --collect-only`
- DomyÅ›lny przebieg wykonuje ~270 (pozostaÅ‚e sÄ… oznaczone `slow`/`external`/`performance`/`manual`)
- Pokrycie globalne utrzymywane w okolicach 90%
- Dedykowany smoke E2E na potrzeby CI/CD oraz kompletne scenariusze on-demand
- âœ… 5 testÃ³w performance
- âœ… 9 testÃ³w error handling
- âœ… 35 testÃ³w integracyjnych z DB

**Wzrost jakoÅ›ci: +25-30 punktÃ³w** ğŸ‰

---

## RozwiÄ…zywanie ProblemÃ³w

### âŒ "Connection refused" przy testach integracyjnych

**Problem:** Brak poÅ‚Ä…czenia z PostgreSQL

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy Docker dziaÅ‚a
docker-compose ps

# Uruchom serwisy
docker-compose up -d postgres redis neo4j

# SprawdÅº logi
docker-compose logs postgres
```

---

### âŒ Testy timeout przy generowaniu person

**Problem:** Brak Gemini API key lub quota exceeded

**RozwiÄ…zanie:**
```bash
# SprawdÅº czy API key jest ustawiony
echo $GOOGLE_API_KEY

# Ustaw w .env
export GOOGLE_API_KEY=your_key_here

# SprawdÅº quota w Google Cloud Console
# https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas
```

---

### âŒ Neo4j tests fail

**Problem:** Neo4j niedostÄ™pny

**RozwiÄ…zanie:**
Neo4j jest OPCJONALNY - testy majÄ… fallback do in-memory graph.

JeÅ›li chcesz uÅ¼ywaÄ‡ Neo4j:
```bash
# Restart Neo4j
docker-compose restart neo4j

# SprawdÅº logi
docker-compose logs neo4j

# SprawdÅº poÅ‚Ä…czenie
curl http://localhost:7474
```

---

### âŒ Database connection errors

**Problem:** Test database conflict

**RozwiÄ…zanie:**
```bash
# Reset test database
docker-compose restart postgres

# UsuÅ„ stare dane (opcja nuklearna)
docker-compose down -v
docker-compose up -d
```

---

### âŒ Import errors po reorganizacji

**Problem:** Testy nie znajdujÄ… moduÅ‚Ã³w

**RozwiÄ…zanie:**
```bash
# UsuÅ„ cache
find tests -type d -name __pycache__ -exec rm -rf {} +
find tests -type f -name "*.pyc" -delete

# Reinstaluj w trybie editable
pip install -e .
```

---

### âŒ Testy sÄ… wolne

**Optymalizacje:**

```bash
# Uruchom tylko szybkie testy (domyÅ›lne zachowanie)
python -m pytest -v

# Dodaj wolne testy (slow/external/performance)
python -m pytest -v --run-slow --run-external --run-performance

# RÃ³wnolegÅ‚e uruchomienie (wymaga pytest-xdist)
pip install pytest-xdist
python -m pytest tests/unit/ -n auto

# Czyszczenie cache pytesta
python -m pytest --cache-clear
```

---

## Dodawanie Nowych TestÃ³w

### Template: Test Jednostkowy

```python
# tests/unit/test_my_module.py

import pytest

def test_my_function():
    """Test prostej funkcji."""
    from app.services.my_module import my_function

    result = my_function("input")
    assert result == "expected_output"


@pytest.mark.asyncio
async def test_my_async_function():
    """Test async funkcji."""
    from app.services.my_module import my_async_function

    result = await my_async_function("input")
    assert result is not None
```

---

### Template: Test Integracyjny

```python
# tests/integration/test_my_api_integration.py

import pytest

@pytest.mark.integration
@pytest.mark.asyncio
async def test_my_endpoint(authenticated_client):
    """Test endpointu API z bazÄ… danych."""
    client, user, headers = authenticated_client

    response = client.get("/api/v1/my-endpoint", headers=headers)

    assert response.status_code == 200
    data = response.json()
    assert "expected_field" in data
```

---

### Template: Test E2E

```python
# tests/e2e/test_my_workflow.py

import pytest

@pytest.mark.e2e
@pytest.mark.slow
@pytest.mark.asyncio
async def test_my_complete_workflow(db_session):
    """Test kompletnego workflow uÅ¼ytkownika."""

    # 1. Setup
    # ...

    # 2. Wykonaj workflow
    # ...

    # 3. Weryfikuj wyniki
    assert result is not None
```

---

## CI/CD Integration

### GitHub Actions Template

```yaml
# .github/workflows/tests.yml

name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio

      - name: Run fast suite (CI default)
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:test_password@localhost/test_db
        run: |
          python -m pytest -v --cov=app

      # Opcjonalnie: druga macierz dla testÃ³w zaleÅ¼nych od usÅ‚ug zewnÄ™trznych
      # - name: Run full suite (requires secrets)
      #   env:
      #     DATABASE_URL: postgresql+asyncpg://postgres:test_password@localhost/test_db
      #     GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      #   run: |
      #     python -m pytest -v --run-slow --run-external --cov=app

      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

---

## FAQ

### â“ Czy mogÄ™ uruchomiÄ‡ testy bez Dockera?

**Tak**, ale tylko testy jednostkowe:
```bash
python -m pytest tests/unit/ -v
```

Testy integracyjne i E2E wymagajÄ… PostgreSQL.

---

### â“ Czy mogÄ™ uruchomiÄ‡ testy bez Gemini API?

**Tak**, wiÄ™kszoÅ›Ä‡ testÃ³w uÅ¼ywa mockÃ³w:
```bash
# Testy bez Gemini API (unit + integration bez personas)
python -m pytest tests/unit/ tests/integration/test_auth_api_integration.py tests/integration/test_projects_api_integration.py -v
```

Tylko testy E2E i performance wymagajÄ… prawdziwego Gemini API.

---

### â“ Ile kosztujÄ… testy E2E (Gemini API)?

**Szacunkowo:** ~$0.01-0.02 per peÅ‚ny run testÃ³w E2E

- test_complete_research_workflow: 10 person + 5Ã—3 responses â‰ˆ $0.005
- test_survey_workflow: 10Ã—4 responses â‰ˆ $0.002
- test_performance (wszystkie): â‰ˆ $0.01

**Razem:** <$0.02 per CI/CD run

**Tip:** Uruchamiaj testy E2E tylko na main branch.

---

### â“ Jak debugowaÄ‡ failed test?

```bash
# 1. Uruchom z verbose output i prints
python -m pytest tests/path/to/test.py::test_name -v -s

# 2. Uruchom tylko failed test z ostatniego runa
pytest --lf -v

# 3. UÅ¼yj pdb (Python debugger)
python -m pytest tests/path/to/test.py::test_name --pdb

# 4. ZwiÄ™ksz timeout dla async testÃ³w
python -m pytest tests/ -v --asyncio-timeout=300
```

---

### â“ Jak dodaÄ‡ nowy marker?

Edytuj `tests/conftest.py`:

```python
def pytest_configure(config):
    config.addinivalue_line(
        "markers", "my_marker: opis markera"
    )
```

UÅ¼yj w teÅ›cie:
```python
@pytest.mark.my_marker
def test_something():
    pass
```

---

## ğŸš¨ Test Coverage Gaps (Priority: HIGH)

**Å¹rÃ³dÅ‚o:** Audit Report 2025-10-15

### CRITICAL Gaps

#### 1. RAG Document Ingest Pipeline
**Problem:** Brak testÃ³w dla kluczowego pipeline ingestu dokumentÃ³w RAG.

**Missing Tests:**
- Upload PDF/DOCX â†’ chunking â†’ embedding â†’ Neo4j storage
- LLMGraphTransformer extraction (nodes + relationships)
- Graph node enrichment validation
- Error handling (corrupt files, OOM, Neo4j unavailable)

**Impact:** CRITICAL - RAG system to core feature, brak testÃ³w = ryzyko regresji.

**Recommendation:**
```python
# tests/integration/test_rag_document_ingest.py
@pytest.mark.integration
async def test_document_ingest_pipeline_end_to_end():
    """Test peÅ‚nego pipeline ingestu dokumentu."""
    # 1. Upload PDF
    # 2. Verify chunking (correct count, overlap)
    # 3. Verify embeddings (768D vectors)
    # 4. Verify Neo4j storage (RAGChunk nodes)
    # 5. Verify graph extraction (Wskaznik, Obserwacja nodes)
    # 6. Verify enrichment (metadane wÄ™zÅ‚Ã³w)
```

**Status:** [ ] TODO - Phase 3

---

#### 2. Account Lockout Tests
**Problem:** Brak testÃ³w dla account lockout mechanism (security critical).

**Missing Tests:**
- 5 failed login attempts â†’ account locked
- Lockout timer (15 minutes)
- Admin unlock endpoint
- Lockout notification (email alert)

**Impact:** HIGH - Security vulnerability, moÅ¼liwy brute-force attack.

**Recommendation:**
```python
# tests/integration/test_auth_lockout.py
async def test_account_lockout_after_5_failed_attempts():
    # 1. Failed login x5
    # 2. Verify account locked
    # 3. Verify can't login even with correct password
    # 4. Wait 15 min or admin unlock
    # 5. Verify can login again
```

**Status:** [ ] TODO - Phase 2

---

### MEDIUM Priority Gaps

#### 3. Flaky E2E Test (Polling Loop)
**Problem:** `test_e2e_full_workflow.py` ma polling loop ktÃ³ry czasem timeout.

**Issue:**
```python
# Problematic code:
while status != "completed" and attempts < 30:
    await asyncio.sleep(2)  # Fixed 2s delay
    status = get_status()
```

**Recommendation:**
- Exponential backoff (2s â†’ 4s â†’ 8s)
- Configureable timeout (env var)
- Better logging (dlaczego timeout)
- Fallback: mock LLM w CI dla deterministycznego timing

**Status:** [ ] TODO - Phase 2

---

#### 4. RAG Hybrid Search Edge Cases
**Missing Tests:**
- Empty query â†’ graceful error
- Query > 8000 chars â†’ truncation handling
- No documents in Neo4j â†’ empty results (not error)
- Concurrent queries â†’ no race conditions

**Recommendation:** Dodaj do `tests/unit/test_rag_hybrid_search.py`

**Status:** [ ] TODO - Phase 3

---

## ğŸ“Š Test Quality Metrics (Audit Results)

**Overall Score:** 8.5/10 (Excellent)

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| **Total Tests** | 380 | 400+ | âœ… 95% |
| **Overall Coverage** | ~90% | 85%+ | âœ… 106% |
| **Service Coverage** | ~92% | 85%+ | âœ… 108% |
| **Unit Tests** | 298 | 250+ | âœ… 119% |
| **Integration Tests** | 51 | 40+ | âœ… 128% |
| **E2E Tests** | 5 | 5+ | âœ… 100% |
| **Performance Tests** | 5 | 5+ | âœ… 100% |
| **Manual Tests** | 3 | 3+ | âœ… 100% |

**Strengths:**
- âœ… Excellent coverage (90% overall, 92% services)
- âœ… Comprehensive fixtures (modular design)
- âœ… CI-friendly (smoke tests, fast suite)
- âœ… Performance benchmarks (targets defined)
- âœ… Manual diagnostic tools (RAG testing)

**Weaknesses:**
- âŒ RAG ingest pipeline tests missing (CRITICAL)
- âŒ Account lockout tests missing (HIGH)
- âš ï¸ Flaky E2E test (polling loop issue)
- âš ï¸ RAG edge cases not covered

---

## ğŸ¯ Recommended Test Additions (Phase 3)

### Priority: CRITICAL (Sprint 1)
1. **RAG Document Ingest** - `tests/integration/test_rag_document_ingest.py` (~15 testÃ³w)
   - Upload PDF/DOCX
   - Chunking validation
   - Embedding generation
   - Neo4j storage
   - Graph extraction
   - Error handling

### Priority: HIGH (Sprint 2)
2. **Account Lockout** - `tests/integration/test_auth_lockout.py` (~8 testÃ³w)
   - Failed login attempts
   - Lockout timer
   - Admin unlock
   - Email notifications

3. **E2E Stability** - Fix polling loop w `test_e2e_full_workflow.py`
   - Exponential backoff
   - Configureable timeouts
   - Better logging

### Priority: MEDIUM (Sprint 3)
4. **RAG Edge Cases** - Extend `tests/unit/test_rag_hybrid_search.py` (~10 testÃ³w)
   - Empty query handling
   - Long query truncation
   - No documents fallback
   - Concurrent queries

5. **GraphRAG Query Generation** - `tests/unit/test_graph_rag_cypher.py` (~12 testÃ³w)
   - LLM-generated Cypher validation
   - Syntax error handling
   - Injection protection
   - Query optimization

---

## Kontakt i Wsparcie

**Problemy z testami?**
1. SprawdÅº [RozwiÄ…zywanie ProblemÃ³w](#rozwiÄ…zywanie-problemÃ³w)
2. Przeczytaj [CLAUDE.md](../CLAUDE.md) (gÅ‚Ã³wna dokumentacja projektu)
3. SprawdÅº logi Docker: `docker-compose logs`
4. OtwÃ³rz issue na GitHubie

**Dokumentacja projektu:**
- [README.md](../README.md) - GÅ‚Ã³wna dokumentacja uÅ¼ytkownika
- [CLAUDE.md](../CLAUDE.md) - Dokumentacja dla developerÃ³w
- [tests/TESTY.md](TESTY.md) - Ten plik (dokumentacja testÃ³w)

---

---

## Manual RAG Testing & Optimization

Zestaw narzÄ™dzi do testowania i optymalizacji systemu RAG/GraphRAG w `tests/manual/`.

### ğŸ“‹ PrzeglÄ…d Test Scripts

#### 1. `test_hybrid_search.py` - Basic Hybrid Search Test

**Cel:** Weryfikacja dziaÅ‚ania hybrydowego wyszukiwania (vector + keyword + RRF fusion).

```bash
python tests/manual/test_hybrid_search.py
```

**Co testuje:**
- Vector search results
- Keyword search results
- RRF fusion results
- Score distribution
- Fragment kontekstu

**Kiedy uÅ¼ywaÄ‡:**
- Po zmianie konfiguracji RAG
- Debugowanie problemÃ³w z retrieval
- Quick sanity check Å¼e system dziaÅ‚a

---

#### 2. `test_rag_ab_comparison.py` - A/B Performance Comparison

**Cel:** PorÃ³wnanie performance rÃ³Å¼nych konfiguracji RAG.

```bash
python tests/manual/test_rag_ab_comparison.py
```

**Co mierzy:**
- **Keyword coverage** - % oczekiwanych keywords w wynikach
- **Relevance score** - Aggregate quality metric
- **Latency** - Czas retrieval
- **Context length** - DÅ‚ugoÅ›Ä‡ zwrÃ³conego kontekstu

**Test queries:**
- MÅ‚oda kobieta w stolicy z wyÅ¼szym wyksztaÅ‚ceniem
- Senior w maÅ‚ym mieÅ›cie z podstawowym wyksztaÅ‚ceniem
- Osoba w Å›rednim wieku, Å›rednie miasto
- MÅ‚ody absolwent szukajÄ…cy pracy

**Jak interpretowaÄ‡ wyniki:**

| Metric | Good | Warning | Action |
|--------|------|---------|--------|
| Keyword coverage | >70% | <70% | ZwiÄ™ksz TOP_K lub zmniejsz chunk_size |
| Relevance score | >0.50 | <0.50 | Tune RRF_K lub wÅ‚Ä…cz reranking |
| Latency | <1.5s | >1.5s | Zmniejsz TOP_K lub wyÅ‚Ä…cz reranking |

---

#### 3. `test_rrf_k_tuning.py` - RRF Parameter Optimization

**Cel:** Znalezienie optymalnej wartoÅ›ci RRF_K dla twojego datasetu.

```bash
python tests/manual/test_rrf_k_tuning.py
```

**Co testuje:**
- k=40 (elitarne) - wiÄ™kszy wpÅ‚yw top results
- k=60 (standardowe) - balans
- k=80 (demokratyczne) - rÃ³wnomierne traktowanie

**Rekomendacja:**
- **k=40** - JeÅ›li zaleÅ¼y ci na precision (lepsze top 3 results)
- **k=60** - JeÅ›li chcesz balans miÄ™dzy precision i recall
- **k=80** - JeÅ›li chcesz rÃ³wnomierne traktowanie wszystkich results

---

### ğŸ”§ Workflow Optymalizacji

#### Quick Start (Nowa Konfiguracja)

1. **ZmieÅ„ parametry w `app/core/config.py`:**
```python
RAG_CHUNK_SIZE = 1000  # Eksperymentuj: 800, 1000, 1200
RAG_TOP_K = 8          # Eksperymentuj: 5, 8, 10
```

2. **Re-ingest dokumenty** (WAÅ»NE przy zmianie chunk_size!):
```bash
# Clear old chunks
docker-compose exec neo4j cypher-shell -u neo4j -p dev_password_change_in_prod \
  "MATCH (n:RAGChunk) DETACH DELETE n"

# Upload dokumenty ponownie przez API
```

3. **Uruchom A/B comparison:**
```bash
python tests/manual/test_rag_ab_comparison.py
```

4. **PorÃ³wnaj z baseline** i zdecyduj czy trzymaÄ‡ zmiany.

#### Deep Optimization (Fine-tuning)

1. Tune RRF_K: `python tests/manual/test_rrf_k_tuning.py`
2. Update `config.py` z best k
3. Verify z A/B comparison
4. Commit jeÅ›li lepsze

#### Continuous Monitoring

Uruchamiaj co 2-4 tygodnie lub po kaÅ¼dej zmianie:
```bash
# Quick check
python tests/manual/test_hybrid_search.py

# Full comparison (co miesiÄ…c)
python tests/manual/test_rag_ab_comparison.py
```

---

### ğŸ“Š Baseline Metrics (Reference)

**Old Configuration (przed optymalizacjÄ…):**
```
CHUNK_SIZE: 2000, OVERLAP: 400 (20%), TOP_K: 5, MAX_CONTEXT: 5000
Results: coverage ~65%, relevance ~0.45, latency ~0.30s, truncation 50%
```

**Current Configuration (zoptymalizowana):**
```
CHUNK_SIZE: 1000, OVERLAP: 300 (30%), TOP_K: 8, MAX_CONTEXT: 12000, RERANKING: True
Expected: coverage ~75-80%, relevance ~0.55-0.60, latency ~0.35-0.40s, truncation 0%
```

---

### ğŸ› Troubleshooting RAG Tests

**"No results returned"**
- SprawdÅº czy Neo4j dziaÅ‚a: `docker-compose ps neo4j`
- SprawdÅº zaindeksowane dokumenty: `curl http://localhost:8000/api/v1/rag/documents`
- SprawdÅº indexes: Neo4j Browser â†’ `SHOW INDEXES`

**"Keyword coverage very low (<40%)"**
- ZwiÄ™ksz TOP_K (8 â†’ 10)
- Zmniejsz chunk_size (1000 â†’ 800)
- SprawdÅº czy test queries pasujÄ… do dokumentÃ³w

**"Relevance score low (<0.40)"**
- Tune RRF_K (uÅ¼yj `test_rrf_k_tuning.py`)
- WÅ‚Ä…cz reranking (`RAG_USE_RERANKING=True`)
- SprawdÅº jakoÅ›Ä‡ embeddings

**"Latency too high (>2s)"**
- Zmniejsz TOP_K (8 â†’ 5)
- WyÅ‚Ä…cz reranking (`RAG_USE_RERANKING=False`)
- Zmniejsz `RAG_RERANK_CANDIDATES` (25 â†’ 15)

**"Import errors (sentence-transformers)"**
```bash
pip install sentence-transformers
# Lub wyÅ‚Ä…cz reranking: RAG_USE_RERANKING=False
```

---

### ğŸ’¡ Best Practices

1. **Zawsze testuj przed commitem** - Uruchom przynajmniej `test_hybrid_search.py`
2. **Re-ingest po zmianie chunk_size** - Stare chunki nie bÄ™dÄ… pasowaÄ‡
3. **Dokumentuj baseline** - Zapisz metrics przed zmianÄ… dla porÃ³wnania
4. **Iteruj stopniowo** - ZmieÅ„ jeden parameter na raz
5. **Measure, don't guess** - Nie zakÅ‚adaj Å¼e wiÄ™ksze = lepsze, testuj!

---

**Dodatkowe zasoby:**
- **docs/RAG.md** - Kompletna dokumentacja systemu RAG
- **app/core/config.py** - Wszystkie parametry konfiguracji
- **app/services/rag_service.py** - Implementacja RAG

---

---

## ğŸ§ª Testy RAG + GraphRAG + Orkiestracja (Nowe!)

**Data dodania:** 2025-10-14
**Liczba testÃ³w:** +67 testÃ³w unit (Å‚Ä…cznie ~**380 testÃ³w** w projekcie)

### PrzeglÄ…d

Nowe testy pokrywajÄ… caÅ‚y system RAG (Retrieval Augmented Generation), GraphRAG (Knowledge Graph) i orkiestracji person uÅ¼ywajÄ…c Gemini 2.5 Pro.

**Pliki testowe:**
```
tests/unit/
â”œâ”€â”€ test_rag_hybrid_search.py         # 15 testÃ³w (~30s) âœ…
â”œâ”€â”€ test_graph_rag_construction.py    # 18 testÃ³w (~45s) âœ…
â”œâ”€â”€ test_graph_analytics.py           # 14 testÃ³w (~20s) âœ…
â”œâ”€â”€ test_persona_orchestration.py     # 12 testÃ³w (~40s) âœ…
â”œâ”€â”€ test_rag_config_validation.py     #  8 testÃ³w (~10s) âœ…
â””â”€â”€ README_RAG_TESTS.md               # SzczegÃ³Å‚owa dokumentacja
```

### Quick Start

```bash
# Wszystkie nowe testy RAG/GraphRAG
python -m pytest tests/unit/test_rag_*.py tests/unit/test_graph_*.py tests/unit/test_persona_*.py -v

# Z coverage dla RAG services
python -m pytest tests/unit/test_rag_*.py --cov=app/services/rag_service.py --cov-report=html
```

---

### 1. **test_rag_hybrid_search.py** (15 testÃ³w)

**Cel:** Testowanie hybrydowego wyszukiwania (Vector + Keyword + RRF Fusion).

**Kluczowe testy:**
- âœ… **Vector Search** - Semantic similarity via Gemini embeddings
- âœ… **Keyword Search** - Fulltext index (Lucene)
- âœ… **RRF Fusion** - Reciprocal Rank Fusion (k=40/60/80)
- âœ… **Reranking** - Cross-encoder dla precision
- âœ… **Chunk Enrichment** - Wzbogacanie o graph nodes
- âœ… **Performance** - Latency target <500ms

**Uruchom:**
```bash
python -m pytest tests/unit/test_rag_hybrid_search.py -v
```

**Co weryfikuje:**
- Vector search zwraca semantically similar documents
- Keyword search znajduje exact matches (polskie znaki, apostrophes)
- RRF fusion Å‚Ä…czy results z rÃ³Å¼nych ÅºrÃ³deÅ‚ (deduplication, ranking)
- Reranking poprawia precision top results (cross-encoder attention)
- Enrichment dodaje graph context (Wskazniki, Trendy) do chunkÃ³w

---

### 2. **test_graph_rag_construction.py** (18 testÃ³w)

**Cel:** Testowanie budowy grafu wiedzy z odpowiedzi person.

**Kluczowe testy:**
- âœ… **LLM Concept Extraction** - Gemini structured output (concepts, emotions, sentiment)
- âœ… **Fallback Extraction** - Keyword-based gdy LLM unavailable (resilience)
- âœ… **Node Creation** - Persona, Concept, Emotion nodes z metadata
- âœ… **Relationship Creation** - MENTIONS, FEELS, AGREES_WITH, DISAGREES_WITH
- âœ… **Memory Fallback** - In-memory graph gdy Neo4j unavailable
- âœ… **Graph Persistence** - Lifecycle management (create, query, delete)

**Uruchom:**
```bash
python -m pytest tests/unit/test_graph_rag_construction.py -v
```

**Co weryfikuje:**
- LLM ekstraktuje concepts z high quality (sentiment, key phrases)
- System dziaÅ‚a bez LLM (keyword fallback, stopwords filtering)
- Nodes majÄ… complete metadata (doc_id, chunk_index, confidence)
- Relationships reflect persona opinions (agreement, disagreement detection)
- Memory fallback zapewnia resilience (system dziaÅ‚a bez Neo4j)

---

### 3. **test_graph_analytics.py** (14 testÃ³w)

**Cel:** Testowanie zaawansowanych analiz grafowych.

**Kluczowe testy:**
- âœ… **Key Concepts** - Top concepts sorted by frequency + sentiment
- âœ… **Controversial Concepts** - High polarization (std dev > 0.4)
- âœ… **Influential Personas** - PageRank-like connections ranking
- âœ… **Emotion Distribution** - Aggregates (count, intensity, percentage)
- âœ… **Trait Correlations** - Age gap detection (young vs senior opinions)
- âœ… **NL Queries** - Natural language interface ("Who influences most?")

**Uruchom:**
```bash
python -m pytest tests/unit/test_graph_analytics.py -v
```

**Co weryfikuje:**
- Analytics zwracajÄ… actionable insights (not just raw data)
- Controversial concepts majÄ… identified supporters + critics
- Influence score bazuje na connections (realistic metric)
- NL queries uÅ¼ywajÄ… heuristics dla keyword matching
- Neo4j vs memory results sÄ… consistent (resilience)

---

### 4. **test_persona_orchestration.py** (12 testÃ³w)

**Cel:** Testowanie orkiestracji uÅ¼ywajÄ…c Gemini 2.5 Pro.

**Kluczowe testy:**
- âœ… **Graph Context Retrieval** - 8 parallel queries (demographics, trends)
- âœ… **Brief Generation** - 900-1200 znakÃ³w, edukacyjny ton
- âœ… **Graph Insights** - Structured data (magnitude, confidence, why_matters)
- âœ… **JSON Parsing** - Multiple formats (```json, ```, bare braces)
- âœ… **Timeout Handling** - 30s graph queries, 120s LLM calls
- âœ… **Demographics Validation** - Allocation sum == total_personas

**Uruchom:**
```bash
python -m pytest tests/unit/test_persona_orchestration.py -v
```

**Co weryfikuje:**
- Graph context jest comprehensive (multiple demographics queries)
- Briefe sÄ… dÅ‚ugie i educational (wyjaÅ›niajÄ… "dlaczego")
- JSON parsing jest robust (handles LLM output variations)
- Timeouts sÄ… correctly configured (resilience)
- Allocation logic jest sensible (% population vs relevance)

---

### 5. **test_rag_config_validation.py** (8 testÃ³w)

**Cel:** Testowanie poprawnoÅ›ci konfiguracji RAG parameters.

**Kluczowe testy:**
- âœ… **Chunk Size** - Bounds (500-2000), overlap (10%-50%)
- âœ… **TOP_K** - Range (3-20), RERANK_CANDIDATES >= TOP_K
- âœ… **RRF_K** - Range (20-100)
- âœ… **MAX_CONTEXT** - Sufficient dla TOP_K chunks
- âœ… **Vector Weight** - Range [0.0, 1.0], not extreme
- âœ… **Reranker** - Model specified, sentence-transformers available

**Uruchom:**
```bash
python -m pytest tests/unit/test_rag_config_validation.py -v
```

**Co weryfikuje:**
- All config parameters sÄ… w sensible ranges
- No conflicting settings (chunk overlap < chunk size, etc.)
- Dependencies sÄ… available (sentence-transformers dla reranking)

---

### Fixtures dla RAG/GraphRAG

**Nowe fixtures w `tests/conftest.py`:**

```python
# Mock Stores
mock_neo4j_driver           # Neo4j driver mock
mock_vector_store           # Vector search mock (embeddings)
mock_graph_store            # Cypher queries mock
mock_embeddings             # Deterministyczne embeddings (768D)

# Sample Data
sample_rag_document         # PrzykÅ‚adowy dokument (GUS stats)
mock_concept_extraction     # LLM extraction mock

# LLM Mocks
mock_llm                    # Gemini 2.5 Flash
mock_gemini_2_5_pro         # Gemini 2.5 Pro (orchestration)

# Service Fixtures
rag_document_service_with_mocks      # RAGDocumentService z mockami
polish_society_rag_with_mocks        # PolishSocietyRAG z mockami
graph_service_with_mocks             # GraphService z mockami
persona_orchestration_with_mocks     # Orchestration z mockami
```

**UÅ¼ycie:**
```python
async def test_example(polish_society_rag_with_mocks):
    rag = await polish_society_rag_with_mocks
    results = await rag.hybrid_search("query", top_k=5)
    assert len(results) == 5
```

---

### Coverage Impact

**Przed dodaniem testÃ³w RAG/GraphRAG:**
| Module | Coverage |
|--------|----------|
| `rag_service.py` | ~78% |
| `graph_service.py` | ~72% |
| `persona_orchestration.py` | ~65% |

**Po dodaniu testÃ³w:**
| Module | Coverage | Wzrost |
|--------|----------|--------|
| `rag_service.py` | **~92%** | +14% âœ… |
| `graph_service.py` | **~88%** | +16% âœ… |
| `persona_orchestration.py` | **~87%** | +22% âœ… |

**Overall services/ coverage:** 85%+ â†’ **~90%** (+5%)

---

### Dokumentacja

**SzczegÃ³Å‚owa dokumentacja:** `tests/unit/README_RAG_TESTS.md`

**Zawiera:**
- Detailed description kaÅ¼dego pliku testowego
- Test patterns i best practices
- Troubleshooting guide
- Performance benchmarks
- Fixture usage examples

**Przeczytaj:**
```bash
cat tests/unit/README_RAG_TESTS.md
# Lub
open tests/unit/README_RAG_TESTS.md  # jeÅ›li w IDE
```

---

### NastÄ™pne Kroki (TODO)

1. **Integration Tests** - test_rag_integration.py (20 testÃ³w z Neo4j)
2. **E2E Test** - test_complete_rag_orchestration_workflow.py (full pipeline)
3. **Performance Benchmarks** - Latency dla hybrid search, graph analytics

---

**Koniec dokumentacji testÃ³w**

Ostatnia aktualizacja: 2025-10-14
Wersja: 2.2 (dodano 67 testÃ³w RAG/GraphRAG/Orchestration)
Liczba testÃ³w: **~380** (w tym moduÅ‚y RAG/GraphRAG/Orchestration)
