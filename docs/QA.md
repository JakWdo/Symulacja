# Dokumentacja QA i Testowania - Sight Platform

**Wersja:** 2.3 | **Ostatnia aktualizacja:** 2025-11-03

System testÃ³w dla platformy Sight zostaÅ‚ zaprojektowany jako kompleksowy mechanizm zapewnienia jakoÅ›ci oprogramowania, Å‚Ä…czÄ…c testy jednostkowe, integracyjne, end-to-end, wydajnoÅ›ciowe oraz obsÅ‚ugi bÅ‚Ä™dÃ³w w spÃ³jny ekosystem. Nasz cel to nie tylko weryfikacja poprawnoÅ›ci funkcjonalnej, ale rÃ³wnieÅ¼ budowanie zaufania poprzez dokÅ‚adne pokrycie scenariuszy uÅ¼ycia, weryfikacjÄ™ wydajnoÅ›ci oraz zapewnienie odpornoÅ›ci na bÅ‚Ä™dy.

## Statystyki Globalne

**Aktualna suite testÃ³w (wersja 2.3):**

- **ÅÄ…czna liczba testÃ³w:** 444 funkcje testowe
- **Pliki testowe:** 66 plikÃ³w w 5 kategoriach
- **Pokrycie kodu:** ~87% overall, ~92% dla krytycznych serwisÃ³w
- **Testy pomijane:** 5 (1.1% - kontrolowane przypadki brzegowe)
- **Czas wykonania:**
  - Testy szybkie (bez `@pytest.mark.slow`): ~90s
  - PeÅ‚na suita z LLM: 5-10 minut

**Trend wzrostu:**
- PaÅºdziernik 2024: ~380 testÃ³w, 85% pokrycia
- Listopad 2025: 444 testy, 87% pokrycia
- Wzrost: +17% liczby testÃ³w, +2% pokrycia w ciÄ…gu roku

## Piramida TestÃ³w

Nasza strategia testowania opiera siÄ™ na klasycznej piramidzie testÃ³w z dodatkowymi warstwami dla wydajnoÅ›ci i obsÅ‚ugi bÅ‚Ä™dÃ³w:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  E2E (12)    â”‚  2.7% - PeÅ‚ne scenariusze uÅ¼ytkownika (2-5 min)
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Integration (63) â”‚  14% - API + DB + External services (10-30s)
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Performance (5)       â”‚  1.1% - Benchmarks, SLA compliance (5-10 min)
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Error Handling (9)          â”‚  2% - Edge cases & failures (5-10s)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Unit Tests (355)               â”‚  80% - Isolated logic (<90s)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Uzasadnienie dystrybucji:**

**80% Unit Tests (355)** - Szybki feedback loop (<90s), deterministyczne wyniki bez zewnÄ™trznych zaleÅ¼noÅ›ci, Å‚atwe debugowanie z izolacjÄ… bÅ‚Ä™dÃ³w, pokrycie logiki biznesowej i transformacji danych. NajniÅ¼szy koszt utrzymania i najwyÅ¼sza wartoÅ›Ä‡ diagnostyczna.

**14% Integration Tests (63)** - Weryfikacja wspÃ³Å‚pracy komponentÃ³w, testy API z prawdziwÄ… bazÄ… danych, integracja LangChain + Gemini (z mockami). Balance miÄ™dzy realistycznoÅ›ciÄ… a prÄ™dkoÅ›ciÄ…, wykrywanie problemÃ³w na poziomie integracji moduÅ‚Ã³w.

**2.7% E2E Tests (12)** - Wysoki koszt czasowy (2-5 min), wymaga zewnÄ™trznych serwisÃ³w (Gemini API). Focus na krytycznych user flows, smoke tests dla CI/CD, weryfikacja peÅ‚nych scenariuszy biznesowych.

**3.1% Performance + Error Handling (14)** - Niche scenarios wymagajÄ…ce specjalnego setupu, performance benchmarks przeciw SLA, edge cases i failure scenarios, weryfikacja odpornoÅ›ci systemu.

## Kategorie TestÃ³w

### 1. Testy Jednostkowe (Unit Tests)

**Statystyki:** 355 testÃ³w (80% suite), czas wykonania <90s, cel: izolowana weryfikacja logiki serwisÃ³w

**Zakres pokrycia:**
- **Logika generacji person:** Sampling demograficzny, Big Five traits, psychografia
- **Serwisy RAG:** Hybrid search, graph transformations, document processing
- **Walidatory:** Chi-kwadrat, segment brief validation, demographic constraints
- **Modele ORM:** Relacje, constraints, cascade deletes
- **Utilities:** Language detection, datetime handling, Polish NLP

**PrzykÅ‚adowe testy krytyczne:**
- `test_demographic_distribution_sums_to_one` - Weryfikacja poprawnoÅ›ci matematycznej rozkÅ‚adÃ³w
- `test_big_five_traits_in_valid_range` - Sprawdzenie zakresÃ³w cech osobowoÅ›ci [0,1]
- `test_persona_must_have_required_fields` - KompletnoÅ›Ä‡ struktury danych persony
- `test_polish_character_handling` - ObsÅ‚uga polskich znakÃ³w (Ä…, Ä‡, Ä™, Å‚, Å„, Ã³, Å›, Åº, Å¼)

**Kluczowe pliki:** `tests/unit/test_persona_generator.py`, `test_persona_orchestration.py`, `test_focus_group_service.py`, `test_rag_hybrid_search_service.py`, `test_rag_graph_service.py`, `test_survey_response_generator.py`, `test_critical_paths.py`, `test_models.py`, `test_language_detection.py`

### 2. Testy Integracyjne (Integration Tests)

**Statystyki:** 63 testy (14% suite), czas wykonania 10-30s, cel: weryfikacja wspÃ³Å‚pracy komponentÃ³w

**Zakres pokrycia:**
- **API endpoints + baza danych:** CRUD operations, data persistence
- **Autentykacja JWT + autoryzacja:** Token validation, permission checks
- **CRUD projektÃ³w i person:** Lifecycle management
- **Integracja LangChain z Gemini API:** Z mockami dla szybkoÅ›ci
- **Focus groups orchestration:** PeÅ‚ny workflow dyskusji
- **Dashboard analytics:** Agregacje danych, usage tracking

**Markery:** `@pytest.mark.integration` (wymaga DB session), `@pytest.mark.external` (wymaga Gemini API key, opcjonalne)

**Kluczowe testy:**
- `test_generate_personas_success` - E2E generacja person z API
- `test_focus_groups_api_integration` - PeÅ‚ny flow grupy fokusowej
- `test_dashboard_orchestrator_pl_integration` - Dashboard analytics z polskimi danymi
- `test_auth_api_integration` - JWT authentication flow
- `test_projects_api_integration` - Project lifecycle management

**Kluczowe pliki:** `tests/integration/test_personas_api_integration.py`, `test_focus_groups_api_integration.py`, `test_surveys_api_integration.py`, `test_dashboard_api.py`, `test_auth_api_integration.py`, `test_projects_api_integration.py`

### 3. Testy End-to-End (E2E Tests)

**Statystyki:** 12 testÃ³w (2.7% suite), czas wykonania 2-5 minut, cel: weryfikacja peÅ‚nych scenariuszy uÅ¼ytkownika

**Zakres pokrycia:**
- **Rejestracja â†’ Projekt â†’ Generacja person â†’ Focus group â†’ Insights**
- **Survey workflow:** Utworzenie â†’ distribucja â†’ analiza odpowiedzi
- **CI smoke tests:** Weryfikacja podstawowej funkcjonalnoÅ›ci
- **Multi-user scenarios:** WspÃ³Å‚dzielenie projektÃ³w, permissions

**Kluczowy scenariusz:**
```python
def test_complete_research_workflow_end_to_end():
    """
    PeÅ‚ny flow:
    1. Rejestracja uÅ¼ytkownika (<1s)
    2. Utworzenie projektu (<1s)
    3. Generowanie 10 person (15-30s)
    4. Utworzenie focus group (<1s)
    5. Uruchomienie dyskusji 5 person Ã— 3 pytania (30-60s)
    6. Budowa grafu wiedzy (10-20s)
    7. Generowanie insights (5-10s)

    Oczekiwany czas: 90-180 sekund
    """
```

**Markery:** `@pytest.mark.e2e` (testy end-to-end), `@pytest.mark.slow` (testy >10s), `@pytest.mark.external` (wymagajÄ… Gemini API)

**Kluczowe pliki:** `tests/e2e/test_e2e_full_workflow.py`, `test_e2e_survey_workflow.py`, `test_e2e_ci_smoke.py`, `test_orchestration_smoke.py`

### 4. Testy WydajnoÅ›ciowe (Performance Tests)

**Statystyki:** 5 testÃ³w (1.1% suite), czas wykonania 5-10 minut, cel: weryfikacja speÅ‚nienia celÃ³w wydajnoÅ›ciowych (SLA)

**Cele wydajnoÅ›ciowe:**
- **Generowanie 20 person:** target <60s, ideal 30-45s
- **Focus group 20Ã—4:** target <3 min, ideal <2 min
- **Survey 10Ã—10:** target <60s
- **RAG hybrid search:** target <350ms
- **API response time:** target <500ms (P90)
- **DB query time:** target <100ms (P95)

**Markery:** `@pytest.mark.performance` (benchmark tests), `@pytest.mark.slow` (long-running tests)

**Kluczowy plik:** `tests/performance/test_performance.py`

### 5. Testy ObsÅ‚ugi BÅ‚Ä™dÃ³w (Error Handling Tests)

**Statystyki:** 9 testÃ³w (2% suite), czas wykonania 5-10s, cel: weryfikacja resilience i error recovery

**Zakres pokrycia:**
- **Timeout Gemini API â†’ 503 Service Unavailable**
- **Quota exceeded â†’ 429 Too Many Requests + retry logic**
- **Neo4j connection failures â†’ graceful degradation**
- **Malformed LLM responses â†’ JSON parsing errors**
- **Race conditions w generacji person**
- **Invalid demographic constraints**
- **Database connection pool exhaustion**

**Marker:** `@pytest.mark.error_handling`

**Kluczowy plik:** `tests/error_handling/test_error_handling.py`

## Organizacja TestÃ³w

### Struktura KatalogÃ³w

```
tests/
â”œâ”€â”€ conftest.py                    # Plugin orchestration
â”œâ”€â”€ fixtures/                      # Modular test fixtures (16 fixtures w 8 moduÅ‚ach)
â”‚   â”œâ”€â”€ api.py                    # API client fixtures
â”‚   â”œâ”€â”€ asyncio_loop.py           # Event loop fixtures
â”‚   â”œâ”€â”€ config.py                 # Configuration mocks
â”‚   â”œâ”€â”€ database.py               # DB session fixtures
â”‚   â”œâ”€â”€ mocks.py                  # LLM + service mocks
â”‚   â”œâ”€â”€ rag.py                    # RAG service mocks
â”‚   â”œâ”€â”€ samples.py                # Sample data (personas, projects)
â”‚   â””â”€â”€ utils.py                  # Test utilities
â”œâ”€â”€ unit/                          # 355 unit tests (<90s)
â”œâ”€â”€ integration/                   # 63 integration tests (10-30s)
â”œâ”€â”€ e2e/                           # 12 E2E tests (2-5 min)
â”œâ”€â”€ performance/                   # 5 performance tests (5-10 min)
â””â”€â”€ error_handling/                # 9 error handling tests (5-10s)
```

### Konwencje Nazewnictwa

**Pliki testowe:** `test_*.py` lub `*_test.py` - prefiks/sufiks `test_` wymagany przez pytest, nazwy opisowe odzwierciedlajÄ…ce testowany moduÅ‚.

**Funkcje testowe:**
```python
# Unit tests
def test_demographic_distribution_sums_to_one():
    """KRYTYCZNE: RozkÅ‚ady demograficzne muszÄ… sumowaÄ‡ siÄ™ do 1.0."""
    ...

# Async tests
@pytest.mark.asyncio
async def test_generate_personas_success(db_session):
    """Test pomyÅ›lnego wygenerowania person z API."""
    ...

# Parametrized tests
@pytest.mark.parametrize("age,gender,expected", [
    (25, "male", "young-male"),
    (45, "female", "middle-aged-female"),
])
def test_segment_classification(age, gender, expected):
    ...
```

### Markery TestÃ³w

System markerÃ³w pozwala na selektywne uruchamianie testÃ³w:

```python
# Kategorie testÃ³w
@pytest.mark.integration   # Wymaga DB session
@pytest.mark.e2e          # End-to-end workflow
@pytest.mark.performance  # Performance benchmark

# Charakterystyki
@pytest.mark.slow         # Testy >10s
@pytest.mark.external     # Wymaga Gemini API key

# Kontrola wykonania
@pytest.mark.skipif       # Warunkowe pomijanie
@pytest.mark.xfail        # Expected failures

# Parametryzacja
@pytest.mark.parametrize  # Data-driven tests
```

**UÅ¼ycie:**
```bash
pytest -v -m "not slow"                    # Tylko szybkie testy
pytest -v -m integration                   # Tylko testy integracyjne
pytest -v -m external                      # Testy wymagajÄ…ce Gemini API
pytest -v -m performance                   # Performance benchmarks
pytest -v -m "integration and not external" # Kombinacje markerÃ³w
```

## Kluczowe Fixtury Testowe

System fixtures wykorzystuje modularnÄ… architekturÄ™ (16 gÅ‚Ã³wnych fixtures w 8 moduÅ‚ach) eliminujÄ…cÄ… powtarzalny kod i przyspieszajÄ…cÄ… pisanie testÃ³w.

### 1. Database Fixtures (`tests/fixtures/database.py`)

```python
@pytest_asyncio.fixture(scope="session")
async def test_engine():
    """Izolowany async SQLAlchemy engine przeciw test_sight_db."""

@pytest_asyncio.fixture
async def db_session(test_engine) -> AsyncSession:
    """Transakcyjna AsyncSession z automatycznym rollbackiem po teÅ›cie."""
```

**UÅ¼ycie:** KaÅ¼dy test otrzymuje Å›wieÅ¼Ä… sesjÄ™ z automatycznym rollbackiem.

### 2. API Fixtures (`tests/fixtures/api.py`)

```python
@pytest.fixture
def api_client() -> TestClient:
    """FastAPI TestClient bez exception bubbling."""

@pytest.fixture
def auth_headers() -> dict[str, str]:
    """One-off JWT header dla authenticated requests."""

@pytest_asyncio.fixture
async def authenticated_client(db_session):
    """Zwraca: (TestClient, User, headers) - persisted user w DB, waÅ¼ny JWT token, gotowe headers."""

@pytest_asyncio.fixture
async def project_with_personas(db_session, authenticated_client):
    """Zwraca: (Project, List[Persona], TestClient, headers) - projekt z 10 deterministycznymi personami."""

@pytest_asyncio.fixture
async def completed_focus_group(db_session, project_with_personas):
    """Zwraca: (FocusGroup, List[PersonaResponse], TestClient, headers) - ukoÅ„czona grupa fokusowa z odpowiedziami."""
```

### 3. Mock Fixtures (`tests/fixtures/mocks.py`)

```python
@pytest.fixture
def mock_settings():
    """Deterministyczne ustawienia konfiguracji."""

@pytest.fixture
def mock_llm():
    """AsyncMock dla LangChain LLM interface."""

@pytest.fixture
def mock_datetime():
    """Freezing datetime.now() dla deterministycznych testÃ³w."""
```

### 4. RAG Fixtures (`tests/fixtures/rag.py`)

```python
@pytest.fixture
def mock_neo4j_driver():
    """AsyncMock dla Neo4j AsyncDriver."""

@pytest.fixture
def mock_vector_store():
    """Mock Neo4j vector store dla hybrid search tests."""

@pytest.fixture
def mock_embeddings():
    """Deterministyczne embeddingi (768 wymiarÃ³w) oparte na hash(text)."""

@pytest.fixture
def mock_gemini_2_5_pro():
    """AsyncMock dla Gemini 2.5 Pro z realistycznym allocation plan."""
```

### 5. Sample Data Fixtures (`tests/fixtures/samples.py`)

```python
@pytest.fixture
def sample_persona_dict():
    """Minimalna struktura persony dla schema/unit tests."""

@pytest.fixture
def sample_project_dict():
    """Minimalna struktura projektu z target demographics."""
```

## Metryki Pokrycia

### Aktualny Stan Pokrycia

| ModuÅ‚ | Cel | Aktualny | Gap | Status |
|-------|-----|----------|-----|--------|
| **app/services/** | 85%+ | ~87% | -2% | âœ… HIGH |
| app/services/personas/ | 90%+ | 92% | +2% | âœ… |
| app/services/focus_groups/ | 90%+ | 89% | -1% | âš ï¸ |
| app/services/rag/ | 85%+ | 84% | -1% | âš ï¸ |
| app/services/surveys/ | 85%+ | 81% | -4% | ğŸ”´ |
| **app/api/** | 85%+ | ~88% | +3% | âœ… |
| **app/models/** | 95%+ | ~96% | +1% | âœ… |
| **app/core/** | 90%+ | ~93% | +3% | âœ… |
| **app/db/** | 90%+ | ~91% | +1% | âœ… |
| **OgÃ³lnie** | 85%+ | ~87% | +2% | âœ… |

### Krytyczne Luki w Pokryciu

**ğŸ”´ app/services/surveys/survey_response_generator.py (81% - target: 85%+)**
- **Missing:** Error handling dla malformed questions, validation polskich znakÃ³w, edge case survey z 0 pytaÅ„, handling bardzo dÅ‚ugich odpowiedzi (>2000 chars)
- **Effort:** 2 dni | **Owner:** Backend Engineer

**ğŸ”´ app/services/rag/rag_graph_service.py (84% - target: 85%+)**
- **Missing:** Neo4j connection failure scenarios, Cypher query injection prevention, graph transformation edge cases, performance test dla 1000+ nodes
- **Effort:** 3 dni | **Owner:** RAG Engineer

**âš ï¸ app/services/focus_groups/discussion_summarizer.py (89% - target: 90%+)**
- **Missing:** Summarization z dÅ‚ugimi odpowiedziami (>2000 tokens), Polish sentiment analysis accuracy tests, multi-language mixing (PL/EN)
- **Effort:** 2 dni | **Owner:** NLP Engineer

**âš ï¸ Integration Tests dla Neo4j Graph Operations**
- **Status:** Brak testÃ³w integracyjnych dla peÅ‚nego flow RAG Graph
- **Gap:** Testy jednostkowe OK, brakuje weryfikacji z prawdziwym Neo4j
- **Effort:** 5 dni | **Owner:** Backend Engineer + QA

**Znane wykluczone obszary:** `app/main.py` (FastAPI startup/shutdown testowane przez E2E), `app/core/config.py` (statyczna konfiguracja validowana przez pytest-env), `scripts/` (narzÄ™dzia administracyjne - manual testing), `migrations/` (Alembic - testowane manualnie)

## Benchmarki WydajnoÅ›ciowe

### Cele WydajnoÅ›ciowe (SLA Targets)

| Operacja | Target | Idealny | Aktualny | Status |
|----------|--------|---------|----------|--------|
| **Generacja 20 person** | <60s | 30-45s | ~45s | âœ… GREEN |
| **Focus group 20Ã—4** | <3 min | <2 min | ~2 min | âœ… GREEN |
| **Survey 10Ã—10** | <60s | 30-45s | ~40s | âœ… GREEN |
| **RAG hybrid search** | <350ms | <200ms | ~280ms | âœ… GREEN |
| **API response (90%ile)** | <500ms | <300ms | ~380ms | âœ… GREEN |
| **DB query (95%ile)** | <100ms | <50ms | ~65ms | âœ… GREEN |

### SzczegÃ³Å‚y Performance Tests

**1. Persona Generation Performance**

Test: `test_persona_generation_performance_20_personas` - TARGET <60s, IDEAL 30-45s

Komponenty: Orchestration (5-10s) + RAG queries (5-10s) + LLM calls 20x parallel (20-30s) + Validation chi-square (1-2s) + DB persistence batch insert (2-5s)

**Aktualne wyniki:** Mean: 45.2s, P50: 44.8s, P90: 52.3s, P99: 58.7s

**Bottlenecki:** Gemini API rate limiting (5 RPM bez quota increase), network latency do Google API (~150-200ms per request), JSON parsing dla zÅ‚oÅ¼onych allocation plans

**Optymalizacje:** Async/await parallel execution (20x faster niÅ¼ sequential), caching segment briefs (Redis, 24h TTL), batch LLM requests gdzie moÅ¼liwe

**2. Focus Group Performance**

Test: `test_focus_group_discussion_performance` - TARGET <3 min, IDEAL <2 min

Komponenty: Memory loading (5-10s) + LLM calls 80x parallel (60-90s) + Response persistence batch insert (5-10s) + Summarization (10-20s)

**Aktualne wyniki:** Mean: 118.4s, P50: 115.2s, P90: 135.8s, P99: 158.3s

**3. RAG Hybrid Search Performance**

Test: `test_rag_hybrid_search_latency` - TARGET <350ms, IDEAL <200ms

Komponenty: Vector search embedding + similarity (100-150ms) + Fulltext search Neo4j Lucene (50-80ms) + RRF fusion (20-40ms) + Graph enrichment optional (+50-100ms)

**Aktualne wyniki:** Mean: 278ms, P50: 265ms, P90: 315ms, P99: 358ms (âš ï¸ powyÅ¼ej targetu)

**Optymalizacje planowane:** Neo4j index tuning (FULLTEXT â†’ VECTOR hybrid index), embedding caching dla popularnych zapytaÅ„, connection pooling dla Neo4j driver

## Uruchamianie TestÃ³w

### Podstawowe Komendy

```bash
# DomyÅ›lny zestaw testÃ³w (szybkie)
pytest -v

# Wszystkie testy (wÅ‚Ä…cznie z wolnymi)
pytest -v --run-slow

# Testy z raportem pokrycia
pytest -v --cov=app --cov-report=html

# Tylko testy jednostkowe (~90s)
pytest tests/unit -v

# Tylko testy integracyjne (10-30s)
pytest tests/integration -v

# Testy end-to-end (2-5 min)
pytest tests/e2e/ -v --run-slow --run-external -s

# Performance benchmarks (5-10 min)
pytest tests/performance/ -v --run-slow --run-external

# Tylko szybkie testy (bez markerÃ³w slow)
pytest -v -m "not slow"

# Testy wymagajÄ…ce Gemini API
pytest -v -m external --run-external

# Kombinacje markerÃ³w
pytest -v -m "integration and not external"
```

### Pokrycie Kodu

```bash
# Raport HTML (najlepszy dla eksploracji)
pytest --cov=app --cov-report=html
open htmlcov/index.html

# Raport terminal (szybki overview)
pytest --cov=app --cov-report=term

# Raport XML (dla CI/CD)
pytest --cov=app --cov-report=xml

# Fail build jeÅ›li pokrycie <85%
pytest --cov=app --cov-fail-under=85

# Pokrycie tylko dla serwisÃ³w
pytest --cov=app/services --cov-report=term
```

## Integracja CI/CD

### Strategia CI/CD

**PR Workflow:**

**1. Fast Feedback (2-5 min):**
- Unit tests (355 testÃ³w, ~90s)
- Error handling tests (9 testÃ³w, ~10s)
- Linting (ruff check, ~5s)
- Coverage threshold check (85%+)

**2. Integration Tests (5-10 min):**
- API + DB tests (63 testy, ~30s)
- Mocked external services (bez Gemini API)
- Redis + Neo4j + PostgreSQL w Docker

**3. E2E Smoke Tests (opcjonalne, 5-10 min):**
- Tylko na main branch
- Wymaga Gemini API key w secrets
- Smoke tests: podstawowe user flows

**Nightly Builds:**
- PeÅ‚na suita testÃ³w (wszystkie 444 testy)
- Performance benchmarks
- External service integration (prawdziwy Gemini API)
- Coverage report + trends

### Coverage Tracking

```bash
# Lokalnie
pytest --cov=app --cov-report=html --cov-report=term

# CI/CD
pytest --cov=app --cov-report=xml --cov-fail-under=85
```

**Thresholdy:**
- Overall: 85% (fail build jeÅ›li <85%)
- Services: 85% (warning jeÅ›li <85%)
- Critical paths: 90% (fail build jeÅ›li <90%)

**Codecov Integration (zalecane):**
- Automatyczne komentarze na PR z coverage diff
- Trend tracking (coverage over time)
- File-level coverage heatmaps

## Bramy JakoÅ›ci (Quality Gates)

### Checklist Przed Deploymentem na ProdukcjÄ™

**âœ… Testy**
- [ ] **Wszystkie testy przechodzÄ…:** `pytest -v` (444/444 âœ…)
- [ ] **Pokrycie â‰¥85% overall:** `pytest --cov=app --cov-report=term`
- [ ] **Pokrycie â‰¥85% services:** `pytest --cov=app/services`
- [ ] **Pokrycie â‰¥90% critical paths:** `pytest tests/unit/test_critical_paths.py --cov`
- [ ] **Zero testÃ³w skipped (oprÃ³cz known xfails):** Max 5 skipped
- [ ] **Brak flaky tests:** 3x consecutive passes

**âœ… Performance**
- [ ] **Generacja 20 person <60s:** `pytest -v -m performance -k persona_generation`
- [ ] **Focus group 20Ã—4 <3min:** `pytest -v -m performance -k focus_group`
- [ ] **RAG hybrid search <350ms:** `pytest -v -m performance -k hybrid_search`
- [ ] **API response time <500ms (P90):** Load testing z Locust
- [ ] **DB query time <100ms (P95):** Monitoring z Datadog/New Relic

**âœ… Code Quality**
- [ ] **Linting passes:** `ruff check app/` (zero errors)
- [ ] **No high-severity bugs:** SonarQube/CodeQL scan
- [ ] **No security vulnerabilities:** `pip-audit` + Snyk scan

**âœ… Infrastructure**
- [ ] **Migracje zastosowane:** `alembic upgrade head`
- [ ] **Neo4j indeksy utworzone:** `python scripts/init_neo4j_indexes.py`
- [ ] **Redis dziaÅ‚a:** `docker-compose up redis -d && redis-cli ping`

**âœ… Configuration**
- [ ] **Zmienne Å›rodowiskowe ustawione:** SECRET_KEY, GOOGLE_API_KEY, DATABASE_URL, NEO4J_URI, REDIS_URL, ENVIRONMENT=production
- [ ] **Config validation passes:** `python scripts/config_validate.py`
- [ ] **No secrets in code/git history:** `git secrets --scan`

## Znany DÅ‚ug Techniczny (Testing Focus)

### ğŸ”´ Priorytet 1: Krytyczne Luki (Q1 2025)

**1. BrakujÄ…ce E2E Testy dla Survey Workflows**
- **Status:** CzÄ™Å›ciowe pokrycie (1 E2E test, brak edge cases)
- **Impact:** HIGH - Survey functionality nie ma comprehensive E2E coverage
- **Gap:** Survey creation z validation errors, distribution do 50+ person (performance), response analysis + insights, export results (CSV, PDF)
- **Effort:** 3-5 dni | **Owner:** QA Engineer

**2. Integration Tests dla Neo4j Graph Operations**
- **Status:** Unit tests OK, brakuje integration tests z prawdziwym Neo4j
- **Impact:** HIGH - RAG Graph functionality nie ma weryfikacji z prawdziwÄ… bazÄ…
- **Gap:** Full graph ingestion workflow (documents â†’ chunks â†’ embeddings â†’ Neo4j), Cypher query generation + execution (z prawdziwym LLM), graph traversal dla complex queries, performance testing dla 1000+ nodes
- **Effort:** 5-7 dni | **Owner:** Backend Engineer + QA

**3. Performance Tests dla 100+ Persona Generation**
- **Status:** Brak testÃ³w dla duÅ¼ych projektÃ³w (max tested: 20 person)
- **Impact:** MEDIUM - Nie wiemy jak system siÄ™ zachowa przy 100+ personach
- **Gap:** Generacja 100 person, memory consumption test (czy nie OOM), DB performance (batch inserts, indexy), LLM rate limiting handling (Gemini API quota)
- **Effort:** 2-3 dni | **Owner:** Performance Engineer

### âš ï¸ Priorytet 2: WaÅ¼ne Luki (Q2 2025)

**4. Security Tests (SQL Injection, XSS, Auth Bypass)**
- **Status:** Brak dedykowanych security tests
- **Impact:** MEDIUM - Potencjalne security vulnerabilities
- **Gap:** SQL injection prevention tests, XSS prevention tests, auth bypass tests (JWT validation), CSRF protection tests, rate limiting bypass tests
- **Effort:** 3-4 dni | **Owner:** Security Engineer + QA

**5. Load Tests dla Concurrent Users**
- **Status:** Brak load testÃ³w
- **Impact:** MEDIUM - Nie wiemy jak system siÄ™ zachowa przy 10+ concurrent users
- **Gap:** 10 concurrent users generating personas, 5 concurrent focus groups, DB connection pooling stress test, Redis cache hit rate under load
- **Effort:** 2-3 dni | **Owner:** Performance Engineer | **Tools:** Locust, k6, Artillery

**6. Polish NLP Edge Cases**
- **Status:** Podstawowe testy OK, brakuje edge cases
- **Impact:** LOW - Edge cases dla polskich znakÃ³w specjalnych
- **Gap:** Polskie znaki w odpowiedziach, sentiment analysis accuracy dla polskich idiomÃ³w, language detection dla mixed PL/EN, tokenization dla dÅ‚ugich sÅ‚Ã³w (>30 znakÃ³w)
- **Effort:** 1-2 dni | **Owner:** NLP Engineer

## RozwiÄ…zywanie ProblemÃ³w

### Top 5 Typowych ProblemÃ³w

**1. Brak poÅ‚Ä…czenia z bazÄ… danych**
- **Objawy:** Testy integracyjne failujÄ… z connection refused, `sqlalchemy.exc.OperationalError`
- **RozwiÄ…zanie:**
  ```bash
  docker-compose ps                           # SprawdÅº status
  docker-compose up -d postgres              # Uruchom bazÄ™
  docker-compose exec postgres psql -U sight -d sight_db -c "SELECT 1"  # Zweryfikuj
  docker-compose logs postgres               # SprawdÅº logi
  ```

**2. Problemy z Gemini API**
- **Objawy:** Testy external failujÄ… z 401 Unauthorized, `google.api_core.exceptions.Unauthenticated`
- **RozwiÄ…zanie:**
  ```bash
  echo $GOOGLE_API_KEY                       # Zweryfikuj klucz
  # SprawdÅº quota: https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas
  pytest -v -m "not external"                # PomiÅ„ testy wymagajÄ…ce API
  ```

**3. Testy E2E nie uruchamiajÄ… siÄ™**
- **Objawy:** E2E tests sÄ… skipowane, `skipped: use --run-slow --run-external to run`
- **RozwiÄ…zanie:**
  ```bash
  pytest tests/e2e/ -v --run-slow --run-external -s  # UÅ¼yj wymaganych flag
  # Lub ustaw zmienne Å›rodowiskowe:
  export RUN_SLOW_TESTS=1
  export RUN_EXTERNAL_TESTS=1
  pytest tests/e2e/ -v
  ```

**4. Flaky Tests (niestabilne testy)**
- **Objawy:** Testy czasami przechodzÄ…, czasami failujÄ…, race conditions w testach async
- **RozwiÄ…zanie:**
  ```bash
  pytest -v tests/integration/test_focus_groups_api.py --count=10  # Uruchom wielokrotnie
  pip install pytest-repeat
  pytest -v --count=10 tests/integration/     # UÅ¼yj pytest-repeat
  pytest -v -s tests/integration/test_focus_groups_api.py  # Debug z verbose
  ```

**5. Neo4j connection failures w testach**
- **Objawy:** `neo4j.exceptions.ServiceUnavailable: Could not connect to Neo4j`
- **RozwiÄ…zanie:**
  ```bash
  docker-compose up -d neo4j                 # Uruchom Neo4j
  docker-compose exec neo4j cypher-shell -u neo4j -p testpassword "RETURN 1"  # SprawdÅº
  python scripts/init_neo4j_indexes.py       # Zainicjuj indeksy
  ```

## Podsumowanie

### Silne Strony

âœ… **Wysoka piramida testÃ³w:** 80% unit, 14% integration, 3% E2E - optymalna dystrybucja dla szybkiego feedback

âœ… **Pokrycie >85%:** Overall 87%, services 87%, models 96% - przekraczamy cele jakoÅ›ci

âœ… **Modularny system fixtures:** 16 fixtures w 8 moduÅ‚ach - eliminacja powtarzalnego kodu

âœ… **Performance benchmarks:** Wszystkie SLA targets speÅ‚nione - system jest wydajny

âœ… **Fast feedback:** Unit tests <90s - deweloperzy dostajÄ… szybkÄ… informacjÄ™ zwrotnÄ…

âœ… **Comprehensive test categories:** Unit, integration, E2E, performance, error handling - peÅ‚ne spektrum testowania

### Obszary do Poprawy

ğŸ”´ **E2E coverage:** Brak comprehensive survey workflow tests - potrzebne peÅ‚ne testy end-to-end dla ankiet

ğŸ”´ **Integration tests:** Neo4j graph operations nie przetestowane z prawdziwÄ… bazÄ… - ryzyko dla RAG functionality

ğŸ”´ **Large scale tests:** Brak testÃ³w dla 100+ person - nie wiemy jak system siÄ™ skaluje

âš ï¸ **Security tests:** Brak dedykowanych security tests (SQL injection, XSS) - potencjalne luki bezpieczeÅ„stwa

âš ï¸ **Load tests:** Brak testÃ³w dla concurrent users - nie wiemy jak system radzi sobie pod obciÄ…Å¼eniem

âš ï¸ **Polish NLP edge cases:** Podstawowe testy OK, brakuje edge cases - ryzyko dla polskich znakÃ³w specjalnych

### Roadmap Q1-Q2 2025

**Q1 2025:**
1. Implementacja E2E testÃ³w dla survey workflows (ğŸ”´ Priority 1, 3-5 dni)
2. Integration tests dla Neo4j graph operations (ğŸ”´ Priority 1, 5-7 dni)
3. Performance tests dla 100+ persona generation (ğŸ”´ Priority 1, 2-3 dni)

**Q2 2025:**
4. Security test suite (âš ï¸ Priority 2, 3-4 dni)
5. Load testing z Locust (âš ï¸ Priority 2, 2-3 dni)
6. Polish NLP edge cases (âš ï¸ Priority 2, 1-2 dni)

### Metryki Sukcesu

**KrÃ³tkoterminowe (Q1 2025):**
- [ ] Pokrycie E2E dla survey workflows: 0% â†’ 90%
- [ ] Integration tests dla Neo4j: 0 testÃ³w â†’ 5+ testÃ³w
- [ ] Performance tests dla 100 person: brak â†’ test passing <5min

**Åšrednioterminowe (Q2 2025):**
- [ ] Security test suite: 0 testÃ³w â†’ 15+ testÃ³w
- [ ] Load tests: brak â†’ 10 concurrent users tested
- [ ] Overall coverage: 87% â†’ 90%

**DÅ‚ugoterminowe (H2 2025):**
- [ ] CI/CD fully automated z GitHub Actions
- [ ] Codecov integration z PR comments
- [ ] Nightly builds z full external test suite
- [ ] Visual regression tests dla kluczowych UI flows

---

**Ostatnia aktualizacja:** 2025-11-03 | **Wersja dokumentu:** 2.3 | **Odpowiedzialny:** QA Engineering Team
