"""Graph enrichment dla hybrid search results.

ModuÅ‚ odpowiada za:
- Formatowanie graph nodes do czytelnego kontekstu dla LLM
- Znajdowanie graph nodes powiÄ…zanych z chunkami
- Wzbogacanie chunkÃ³w o powiÄ…zane graph nodes
"""

import inspect
import logging
from typing import Any

from langchain_core.documents import Document

logger = logging.getLogger(__name__)


def format_graph_context(graph_nodes: list[dict[str, Any]]) -> str:
    """Formatuje wÄ™zÅ‚y grafu do czytelnego kontekstu tekstowego dla LLM.

    Args:
        graph_nodes: Lista wÄ™zÅ‚Ã³w z grafu z wÅ‚aÅ›ciwoÅ›ciami

    Returns:
        Sformatowany string z strukturalnÄ… wiedzÄ… z grafu
    """
    # DEFENSIVE CHECK: Validate input type
    if inspect.iscoroutine(graph_nodes):
        logger.error(
            "âŒ BUG: format_graph_context received a coroutine instead of list! "
            "This indicates a serious bug in the call chain. Cleaning up and returning empty string."
        )
        graph_nodes.close()
        return ""

    if not isinstance(graph_nodes, list):
        logger.error(
            "âŒ BUG: format_graph_context received %s instead of list! "
            "Returning empty string to prevent crash",
            type(graph_nodes).__name__
        )
        return ""

    if not graph_nodes:
        return ""

    # Grupuj wÄ™zÅ‚y po typie
    indicators = [n for n in graph_nodes if n.get('type') == 'Wskaznik']
    observations = [n for n in graph_nodes if n.get('type') == 'Obserwacja']
    trends = [n for n in graph_nodes if n.get('type') == 'Trend']
    demographics = [n for n in graph_nodes if n.get('type') == 'Demografia']

    sections = []

    # Sekcja WskaÅºniki
    if indicators:
        sections.append("ğŸ“Š WSKAÅ¹NIKI DEMOGRAFICZNE (Wskaznik):\n")
        for ind in indicators:
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = ind.get('streszczenie') or ind.get('summary', 'Brak podsumowania')
            skala = ind.get('skala') or ind.get('magnitude', 'N/A')
            pewnosc = ind.get('pewnosc') or ind.get('confidence_level', 'N/A')
            kluczowe_fakty = ind.get('kluczowe_fakty') or ind.get('key_facts', '')
            okres_czasu = ind.get('okres_czasu') or ind.get('time_period', '')

            sections.append(f"â€¢ {streszczenie}")
            if skala and skala != 'N/A':
                sections.append(f"  WielkoÅ›Ä‡: {skala}")
            if okres_czasu:
                sections.append(f"  Okres: {okres_czasu}")
            sections.append(f"  PewnoÅ›Ä‡: {pewnosc}")
            if kluczowe_fakty:
                sections.append(f"  Kluczowe fakty: {kluczowe_fakty}")
            sections.append("")

    # Sekcja Obserwacje
    if observations:
        sections.append("\nğŸ‘¥ OBSERWACJE DEMOGRAFICZNE (Obserwacja):\n")
        for obs in observations:
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = obs.get('streszczenie') or obs.get('summary', 'Brak podsumowania')
            pewnosc = obs.get('pewnosc') or obs.get('confidence_level', 'N/A')
            kluczowe_fakty = obs.get('kluczowe_fakty') or obs.get('key_facts', '')
            okres_czasu = obs.get('okres_czasu') or obs.get('time_period', '')

            sections.append(f"â€¢ {streszczenie}")
            sections.append(f"  PewnoÅ›Ä‡: {pewnosc}")
            if okres_czasu:
                sections.append(f"  Okres: {okres_czasu}")
            if kluczowe_fakty:
                sections.append(f"  Kluczowe fakty: {kluczowe_fakty}")
            sections.append("")

    # Sekcja Trendy
    if trends:
        sections.append("\nğŸ“ˆ TRENDY DEMOGRAFICZNE (Trend):\n")
        for trend in trends:
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = trend.get('streszczenie') or trend.get('summary', 'Brak podsumowania')
            okres_czasu = trend.get('okres_czasu') or trend.get('time_period', 'N/A')
            kluczowe_fakty = trend.get('kluczowe_fakty') or trend.get('key_facts', '')

            sections.append(f"â€¢ {streszczenie}")
            sections.append(f"  Okres: {okres_czasu}")
            if kluczowe_fakty:
                sections.append(f"  Kluczowe fakty: {kluczowe_fakty}")
            sections.append("")

    # Sekcja Demografia
    if demographics:
        sections.append("\nğŸ¯ GRUPY DEMOGRAFICZNE (Demografia):\n")
        for demo in demographics:
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = demo.get('streszczenie') or demo.get('summary', 'Brak podsumowania')
            pewnosc = demo.get('pewnosc') or demo.get('confidence_level', 'N/A')
            kluczowe_fakty = demo.get('kluczowe_fakty') or demo.get('key_facts', '')

            sections.append(f"â€¢ {streszczenie}")
            sections.append(f"  PewnoÅ›Ä‡: {pewnosc}")
            if kluczowe_fakty:
                sections.append(f"  Kluczowe fakty: {kluczowe_fakty}")
            sections.append("")

    return "\n".join(sections)


def find_related_graph_nodes(
    chunk_doc: Document,
    graph_nodes: list[dict[str, Any]]
) -> list[dict[str, Any]]:
    """ZnajdÅº graph nodes ktÃ³re sÄ… powiÄ…zane z danym chunkiem.

    Matching bazuje na:
    1. WspÃ³lnych sÅ‚owach kluczowych (z summary/key_facts)
    2. Dokumencie ÅºrÃ³dÅ‚owym (doc_id)

    Args:
        chunk_doc: Document chunk z vector/keyword search
        graph_nodes: Lista graph nodes z get_demographic_graph_context()

    Returns:
        Lista graph nodes ktÃ³re sÄ… powiÄ…zane z chunkiem
    """
    # DEFENSIVE CHECK: Validate input type
    if inspect.iscoroutine(graph_nodes):
        logger.error(
            "âŒ BUG: find_related_graph_nodes received a coroutine instead of list! "
            "Cleaning up and returning empty list."
        )
        graph_nodes.close()
        return []

    if not isinstance(graph_nodes, list):
        logger.error(
            "âŒ BUG: find_related_graph_nodes received %s instead of list!",
            type(graph_nodes).__name__
        )
        return []

    if not graph_nodes:
        return []

    related = []
    chunk_text = chunk_doc.page_content.lower()
    chunk_doc_id = chunk_doc.metadata.get('doc_id', '')

    for node in graph_nodes:
        # SprawdÅº czy node pochodzi z tego samego dokumentu
        node_doc_id = node.get('doc_id', '')
        if node_doc_id and node_doc_id == chunk_doc_id:
            related.append(node)
            continue

        # SprawdÅº overlap sÅ‚Ã³w kluczowych
        # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
        summary = (node.get('streszczenie') or node.get('summary', '') or '').lower()
        key_facts = (node.get('kluczowe_fakty') or node.get('key_facts', '') or '').lower()

        # Ekstraktuj sÅ‚owa kluczowe (> 5 chars)
        summary_words = {w for w in summary.split() if len(w) > 5}
        key_facts_words = {w for w in key_facts.split() if len(w) > 5}
        node_keywords = summary_words | key_facts_words

        # Policz overlap
        matches = sum(1 for keyword in node_keywords if keyword in chunk_text)

        # JeÅ›li >=2 matching keywords, uznaj za related
        if matches >= 2:
            related.append(node)

    return related


def enrich_chunk_with_graph(
    chunk_text: str,
    related_nodes: list[dict[str, Any]]
) -> str:
    """WzbogaÄ‡ chunk o powiÄ…zane graph nodes w naturalny sposÃ³b.

    Args:
        chunk_text: Oryginalny tekst chunku
        related_nodes: PowiÄ…zane graph nodes

    Returns:
        Enriched chunk text z embedded graph context
    """
    if not related_nodes:
        return chunk_text

    # Grupuj nodes po typie
    indicators = [n for n in related_nodes if n.get('type') == 'Wskaznik']
    observations = [n for n in related_nodes if n.get('type') == 'Obserwacja']
    trends = [n for n in related_nodes if n.get('type') == 'Trend']

    enrichments = []

    # Dodaj wskaÅºniki
    if indicators:
        enrichments.append("\nğŸ’¡ PowiÄ…zane wskaÅºniki:")
        for ind in indicators[:2]:  # Max 2 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = ind.get('streszczenie') or ind.get('summary', '')
            skala = ind.get('skala') or ind.get('magnitude', '')
            if streszczenie:
                if skala:
                    enrichments.append(f"  â€¢ {streszczenie} ({skala})")
                else:
                    enrichments.append(f"  â€¢ {streszczenie}")

    # Dodaj obserwacje
    if observations:
        enrichments.append("\nğŸ” PowiÄ…zane obserwacje:")
        for obs in observations[:2]:  # Max 2 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = obs.get('streszczenie') or obs.get('summary', '')
            if streszczenie:
                enrichments.append(f"  â€¢ {streszczenie}")

    # Dodaj trendy
    if trends:
        enrichments.append("\nğŸ“ˆ PowiÄ…zane trendy:")
        for trend in trends[:1]:  # Max 1 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = trend.get('streszczenie') or trend.get('summary', '')
            okres_czasu = trend.get('okres_czasu') or trend.get('time_period', '')
            if streszczenie:
                if okres_czasu:
                    enrichments.append(f"  â€¢ {streszczenie} ({okres_czasu})")
                else:
                    enrichments.append(f"  â€¢ {streszczenie}")

    if enrichments:
        return chunk_text + "\n" + "\n".join(enrichments)
    else:
        return chunk_text
