"""Wzbogacanie chunkÃ³w o kontekst z grafu Neo4j.

ModuÅ‚ odpowiada za:
- Znajdowanie graph nodes powiÄ…zanych z chunkiem (matching via keywords/doc_id)
- Wzbogacanie tekstu chunku o powiÄ…zane wskaÅºniki, obserwacje i trendy
"""

import inspect
import logging
from typing import List, Dict, Any

from langchain_core.documents import Document

logger = logging.getLogger(__name__)


def find_related_graph_nodes(
    chunk_doc: Document,
    graph_nodes: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """ZnajdÅº graph nodes ktÃ³re sÄ… powiÄ…zane z danym chunkiem.

    Matching bazuje na:
    1. WspÃ³lnych sÅ‚owach kluczowych (z summary/key_facts)
    2. Dokumencie ÅºrÃ³dÅ‚owym (doc_id)

    Args:
        chunk_doc: Document chunk z vector/keyword search
        graph_nodes: Lista graph nodes z get_demographic_graph_context()

    Returns:
        Lista graph nodes ktÃ³re sÄ… powiÄ…zane z chunkiem
    """
    # DEFENSIVE CHECK: Validate input type
    if inspect.iscoroutine(graph_nodes):
        logger.error(
            "âŒ BUG: find_related_graph_nodes received a coroutine instead of list! "
            "Cleaning up and returning empty list."
        )
        graph_nodes.close()
        return []

    if not isinstance(graph_nodes, list):
        logger.error(
            "âŒ BUG: find_related_graph_nodes received %s instead of list!",
            type(graph_nodes).__name__
        )
        return []

    if not graph_nodes:
        return []

    related = []
    chunk_text = chunk_doc.page_content.lower()
    chunk_doc_id = chunk_doc.metadata.get('doc_id', '')

    for node in graph_nodes:
        # SprawdÅº czy node pochodzi z tego samego dokumentu
        node_doc_id = node.get('doc_id', '')
        if node_doc_id and node_doc_id == chunk_doc_id:
            related.append(node)
            continue

        # SprawdÅº overlap sÅ‚Ã³w kluczowych
        # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
        summary = (node.get('streszczenie') or node.get('summary', '') or '').lower()
        key_facts = (node.get('kluczowe_fakty') or node.get('key_facts', '') or '').lower()

        # Ekstraktuj sÅ‚owa kluczowe (> 5 chars)
        summary_words = {w for w in summary.split() if len(w) > 5}
        key_facts_words = {w for w in key_facts.split() if len(w) > 5}
        node_keywords = summary_words | key_facts_words

        # Policz overlap
        matches = sum(1 for keyword in node_keywords if keyword in chunk_text)

        # JeÅ›li >=2 matching keywords, uznaj za related
        if matches >= 2:
            related.append(node)

    return related


def enrich_chunk_with_graph(
    chunk_text: str,
    related_nodes: List[Dict[str, Any]]
) -> str:
    """WzbogaÄ‡ chunk o powiÄ…zane graph nodes w naturalny sposÃ³b.

    Args:
        chunk_text: Oryginalny tekst chunku
        related_nodes: PowiÄ…zane graph nodes

    Returns:
        Enriched chunk text z embedded graph context
    """
    if not related_nodes:
        return chunk_text

    # Grupuj nodes po typie
    indicators = [n for n in related_nodes if n.get('type') == 'Wskaznik']
    observations = [n for n in related_nodes if n.get('type') == 'Obserwacja']
    trends = [n for n in related_nodes if n.get('type') == 'Trend']

    enrichments = []

    # Dodaj wskaÅºniki
    if indicators:
        enrichments.append("\nğŸ’¡ PowiÄ…zane wskaÅºniki:")
        for ind in indicators[:2]:  # Max 2 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = ind.get('streszczenie') or ind.get('summary', '')
            skala = ind.get('skala') or ind.get('magnitude', '')
            if streszczenie:
                if skala:
                    enrichments.append(f"  â€¢ {streszczenie} ({skala})")
                else:
                    enrichments.append(f"  â€¢ {streszczenie}")

    # Dodaj obserwacje
    if observations:
        enrichments.append("\nğŸ” PowiÄ…zane obserwacje:")
        for obs in observations[:2]:  # Max 2 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = obs.get('streszczenie') or obs.get('summary', '')
            if streszczenie:
                enrichments.append(f"  â€¢ {streszczenie}")

    # Dodaj trendy
    if trends:
        enrichments.append("\nğŸ“ˆ PowiÄ…zane trendy:")
        for trend in trends[:1]:  # Max 1 na chunk
            # Backward compatibility: uÅ¼ywaj nowych nazw z fallbackiem na stare
            streszczenie = trend.get('streszczenie') or trend.get('summary', '')
            okres_czasu = trend.get('okres_czasu') or trend.get('time_period', '')
            if streszczenie:
                if okres_czasu:
                    enrichments.append(f"  â€¢ {streszczenie} ({okres_czasu})")
                else:
                    enrichments.append(f"  â€¢ {streszczenie}")

    if enrichments:
        return chunk_text + "\n" + "\n".join(enrichments)
    else:
        return chunk_text
