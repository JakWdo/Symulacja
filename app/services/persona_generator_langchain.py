"""
Generator Person oparty na LangChain i Google Gemini

Ten modu≈Ç generuje realistyczne, statystycznie reprezentatywne persony
dla bada≈Ñ rynkowych przy u≈ºyciu Google Gemini przez framework LangChain.

Kluczowe funkcjonalno≈õci:
- Generowanie person zgodnie z zadanymi rozk≈Çadami demograficznymi
- Walidacja statystyczna przy u≈ºyciu testu chi-kwadrat
- Sampling cech osobowo≈õci (Big Five) i wymiar√≥w kulturowych (Hofstede)
- Integracja z LangChain dla ≈Çatwej zmiany modelu LLM
"""

import numpy as np
from typing import Dict, List, Any, Tuple, Optional
from scipy import stats
from dataclasses import dataclass

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnablePassthrough

from app.core.config import get_settings
from app.core.constants import (
    DEFAULT_AGE_GROUPS,
    DEFAULT_GENDERS,
    DEFAULT_EDUCATION_LEVELS,
    DEFAULT_INCOME_BRACKETS,
    DEFAULT_LOCATIONS,
    POLISH_LOCATIONS,
    POLISH_VALUES,
    POLISH_INTERESTS,
    POLISH_COMMUNICATION_STYLES,
    POLISH_DECISION_STYLES,
    POLISH_INCOME_BRACKETS,
    POLISH_EDUCATION_LEVELS,
    POLISH_MALE_NAMES,
    POLISH_FEMALE_NAMES,
    POLISH_SURNAMES,
)
from app.models import Persona

settings = get_settings()

# Import RAG service (opcjonalny - tylko je≈õli RAG w≈ÇƒÖczony)
try:
    if settings.RAG_ENABLED:
        from app.services.rag_service import PolishSocietyRAG
        _rag_service_available = True
    else:
        _rag_service_available = False
except ImportError:
    _rag_service_available = False


@dataclass
class DemographicDistribution:
    """
    Rozk≈Çad demograficzny populacji docelowej

    Ka≈ºde pole to s≈Çownik mapujƒÖcy kategorie na prawdopodobie≈Ñstwa (sumujƒÖce siƒô do 1.0)
    Przyk≈Çad: {"18-24": 0.3, "25-34": 0.5, "35-44": 0.2}
    """
    age_groups: Dict[str, float]        # Grupy wiekowe
    genders: Dict[str, float]           # P≈Çeƒá
    education_levels: Dict[str, float]  # Poziomy edukacji
    income_brackets: Dict[str, float]   # Przedzia≈Çy dochodowe
    locations: Dict[str, float]         # Lokalizacje geograficzne


class PersonaGeneratorLangChain:
    """
    Generator statystycznie reprezentatywnych person przy u≈ºyciu LangChain + Gemini

    U≈ºywa Google Gemini do generowania realistycznych profili person na podstawie
    zadanych rozk≈Çad√≥w demograficznych i psychologicznych.
    """

    def __init__(self):
        """Inicjalizuj generator z konfiguracjƒÖ LangChain i Gemini"""
        import logging
        logger = logging.getLogger(__name__)

        self.settings = settings
        self._rng = np.random.default_rng(self.settings.RANDOM_SEED)

        # Inicjalizujemy model Gemini z wy≈ºszƒÖ temperaturƒÖ dla wiƒôkszej r√≥≈ºnorodno≈õci
        persona_model = getattr(settings, "PERSONA_GENERATION_MODEL", settings.DEFAULT_MODEL)

        self.llm = ChatGoogleGenerativeAI(
            model=persona_model,
            google_api_key=settings.GOOGLE_API_KEY,
            temperature=0.9,  # Podniesiona warto≈õƒá dla bardziej kreatywnych, zr√≥≈ºnicowanych person
            max_tokens=settings.MAX_TOKENS,
            top_p=0.95,
            top_k=40,
        )

        # Konfigurujemy parser JSON, aby wymusiƒá strukturalnƒÖ odpowied≈∫
        self.json_parser = JsonOutputParser()

        # Budujemy szablon promptu do generowania person
        self.persona_prompt = ChatPromptTemplate.from_messages([
            ("system", "Jeste≈õ ekspertem od bada≈Ñ rynkowych tworzƒÖcym realistyczne syntetyczne persony dla polskiego rynku. Zawsze odpowiadaj poprawnym JSONem."),
            ("user", "{prompt}")
        ])

        # Sk≈Çadamy ≈Ça≈Ñcuch LangChain (prompt -> LLM -> parser)
        self.persona_chain = (
            self.persona_prompt
            | self.llm
            | self.json_parser
        )

        # Inicjalizuj RAG service (opcjonalnie - tylko je≈õli w≈ÇƒÖczony)
        self.rag_service = None
        if _rag_service_available and settings.RAG_ENABLED:
            try:
                self.rag_service = PolishSocietyRAG()
                logger.info("RAG service initialized successfully in PersonaGenerator")
            except Exception as e:
                logger.warning(f"RAG service unavailable: {e}")

    def sample_demographic_profile(
        self, distribution: DemographicDistribution, n_samples: int = 1
    ) -> List[Dict[str, Any]]:
        """
        Pr√≥bkuj profile demograficzne zgodnie z zadanym rozk≈Çadem

        Metoda ta tworzy losowe profile demograficzne na podstawie prawdopodobie≈Ñstw
        w obiekcie DemographicDistribution. Je≈õli jaki≈õ rozk≈Çad jest pusty lub niepoprawny,
        u≈ºywa domy≈õlnych warto≈õci z constants.py.

        Args:
            distribution: Obiekt zawierajƒÖcy rozk≈Çady prawdopodobie≈Ñstw dla ka≈ºdej kategorii
            n_samples: Liczba profili do wygenerowania (domy≈õlnie 1)

        Returns:
            Lista s≈Çownik√≥w, ka≈ºdy zawiera klucze: age_group, gender, education_level,
            income_bracket, location
        """
        profiles = []

        for _ in range(n_samples):
            # Normalizuj ka≈ºdy rozk≈Çad lub u≈ºyj warto≈õci domy≈õlnych
            age_groups = self._prepare_distribution(
                distribution.age_groups, DEFAULT_AGE_GROUPS
            )
            genders = self._prepare_distribution(distribution.genders, DEFAULT_GENDERS)
            education_levels = self._prepare_distribution(
                distribution.education_levels, DEFAULT_EDUCATION_LEVELS
            )
            income_brackets = self._prepare_distribution(
                distribution.income_brackets, DEFAULT_INCOME_BRACKETS
            )
            locations = self._prepare_distribution(
                distribution.locations, DEFAULT_LOCATIONS
            )

            # Losuj warto≈õƒá z ka≈ºdej kategorii zgodnie z wagami
            profile = {
                "age_group": self._weighted_sample(age_groups),
                "gender": self._weighted_sample(genders),
                "education_level": self._weighted_sample(education_levels),
                "income_bracket": self._weighted_sample(income_brackets),
                "location": self._weighted_sample(locations),
            }
            profiles.append(profile)

        return profiles

    def _weighted_sample(self, distribution: Dict[str, float]) -> str:
        """
        Losuj element z rozk≈Çadu wa≈ºonego (weighted sampling)

        Args:
            distribution: S≈Çownik kategoria -> prawdopodobie≈Ñstwo (suma = 1.0)

        Returns:
            Wylosowana kategoria jako string

        Raises:
            ValueError: Je≈õli rozk≈Çad jest pusty
        """
        if not distribution:
            raise ValueError("Distribution cannot be empty")
        categories = list(distribution.keys())
        weights = list(distribution.values())
        return self._rng.choice(categories, p=weights)

    def _prepare_distribution(
        self, distribution: Dict[str, float], fallback: Dict[str, float]
    ) -> Dict[str, float]:
        """
        Przygotuj i znormalizuj rozk≈Çad prawdopodobie≈Ñstw

        Sprawdza czy rozk≈Çad jest poprawny, normalizuje go do sumy 1.0,
        lub zwraca fallback je≈õli rozk≈Çad jest niepoprawny.

        Dodatkowo: je≈õli fallback to DEFAULT_LOCATIONS, DEFAULT_INCOME_BRACKETS
        lub DEFAULT_EDUCATION_LEVELS, zamienia na polskie odpowiedniki.

        Args:
            distribution: Rozk≈Çad do znormalizowania
            fallback: Rozk≈Çad domy≈õlny u≈ºywany gdy distribution jest pusty/b≈Çƒôdny

        Returns:
            Znormalizowany rozk≈Çad (suma = 1.0) lub fallback
        """
        if not distribution:
            # U≈ºyj polskich warto≈õci domy≈õlnych je≈õli fallback jest anglojƒôzyczny
            if fallback is DEFAULT_LOCATIONS:
                fallback = POLISH_LOCATIONS
            elif fallback is DEFAULT_INCOME_BRACKETS:
                fallback = POLISH_INCOME_BRACKETS
            elif fallback is DEFAULT_EDUCATION_LEVELS:
                fallback = POLISH_EDUCATION_LEVELS
            return fallback
        total = sum(distribution.values())
        if total <= 0:
            # U≈ºyj polskich warto≈õci domy≈õlnych je≈õli fallback jest anglojƒôzyczny
            if fallback is DEFAULT_LOCATIONS:
                fallback = POLISH_LOCATIONS
            elif fallback is DEFAULT_INCOME_BRACKETS:
                fallback = POLISH_INCOME_BRACKETS
            elif fallback is DEFAULT_EDUCATION_LEVELS:
                fallback = POLISH_EDUCATION_LEVELS
            return fallback
        # Pierwsza normalizacja - dziel przez sumƒô
        normalized = {key: value / total for key, value in distribution.items()}
        normalized_total = sum(normalized.values())
        # Druga normalizacja je≈õli sƒÖ b≈Çƒôdy zaokrƒÖgle≈Ñ numerycznych
        if not np.isclose(normalized_total, 1.0):
            normalized = {
                key: value / normalized_total for key, value in normalized.items()
            }
        return normalized

    def sample_big_five_traits(self, personality_skew: Dict[str, float] = None) -> Dict[str, float]:
        """
        Pr√≥bkuj cechy osobowo≈õci Big Five z rozk≈Çad√≥w normalnych

        Model Big Five (OCEAN) mierzy piƒôƒá g≈Ç√≥wnych wymiar√≥w osobowo≈õci:
        - Openness (otwarto≈õƒá): ciekawo≈õƒá, kreatywno≈õƒá
        - Conscientiousness (sumienno≈õƒá): organizacja, dyscyplina
        - Extraversion (ekstrawersja): towarzysko≈õƒá, energia
        - Agreeableness (ugodowo≈õƒá): empatia, wsp√≥≈Çpraca
        - Neuroticism (neurotyzm): emocjonalno≈õƒá, podatno≈õƒá na stres

        Args:
            personality_skew: Opcjonalny s≈Çownik do przesuniƒôcia rozk≈Çad√≥w.
                              Klucze: 'openness', 'conscientiousness', etc.
                              Warto≈õci: 0.0-1.0 (0=niskie, 0.5=zbalansowane, 1.0=wysokie)

        Returns:
            S≈Çownik z warto≈õciami cech w przedziale [0, 1]
        """
        skew = personality_skew or {}

        traits = {}
        for trait in ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:
            # Domy≈õlnie: ≈õrednia = 0.5, odchylenie standardowe = 0.15
            mean = skew.get(trait, 0.5)
            # Upewnij siƒô ≈ºe ≈õrednia jest w przedziale [0, 1]
            mean = np.clip(mean, 0.0, 1.0)

            # Losuj z rozk≈Çadu normalnego i przytnij do [0, 1]
            value = np.clip(self._rng.normal(mean, 0.15), 0, 1)
            traits[trait] = value

        return traits

    def sample_cultural_dimensions(self) -> Dict[str, float]:
        """
        Pr√≥bkuj wymiary kulturowe Hofstede

        Model Hofstede opisuje r√≥≈ºnice kulturowe w 6 wymiarach:
        - power_distance: akceptacja nier√≥wno≈õci w≈Çadzy
        - individualism: indywidualizm vs kolektywizm
        - masculinity: asertywno≈õƒá vs troska o innych
        - uncertainty_avoidance: unikanie niepewno≈õci
        - long_term_orientation: orientacja d≈Çugo- vs kr√≥tkoterminowa
        - indulgence: pob≈Ça≈ºliwo≈õƒá vs pow≈õciƒÖgliwo≈õƒá

        Returns:
            S≈Çownik z warto≈õciami wymiar√≥w w przedziale [0, 1]
        """
        return {
            "power_distance": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "individualism": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "masculinity": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "uncertainty_avoidance": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "long_term_orientation": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "indulgence": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
        }

    async def _get_rag_context_for_persona(
        self, demographic: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        Pobierz kontekst z RAG dla danego profilu demograficznego

        Args:
            demographic: Profil demograficzny persony

        Returns:
            Dict z kluczami: context (str), citations (list), query (str),
            graph_context (str), graph_nodes (list), search_type (str)
            lub None je≈õli RAG niedostƒôpny
        """
        if not self.rag_service:
            return None

        import logging
        logger = logging.getLogger(__name__)

        try:
            context_data = await self.rag_service.get_demographic_insights(
                age_group=demographic.get('age_group', '25-34'),
                education=demographic.get('education_level', 'wy≈ºsze'),
                location=demographic.get('location', 'Warszawa'),
                gender=demographic.get('gender', 'mƒô≈ºczyzna')
            )

            # Loguj szczeg√≥≈Çy RAG context
            context_len = len(context_data.get('context', ''))
            graph_nodes_count = len(context_data.get('graph_nodes', []))
            search_type = context_data.get('search_type', 'unknown')
            citations_count = len(context_data.get('citations', []))

            logger.info(
                f"RAG context retrieved: {context_len} chars, "
                f"{graph_nodes_count} graph nodes, "
                f"{citations_count} citations, "
                f"search_type={search_type}"
            )

            # Je≈õli mamy graph nodes, loguj ich typy
            if graph_nodes_count > 0:
                node_types = [node.get('type', 'Unknown') for node in context_data.get('graph_nodes', [])]
                logger.info(f"Graph node types: {', '.join(node_types)}")

            return context_data
        except Exception as e:
            logger.error(f"RAG context retrieval failed: {e}", exc_info=True)
            return None

    async def generate_persona_personality(
        self,
        demographic_profile: Dict[str, Any],
        psychological_profile: Dict[str, Any],
        use_rag: bool = True,  # NOWY PARAMETR - domy≈õlnie w≈ÇƒÖczony
        advanced_options: Optional[Dict[str, Any]] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        Generuj osobowo≈õƒá persony przy u≈ºyciu LangChain + Gemini

        Tworzy szczeg√≥≈Çowy prompt oparty na profilach demograficznym i psychologicznym,
        opcjonalnie wzbogacony o kontekst RAG z bazy wiedzy o polskim spo≈Çecze≈Ñstwie.

        Args:
            demographic_profile: S≈Çownik z danymi demograficznymi (wiek, p≈Çeƒá, lokalizacja, etc.)
            psychological_profile: S≈Çownik z cechami Big Five i wymiarami Hofstede
            use_rag: Czy u≈ºyƒá kontekstu z bazy wiedzy RAG (default: True)
            advanced_options: Opcjonalne zaawansowane opcje generowania (nieu≈ºywane obecnie)

        Returns:
            Krotka (prompt_text, response_dict) gdzie:
            - prompt_text: Pe≈Çny tekst wys≈Çany do LLM (do logowania/debugowania)
            - response_dict: Sparsowana odpowied≈∫ JSON z polami persony
                            + pole '_rag_citations' je≈õli u≈ºyto RAG

        Raises:
            ValueError: Je≈õli generowanie siƒô nie powiedzie lub odpowied≈∫ jest niepoprawna
        """

        import logging
        logger = logging.getLogger(__name__)

        # Pobierz kontekst RAG je≈õli w≈ÇƒÖczony
        rag_context = None
        rag_citations = None
        rag_context_details = None
        if use_rag and self.rag_service:
            rag_data = await self._get_rag_context_for_persona(demographic_profile)
            if rag_data:
                rag_context = rag_data.get('context')
                rag_citations = rag_data.get('citations')

                # Przygotuj rag_context_details dla View Details
                rag_context_details = {
                    "search_type": rag_data.get('search_type', 'unknown'),
                    "num_results": rag_data.get('num_results', 0),
                    "graph_nodes_count": len(rag_data.get('graph_nodes', [])),
                    "graph_nodes": rag_data.get('graph_nodes', []),
                    "graph_context": rag_data.get('graph_context', ''),
                    "enriched_chunks": sum(
                        1 for c in rag_data.get('citations', [])
                        if c.get('enriched', False)
                    )
                }

                logger.info(
                    f"Using RAG context: {len(rag_context or '')} chars, "
                    f"{len(rag_citations or [])} citations, "
                    f"search_type={rag_context_details['search_type']}"
                )

        # Pobierz target_audience_description i orchestration brief z advanced_options
        target_audience_desc = None
        orchestration_brief = None
        graph_insights = None
        allocation_reasoning = None

        if advanced_options:
            target_audience_desc = advanced_options.get('target_audience_description')
            orchestration_brief = advanced_options.get('orchestration_brief')
            graph_insights = advanced_options.get('graph_insights')
            allocation_reasoning = advanced_options.get('allocation_reasoning')

            if target_audience_desc:
                logger.info(f"Using target audience description: {target_audience_desc[:100]}...")
            if orchestration_brief:
                logger.info(f"Using orchestration brief: {orchestration_brief[:150]}... ({len(orchestration_brief)} chars)")

        # Generuj prompt (z RAG, target audience, i orchestration brief je≈õli dostƒôpne)
        prompt_text = self._create_persona_prompt(
            demographic_profile,
            psychological_profile,
            rag_context=rag_context,
            target_audience_description=target_audience_desc,
            orchestration_brief=orchestration_brief
        )

        try:
            logger.info(
                f"Generating persona with demographics: {demographic_profile.get('age_group')}, "
                f"{demographic_profile.get('gender')}, {demographic_profile.get('location')}"
                f" | RAG: {'YES' if rag_context else 'NO'}"
            )
            # Wywo≈Çaj ≈Ça≈Ñcuch LangChain (prompt -> LLM -> parser JSON)
            response = await self.persona_chain.ainvoke({"prompt": prompt_text})

            # Loguj odpowied≈∫ do debugowania
            logger.info(f"LLM response type: {type(response)}, keys: {response.keys() if isinstance(response, dict) else 'N/A'}")

            # Waliduj wymagane pola
            required_fields = ["full_name", "persona_title", "headline", "background_story", "values", "interests"]
            missing_fields = [field for field in required_fields if not response.get(field)]
            if missing_fields:
                logger.error(
                    f"LLM response missing required fields: {missing_fields}. "
                    f"Response keys: {list(response.keys()) if isinstance(response, dict) else 'NOT A DICT'}"
                )

            # Dodaj RAG citations i details do response (je≈õli by≈Çy u≈ºywane)
            if rag_citations:
                response['_rag_citations'] = rag_citations
            if rag_context_details:
                response['_rag_context_details'] = rag_context_details

            return prompt_text, response
        except Exception as e:
            logger.error(f"Failed to generate persona: {str(e)[:500]}", exc_info=True)
            # Fallback dla b≈Çƒôd√≥w parsowania
            raise ValueError(f"Failed to generate persona: {str(e)}")

    def _create_persona_prompt(
        self,
        demographic: Dict[str, Any],
        psychological: Dict[str, Any],
        rag_context: Optional[str] = None,
        target_audience_description: Optional[str] = None,
        orchestration_brief: Optional[str] = None  # NOWY PARAMETR - d≈Çugi brief od Gemini 2.5 Pro
    ) -> str:
        """
        Utw√≥rz prompt dla LLM do generowania persony - WERSJA POLSKA

        Tworzy szczeg√≥≈Çowy prompt zawierajƒÖcy:
        - Dane demograficzne i psychologiczne
        - Interpretacjƒô cech Big Five i Hofstede PO POLSKU
        - 3 przyk≈Çady few-shot z polskimi personami
        - Opcjonalny kontekst RAG z bazy wiedzy o polskim spo≈Çecze≈Ñstwie
        - Opcjonalny dodatkowy opis grupy docelowej od u≈ºytkownika
        - Opcjonalny orchestration brief (2000-3000 znak√≥w) od Gemini 2.5 Pro
        - Instrukcje jak stworzyƒá unikalnƒÖ polskƒÖ personƒô

        Args:
            demographic: Profil demograficzny (wiek, p≈Çeƒá, edukacja, etc.)
            psychological: Profil psychologiczny (Big Five + Hofstede)
            rag_context: Opcjonalny kontekst z RAG (fragmenty z dokument√≥w)
            target_audience_description: Opcjonalny dodatkowy opis grupy docelowej
            orchestration_brief: Opcjonalny D≈ÅUGI brief od orchestration agent (Gemini 2.5 Pro)

        Returns:
            Pe≈Çny tekst prompta gotowy do wys≈Çania do LLM (po polsku)
        """

        # Generuj unikalny seed dla tej persony (do r√≥≈ºnicowania)
        persona_seed = self._rng.integers(1000, 9999)

        # Losuj polskie imiƒô i nazwisko dla wiƒôkszej r√≥≈ºnorodno≈õci
        gender_lower = demographic.get('gender', 'male').lower()
        if 'female' in gender_lower or 'kobieta' in gender_lower:
            suggested_first_name = self._rng.choice(POLISH_FEMALE_NAMES)
        else:
            suggested_first_name = self._rng.choice(POLISH_MALE_NAMES)
        suggested_surname = self._rng.choice(POLISH_SURNAMES)

        # Wskaz√≥wki do interpretacji cech osobowo≈õci (PO POLSKU)
        openness_val = psychological.get('openness', 0.5)
        conscientiousness_val = psychological.get('conscientiousness', 0.5)
        extraversion_val = psychological.get('extraversion', 0.5)
        agreeableness_val = psychological.get('agreeableness', 0.5)
        neuroticism_val = psychological.get('neuroticism', 0.5)

        openness_hint = "kreatywna, ciekawa ≈õwiata, otwarta na nowe do≈õwiadczenia" if openness_val > 0.6 else "praktyczna, tradycyjna, preferuje rutynƒô" if openness_val < 0.4 else "umiarkowanie otwarta"
        conscientiousness_hint = "zorganizowana, zdyscyplinowana, skrupulatna" if conscientiousness_val > 0.6 else "spontaniczna, elastyczna, mniej uporzƒÖdkowana" if conscientiousness_val < 0.4 else "zbalansowana w planowaniu"
        extraversion_hint = "towarzyska, energiczna, lubi ludzi" if extraversion_val > 0.6 else "pow≈õciƒÖgliwa, introwertyczna, preferuje samotno≈õƒá" if extraversion_val < 0.4 else "ambiwertysta"
        agreeableness_hint = "wsp√≥≈ÇpracujƒÖca, empatyczna, ≈ºyczliwa" if agreeableness_val > 0.6 else "konkurencyjna, bezpo≈õrednia, sceptyczna" if agreeableness_val < 0.4 else "zbalansowane podej≈õcie spo≈Çeczne"
        neuroticism_hint = "nerwowa, wra≈ºliwa, podatna na stres" if neuroticism_val > 0.6 else "spokojna, odporna, stabilna emocjonalnie" if neuroticism_val < 0.4 else "umiarkowanie emocjonalna"

        # Sekcja RAG context (je≈õli dostƒôpna)
        rag_section = ""
        if rag_context:
            rag_section = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
KONTEKST Z BAZY WIEDZY O POLSKIM SPO≈ÅECZE≈ÉSTWIE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{rag_context}

‚ö†Ô∏è KRYTYCZNE INSTRUKCJE WYKORZYSTANIA KONTEKSTU:

1. **NATURALNO≈öƒÜ**: NIE cytuj statystyk bezpo≈õrednio w opisach
   - ‚ùå Z≈ÅE: "Nale≈ºy do 67% absolwent√≥w..."
   - ‚úÖ DOBRE: "Jak wielu jej r√≥wie≈õnik√≥w z wy≈ºszym wykszta≈Çceniem, zmaga siƒô z..."
   - U≈ºyj wska≈∫nik√≥w jako T≈ÅEM dla ≈ºycia persony, nie jako fakt√≥w do cytowania

2. **CIEKAWO≈öƒÜ**: Tw√≥rz FASCYNUJƒÑCE historie ≈ºycia
   - Wykorzystaj obserwacje demograficzne jako INSPIRACJƒò do szczeg√≥≈Ç√≥w
   - Przyk≈Çad: Je≈õli kontekst m√≥wi o "wysokiej mobilno≈õci zawodowej"
     ‚Üí Persona mo≈ºe mieƒá historiƒô zmiany 3 prac w ciƒÖgu 5 lat z konkretnymi powodami

3. **KONTEKST CZASOWY**: Osad≈∫ personƒô w trendach bez nazywania ich
   - ‚ùå Z≈ÅE: "Obserwuje trend wzrostu cen mieszka≈Ñ w latach 2018-2023"
   - ‚úÖ DOBRE: "OdkƒÖd 5 lat temu przeprowadzi≈Ça siƒô do Warszawy, ceny mieszka≈Ñ podwoi≈Çy siƒô"

4. **AUTENTYCZNO≈öƒÜ**: Persona ma W≈ÅASNE do≈õwiadczenia odzwierciedlajƒÖce dane
   - Je≈õli wska≈∫niki pokazujƒÖ problem (np. trudno≈õci finansowe m≈Çodych)
   - Persona ma KONKRETNE przyk≈Çady tego w ≈ºyciu (mieszka z rodzicami, sp≈Çaca kredyt)

5. **SP√ìJNO≈öƒÜ Z DANYMI**: Wszystkie szczeg√≥≈Çy PASUJƒÑ do kontekstu
   - Dochody, warto≈õci, zainteresowania, concerns MUSZƒÑ byƒá zgodne z danymi demograficznymi
   - Ale przedstawione jako CZƒò≈öƒÜ ≈ªYCIA persony, nie jako cytaty ze statystyk

üí° PAMIƒòTAJ: Czytelnicy chcƒÖ poznaƒá PRAWDZIWƒÑ OSOBƒò, nie raport statystyczny.
U≈ºyj danych jako fundamentu, ale zbuduj na nich ≈ªYWƒÑ, INTERESUJƒÑCƒÑ postaƒá.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""

        # Sekcja dodatkowego opisu grupy docelowej (je≈õli dostƒôpny)
        target_audience_section = ""
        if target_audience_description and target_audience_description.strip():
            target_audience_section = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
DODATKOWY OPIS GRUPY DOCELOWEJ:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{target_audience_description.strip()}

‚ö†Ô∏è WA≈ªNE: Ta persona MUSI odpowiadaƒá powy≈ºszemu opisowi grupy docelowej.
Upewnij siƒô, ≈ºe cechy, zainteresowania, warto≈õci i styl ≈ºycia persony sƒÖ
zgodne z tym opisem.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""

        # Sekcja orchestration brief (je≈õli dostƒôpny) - D≈ÅUGI edukacyjny brief od Gemini 2.5 Pro
        orchestration_section = ""
        if orchestration_brief and orchestration_brief.strip():
            orchestration_section = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã ORCHESTRATION BRIEF (od Gemini 2.5 Pro - Szczeg√≥≈Çowy Kontekst Spo≈Çeczny)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

{orchestration_brief.strip()}

‚ö†Ô∏è KRYTYCZNE INSTRUKCJE WYKORZYSTANIA BRIEFU:

1. **TO JEST TW√ìJ FUNDAMENT**: Ten brief zawiera g≈ÇƒôbokƒÖ socjologicznƒÖ analizƒô
   grupy demograficznej do kt√≥rej nale≈ºy ta persona. Przeczytaj go UWA≈ªNIE.

2. **NATURALNO≈öƒÜ W OPISIE**: NIE cytuj briefu dos≈Çownie w background_story!
   - ‚ùå Z≈ÅE: "Wed≈Çug briefu, ta grupa stanowi 17.3% populacji..."
   - ‚úÖ DOBRE: "Jak wielu jej r√≥wie≈õnik√≥w w Warszawie, zmaga siƒô z wysokimi cenami mieszka≈Ñ..."

3. **U≈ªYJ JAKO T≈ÅA**: Brief wyja≈õnia DLACZEGO ta persona jest taka jaka jest.
   - Wska≈∫niki z briefu (78.4% zatrudnienia, 63% mobilno≈õƒá) = kontekst ≈ºycia persony
   - Warto≈õci opisane w briefie (work-life balance, rozw√≥j) = warto≈õci persony
   - Wyzwania z briefu (housing crisis, burnout) = konkretne problemy w ≈ºyciu persony

4. **CIEKAWA HISTORIA ≈ªYCIA**: U≈ºyj insights z briefu aby stworzyƒá FASCYNUJƒÑCƒÑ personƒô
   - Brief m√≥wi o "mobilno≈õci zawodowej" ‚Üí Persona mo≈ºe mieƒá historiƒô zmiany 3 prac
   - Brief m√≥wi o "cenach mieszka≈Ñ" ‚Üí Persona wynajmuje, oszczƒôdza, ma konkretne plany
   - Brief m√≥wi o "work-life balance" ‚Üí Persona ma hobby, boundaries, mindfulness

5. **SP√ìJNO≈öƒÜ Z BRIEFEM**: Ka≈ºdy szczeg√≥≈Ç ≈ºycia persony MUSI pasowaƒá do briefu
   - Dochody, zaw√≥d, lokalizacja, warto≈õci, zainteresowania = zgodne z kontekstem
   - Ale przedstawione jako ≈ªYCIE PERSONY, nie jako statystyki

üí° PAMIƒòTAJ: Brief to mapa spo≈Çeczna. Ty tworzysz KONKRETNƒÑ OSOBƒò kt√≥ra ≈ºyje w tym spo≈Çecze≈Ñstwie.
Czytelnicy chcƒÖ poznaƒá FASCYNUJƒÑCƒÑ POSTAƒÜ, kt√≥ra jest autentyczna bo odzwierciedla realne
trendy spo≈Çeczne.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""

        return f"""Jeste≈õ ekspertem od bada≈Ñ rynkowych tworzƒÖcym syntetyczne persony dla polskiego rynku. Twoje persony muszƒÖ byƒá UNIKALNE, REALISTYCZNE i WEWNƒòTRZNIE SP√ìJNE, odzwierciedlajƒÖce POLSKIE SPO≈ÅECZE≈ÉSTWO.

{orchestration_section}{rag_section}{target_audience_section}
PERSONA #{persona_seed}
SUGEROWANE IMIƒò I NAZWISKO: {suggested_first_name} {suggested_surname} (mo≈ºesz u≈ºyƒá lub wybraƒá inne polskie)

PROFIL DEMOGRAFICZNY:
- Grupa wiekowa: {demographic.get('age_group')}
- P≈Çeƒá: {demographic.get('gender')}
- Wykszta≈Çcenie: {demographic.get('education_level')}
- Przedzia≈Ç dochodowy: {demographic.get('income_bracket')}
- Lokalizacja: {demographic.get('location')}

CECHY OSOBOWO≈öCI (Big Five):
- Otwarto≈õƒá: {openness_val:.2f} ‚Üí {openness_hint}
- Sumienno≈õƒá: {conscientiousness_val:.2f} ‚Üí {conscientiousness_hint}
- Ekstrawersja: {extraversion_val:.2f} ‚Üí {extraversion_hint}
- Ugodowo≈õƒá: {agreeableness_val:.2f} ‚Üí {agreeableness_hint}
- Neurotyzm: {neuroticism_val:.2f} ‚Üí {neuroticism_hint}

WYMIARY KULTUROWE (Hofstede):
- Dystans w≈Çadzy: {psychological.get('power_distance', 0.5):.2f}
- Indywidualizm: {psychological.get('individualism', 0.5):.2f}
- Unikanie niepewno≈õci: {psychological.get('uncertainty_avoidance', 0.5):.2f}

KRYTYCZNE INSTRUKCJE DLA POLSKIEJ PERSONY:
1. Persona MUSI byƒá UNIKALNA - unikaj og√≥lnych opis√≥w
2. Imiƒô i nazwisko MUSI byƒá POLSKIE (Jan Kowalski, Anna Nowak, Piotr Zieli≈Ñski, Maria Wi≈õniewska)
3. Lokalizacja MUSI byƒá polska (Warszawa, Krak√≥w, Wroc≈Çaw, Gda≈Ñsk, inne polskie miasta)
4. Wiek ma znaczenie: 25-latek i 65-latek majƒÖ BARDZO r√≥≈ºne konteksty ≈ºyciowe
5. Zaw√≥d zgodny z wykszta≈Çceniem i poziomem dochod√≥w (typowe polskie zawody)
6. Historia ≈ºyciowa zgodna z cechami osobowo≈õci:
   - Wysoka Otwarto≈õƒá ‚Üí podr√≥≈ºe, kreatywne hobby, r√≥≈ºnorodne do≈õwiadczenia
   - Wysoka Sumienno≈õƒá ‚Üí uporzƒÖdkowana ≈õcie≈ºka kariery, planowanie
   - Wysoka Ekstrawersja ‚Üí aktywno≈õci spo≈Çeczne, networking
   - Niska Ugodowo≈õƒá ‚Üí zawody konkurencyjne, niezale≈ºna praca
   - Wysoki Indywidualizm ‚Üí przedsiƒôbiorczo≈õƒá, samodzielno≈õƒá
7. BƒÖd≈∫ KONKRETNY: nazwij dzielnice miast, konkretne polskie marki, prawdziwe hobby

PRZYK≈ÅADY FEW-SHOT (POLSKIE PERSONY):

Przyk≈Çad 1 (Wysoka otwarto≈õƒá, kreatywny zaw√≥d w ≈õredniej karierze):
{{
  "full_name": "Katarzyna Lewandowska",
  "persona_title": "Freelance UX Designer",
  "headline": "Krakowska designerka eksperymentujƒÖca z dostƒôpno≈õciƒÖ cyfrowƒÖ i zero waste.",
  "background_story": "Kasia ma 32 lata i mieszka w Krakowie na Kazimierzu. Po ASP i 5 latach w agencji przesz≈Ça na freelancing 3 lata temu. Obecnie projektuje interfejsy dla polskich startup√≥w i zagranicznych klient√≥w, uczy siƒô Swift, a weekendy spƒôdza na wspinaczce w Tatrach. Singielka cieszƒÖca siƒô wolno≈õciƒÖ wyboru projekt√≥w od sustainable fashion po edtech.",
  "values": ["Kreatywno≈õƒá", "Niezale≈ºno≈õƒá", "CiƒÖg≈Çy rozw√≥j", "Autentyczno≈õƒá", "Ekologia", "R√≥wnowaga praca-≈ºycie"],
  "interests": ["Wspinaczka g√≥rska", "Design dostƒôpny (a11y)", "Festiwale muzyczne (Opener, OFF)", "Kawiarnie specialty coffee", "Zero waste", "Sketching w plenerze"],
  "communication_style": "entuzjastyczna i wizualna, u≈ºywa metafor i przyk≈Çad√≥w z r√≥≈ºnych dziedzin, preferuje Slack i Figma",
  "decision_making_style": "intuicyjna z research; testuje pomys≈Çy szybko przez prototypy i MVP",
  "typical_concerns": ["Utrzymanie wolno≈õci tw√≥rczej przy stabilno≈õci finansowej", "Znalezienie sensownych projekt√≥w", "Balansowanie samotnej pracy z potrzebƒÖ kontaktu spo≈Çecznego", "Brak pewno≈õci socjalnej (ZUS, urlop)"]
}}

Przyk≈Çad 2 (Niska otwarto≈õƒá, wysoka sumienno≈õƒá, zbli≈ºajƒÖcy siƒô do emerytury):
{{
  "full_name": "Marek Kowalczyk",
  "persona_title": "Do≈õwiadczony G≈Ç√≥wny Ksiƒôgowy",
  "headline": "Pozna≈Ñski ksiƒôgowy skrupulatnie planujƒÖcy emeryturƒô i mentorujƒÖcy m≈Çodsze pokolenie.",
  "background_story": "Marek ma 56 lat i pracuje w tej samej firmie produkcyjnej od 28 lat. ≈ªonaty, dwoje doros≈Çych dzieci (syn lekarz, c√≥rka nauczycielka). Kupi≈Ç niedawno dzia≈Çkƒô pod Poznaniem i planuje emeryturƒô za 6 lat. Jest skarbnikiem parafii, dumny ze swojej przewidywalnej rutyny i relacji z klientami budowanych przez dekady.",
  "values": ["Stabilno≈õƒá", "Lojalno≈õƒá", "Rodzina", "Odpowiedzialno≈õƒá", "Tradycja", "Uczciwo≈õƒá"],
  "interests": ["Wƒôdkarstwo nad WartƒÖ", "Majsterkowanie i renowacja domu", "Podcasty o finansach osobistych", "Grillowanie", "Dzia≈Çalno≈õƒá parafialna", "Ch√≥r ko≈õcielny"],
  "communication_style": "formalny i profesjonalny, preferuje spotkania twarzƒÖ w twarz, u≈ºywa sprawdzonych schemat√≥w",
  "decision_making_style": "metodyczny i unikajƒÖcy ryzyka, opiera siƒô na sprawdzonych metodach i dok≈Çadnym planowaniu",
  "typical_concerns": ["Zapewnienie wystarczajƒÖcej emerytury", "Utrzymanie relacji z klientami przez sukcesjƒô", "Zdrowie i opieka medyczna na emeryturze", "Planowanie spadku dla dzieci"]
}}

Przyk≈Çad 3 (Wysoka ekstrawersja, wysoki neurotyzm, ≈õwie≈ºy absolwent):
{{
  "full_name": "Julia Nowicka",
  "persona_title": "Social Media Manager & Content Creator",
  "headline": "Warszawska marketerka Z-ki walczƒÖca z niepewno≈õciƒÖ kariery w creator economy.",
  "background_story": "Julia ma 25 lat i niedawno sko≈Ñczy≈Ça marketing na SGH. Mieszka z trzema wsp√≥≈Çlokatorkami na Mokotowie, pracuje jako social media manager w agencji beauty. Balansuje miƒôdzy lƒôkiem o stabilno≈õƒá pracy a ekscytacjƒÖ gospodarkƒÖ tw√≥rc√≥w. Stale networkuje na eventach bran≈ºowych budujƒÖc markƒô osobistƒÖ jako Gen-Z marketing consultant. Rodzice z Radomia nie do ko≈Ñca rozumiejƒÖ jej wyb√≥r kariery.",
  "values": ["Relacje", "Rozpoznawalno≈õƒá", "Autentyczno≈õƒá", "Innowacja", "Rodzina", "Sukces zawodowy"],
  "interests": ["Tworzenie contentu TikTok/Instagram", "Eventy networkingowe", "Kultura brunchowa", "Secondhandy (Vinted, lumpeksy)", "S≈Çuchanie podcast√≥w", "Mental health awareness", "K-pop"],
  "communication_style": "energiczna i ≈õwiadoma trend√≥w, u≈ºywa slangu social media, bardzo ekspresywna z emoji",
  "decision_making_style": "impulsywna ale kolaboratywna, szuka walidacji od r√≥wie≈õnik√≥w przed zobowiƒÖzaniem",
  "typical_concerns": ["Pewno≈õƒá pracy w niestabilnej bran≈ºy", "Kredyt studencki do sp≈Çaty", "Lƒôk por√≥wnawczy z social media", "Udowodnienie wyboru kariery rodzicom", "Budowanie zr√≥wnowa≈ºonego dochodu", "Wysokie ceny wynajmu w Warszawie"]
}}

Teraz wygeneruj KOMPLETNIE INNƒÑ personƒô zachowujƒÖc ten sam poziom szczeg√≥≈Çowo≈õci i sp√≥jno≈õci z podanym profilem demograficznym i psychologicznym.

Generuj WY≈ÅƒÑCZNIE JSON (bez markdown, bez dodatkowego tekstu):
{{
  "full_name": "<realistyczne polskie imiƒô i nazwisko pasujƒÖce do lokalizacji>",
  "persona_title": "<zwiƒôz≈Çy tytu≈Ç zawodowy lub etapu ≈ºycia>",
  "headline": "<jedno zdanie podsumowujƒÖce sp√≥jne z wiekiem, zawodem i motywacjami>",
  "background_story": "<2-3 konkretne zdania o ich obecnym ≈ºyciu, ≈õcie≈ºce kariery i unikalnym kontek≈õcie>",
  "values": ["<5-7 konkretnych warto≈õci kt√≥re kierujƒÖ ich decyzjami>"],
  "interests": ["<5-7 konkretnych hobby/aktywno≈õci kt√≥re faktycznie uprawiajƒÖ>"],
  "communication_style": "<jak siƒô wyra≈ºajƒÖ i komunikujƒÖ>",
  "decision_making_style": "<jak podchodzƒÖ do wa≈ºnych wybor√≥w>",
  "typical_concerns": ["<3-5 konkretnych zmartwie≈Ñ lub priorytet√≥w na obecnym etapie ≈ºycia>"]
}}"""

    def validate_distribution(
        self,
        generated_personas: List[Dict[str, Any]],
        target_distribution: DemographicDistribution,
    ) -> Dict[str, Any]:
        """
        Waliduj czy wygenerowane persony pasujƒÖ do docelowego rozk≈Çadu (test chi-kwadrat)

        Sprawdza statystycznie czy rzeczywisty rozk≈Çad cech demograficznych w wygenerowanych
        personach odpowiada zadanemu rozk≈Çadowi docelowemu. U≈ºywa testu chi-kwadrat dla
        ka≈ºdej kategorii (wiek, p≈Çeƒá, edukacja, doch√≥d, lokalizacja).

        Args:
            generated_personas: Lista wygenerowanych person (jako s≈Çowniki)
            target_distribution: Oczekiwany rozk≈Çad demograficzny

        Returns:
            S≈Çownik z wynikami test√≥w dla ka≈ºdej kategorii oraz og√≥lnƒÖ ocenƒÖ:
            {
                "age": {"p_value": float, "chi_square_statistic": float, ...},
                "gender": {...},
                "overall_valid": bool  # Warto≈õƒá True oznacza, ≈ºe wszystkie p > 0.05
            }
        """
        results = {}

        # Testuj rozk≈Çad wieku (tylko je≈õli podany)
        if target_distribution.age_groups:
            results["age"] = self._chi_square_test(
                generated_personas, "age_group", target_distribution.age_groups
            )

        # Testuj rozk≈Çad p≈Çci (tylko je≈õli podany)
        if target_distribution.genders:
            results["gender"] = self._chi_square_test(
                generated_personas, "gender", target_distribution.genders
            )

        # Testuj rozk≈Çad edukacji (tylko je≈õli podany)
        if target_distribution.education_levels:
            results["education"] = self._chi_square_test(
                generated_personas, "education_level", target_distribution.education_levels
            )

        # Testuj rozk≈Çad dochod√≥w (tylko je≈õli podany)
        if target_distribution.income_brackets:
            results["income"] = self._chi_square_test(
                generated_personas, "income_bracket", target_distribution.income_brackets
            )

        # Testuj rozk≈Çad lokalizacji (tylko je≈õli podany)
        if target_distribution.locations:
            results["location"] = self._chi_square_test(
                generated_personas, "location", target_distribution.locations
            )

        # Og√≥lna walidacja - wszystkie p-warto≈õci powinny byƒá > 0.05
        all_p_values = [r["p_value"] for r in results.values() if "p_value" in r]
        results["overall_valid"] = all(
            p > settings.STATISTICAL_SIGNIFICANCE_THRESHOLD for p in all_p_values
        ) if all_p_values else True

        return results

    def _chi_square_test(
        self, personas: List[Dict[str, Any]], field: str, expected_dist: Dict[str, float]
    ) -> Dict[str, float]:
        """
        Wykonaj test chi-kwadrat dla konkretnego pola demograficznego

        Test chi-kwadrat sprawdza czy obserwowany rozk≈Çad kategorii (np. grup wiekowych)
        statystycznie r√≥≈ºni siƒô od rozk≈Çadu oczekiwanego. Im wy≈ºsze p-value, tym lepiej
        (p > 0.05 oznacza ≈ºe rozk≈Çady sƒÖ zgodne).

        Args:
            personas: Lista person do sprawdzenia
            field: Nazwa pola do przetestowania (np. "age_group", "gender")
            expected_dist: Oczekiwany rozk≈Çad prawdopodobie≈Ñstw

        Returns:
            S≈Çownik z wynikami testu:
            - chi_square_statistic: warto≈õƒá statystyki chi-kwadrat
            - p_value: p-warto≈õƒá (>0.05 = dobre dopasowanie)
            - degrees_of_freedom: liczba stopni swobody
            - observed: obserwowane liczno≈õci
            - expected: oczekiwane liczno≈õci
        """
        # Filtruj kategorie z niepoprawnymi prawdopodobie≈Ñstwami
        valid_categories = [
            (category, probability)
            for category, probability in expected_dist.items()
            if probability and probability > 0
        ]

        if not valid_categories:
            return {
                "chi_square_statistic": 0.0,
                "p_value": 1.0,
                "degrees_of_freedom": 0,
                "observed": {},
                "expected": {},
            }

        # Normalizuj prawdopodobie≈Ñstwa do sumy = 1.0
        total_prob = sum(probability for _, probability in valid_categories)
        normalized_probs = {
            category: probability / total_prob for category, probability in valid_categories
        }

        # Policz obserwowane wystƒÖpienia ka≈ºdej kategorii
        observed_counts = {category: 0 for category in normalized_probs}
        valid_samples = 0
        for persona in personas:
            value = persona.get(field)
            if value in observed_counts:
                observed_counts[value] += 1
                valid_samples += 1

        if valid_samples == 0:
            return {
                "chi_square_statistic": 0.0,
                "p_value": 1.0,
                "degrees_of_freedom": len(observed_counts) - 1,
                "observed": observed_counts,
                "expected": {category: 0.0 for category in observed_counts},
            }

        # Oblicz oczekiwane liczno≈õci (probability * total_count)
        expected_counts = {
            category: normalized_probs[category] * valid_samples
            for category in normalized_probs
        }

        # Przygotuj listy do testu chi-kwadrat (scipy wymaga list w tej samej kolejno≈õci)
        observed = [observed_counts[category] for category in normalized_probs]
        expected = [expected_counts[category] for category in normalized_probs]

        # Wykonaj test chi-kwadrat
        chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)

        return {
            "chi_square_statistic": float(chi2_stat),
            "p_value": float(p_value),
            "degrees_of_freedom": len(normalized_probs) - 1,
            "observed": observed_counts,
            "expected": expected_counts,
            "sample_size": valid_samples,
        }
