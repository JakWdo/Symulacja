"""
Generator Person oparty na LangChain i Google Gemini

Ten moduÅ‚ generuje realistyczne, statystycznie reprezentatywne persony
dla badaÅ„ rynkowych przy uÅ¼yciu Google Gemini przez framework LangChain.

Kluczowe funkcjonalnoÅ›ci:
- Generowanie person zgodnie z zadanymi rozkÅ‚adami demograficznymi
- Walidacja statystyczna przy uÅ¼yciu testu chi-kwadrat
- Sampling cech osobowoÅ›ci (Big Five) i wymiarÃ³w kulturowych (Hofstede)
- Integracja z LangChain dla Å‚atwej zmiany modelu LLM
"""

import re
import numpy as np
from typing import Any

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

from app.core.config import get_settings
from app.core.constants import (
    POLISH_LOCATIONS,
    POLISH_INCOME_BRACKETS,
    POLISH_EDUCATION_LEVELS,
    POLISH_MALE_NAMES,
    POLISH_FEMALE_NAMES,
    POLISH_SURNAMES,
)
from app.services.shared.clients import build_chat_model

settings = get_settings()


# ============================================================================
# PROMPT BUILDERS - Funkcje pomocnicze dla generacji promptÃ³w
# ============================================================================

def create_persona_prompt(
    demographic: Dict[str, Any],
    psychological: Dict[str, Any],
    persona_seed: int,
    suggested_first_name: str,
    suggested_surname: str,
    rag_context: Optional[str] = None,
    target_audience_description: Optional[str] = None,
    orchestration_brief: Optional[str] = None
) -> str:
    """
    Tworzy szczegÃ³Å‚owy prompt dla LLM do generowania persony - WERSJA POLSKA

    Args:
        demographic: Profil demograficzny (wiek, pÅ‚eÄ‡, edukacja, etc.)
        psychological: Profil psychologiczny (Big Five + Hofstede)
        persona_seed: Unikalny seed dla rÃ³Å¼nicowania (1000-9999)
        suggested_first_name: Sugerowane polskie imiÄ™
        suggested_surname: Sugerowane polskie nazwisko
        rag_context: Opcjonalny kontekst z RAG (fragmenty z dokumentÃ³w)
        target_audience_description: Opcjonalny dodatkowy opis grupy docelowej
        orchestration_brief: Opcjonalny DÅUGI brief od orchestration agent (Gemini 2.5 Pro)

    Returns:
        PeÅ‚ny tekst prompta gotowy do wysÅ‚ania do LLM (po polsku)
    """

    # Determine headline age rule based on available data
    if demographic.get('age'):
        headline_age_rule = f"â€¢ HEADLINE: Musi zawieraÄ‡ liczbÄ™ {demographic['age']} lat i realnÄ… motywacjÄ™ tej osoby.\n"
    elif demographic.get('age_group'):
        headline_age_rule = (
            f"â€¢ HEADLINE: Podaj konkretnÄ… liczbÄ™ lat zgodnÄ… z przedziaÅ‚em {demographic['age_group']} "
            "i pokaÅ¼ realnÄ… motywacjÄ™ tej osoby.\n"
        )
    else:
        headline_age_rule = "â€¢ HEADLINE: Podaj konkretny wiek w latach i realnÄ… motywacjÄ™ tej osoby.\n"

    # Get Big Five values
    openness_val = psychological.get('openness', 0.5)
    conscientiousness_val = psychological.get('conscientiousness', 0.5)
    extraversion_val = psychological.get('extraversion', 0.5)
    agreeableness_val = psychological.get('agreeableness', 0.5)
    neuroticism_val = psychological.get('neuroticism', 0.5)

    # Unified context section (merge RAG + Target Audience + Orchestration Brief)
    unified_context = ""
    if rag_context or target_audience_description or orchestration_brief:
        context_parts = []

        if rag_context:
            context_parts.append(f"ğŸ“Š KONTEKST RAG:\n{rag_context}")
        if orchestration_brief and orchestration_brief.strip():
            context_parts.append(f"ğŸ“‹ ORCHESTRATION BRIEF:\n{orchestration_brief.strip()}")
        if target_audience_description and target_audience_description.strip():
            context_parts.append(f"ğŸ¯ GRUPA DOCELOWA:\n{target_audience_description.strip()}")

        unified_context = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KONTEKST (RAG + Brief + Audience):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{chr(10).join(context_parts)}

âš ï¸ KLUCZOWE ZASADY:
â€¢ UÅ¼yj kontekstu jako TÅA Å¼ycia persony (nie cytuj statystyk!)
â€¢ StwÃ³rz FASCYNUJÄ„CÄ„ historiÄ™ - kontekst to fundament, nie lista faktÃ³w
â€¢ WskaÅºniki â†’ konkretne detale Å¼ycia (housing crisis â†’ wynajmuje, oszczÄ™dza)
â€¢ Trendy â†’ doÅ›wiadczenia Å¼yciowe (mobilnoÅ›Ä‡ â†’ zmiana 3 prac w 5 lat)
â€¢ NaturalnoÅ›Ä‡: "Jak wielu rÃ³wieÅ›nikÃ³w..." zamiast "67% absolwentÃ³w..."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""

    return f"""Expert: Syntetyczne persony dla polskiego rynku - UNIKALNE, REALISTYCZNE, SPÃ“JNE.

{unified_context}PERSONA #{persona_seed}: {suggested_first_name} {suggested_surname}

PROFIL:
â€¢ Wiek: {demographic.get('age_group')} | PÅ‚eÄ‡: {demographic.get('gender')} | Lokalizacja: {demographic.get('location')}
â€¢ WyksztaÅ‚cenie: {demographic.get('education_level')} | DochÃ³d: {demographic.get('income_bracket')}

OSOBOWOÅšÄ† (Big Five - wartoÅ›ci 0-1):
â€¢ OtwartoÅ›Ä‡ (Openness): {openness_val:.2f}
â€¢ SumiennoÅ›Ä‡ (Conscientiousness): {conscientiousness_val:.2f}
â€¢ Ekstrawersja (Extraversion): {extraversion_val:.2f}
â€¢ UgodowoÅ›Ä‡ (Agreeableness): {agreeableness_val:.2f}
â€¢ Neurotyzm (Neuroticism): {neuroticism_val:.2f}

Interpretacja Big Five: <0.4 = niskie, 0.4-0.6 = Å›rednie, >0.6 = wysokie.
Wykorzystaj te wartoÅ›ci do stworzenia spÃ³jnej osobowoÅ›ci i historii Å¼yciowej.

HOFSTEDE (wartoÅ›ci 0-1): PD={psychological.get('power_distance', 0.5):.2f} | IND={psychological.get('individualism', 0.5):.2f} | UA={psychological.get('uncertainty_avoidance', 0.5):.2f}

ZASADY:
â€¢ ZawÃ³d = wyksztaÅ‚cenie + dochÃ³d
â€¢ OsobowoÅ›Ä‡ â†’ historia (Oâ†’podrÃ³Å¼e, Sâ†’planowanie)
â€¢ Detale: dzielnice, marki, konkretne hobby
â€¢ UNIKALNOÅšÄ†: KaÅ¼da persona MUSI mieÄ‡ RÃ“Å»NÄ„ historiÄ™ Å¼yciowÄ… - nie kopiuj opisÃ³w!
â€¢ Background_story NIE moÅ¼e kopiowaÄ‡ briefu segmentu ani powtarzaÄ‡ caÅ‚ych akapitÃ³w z kontekstu
{headline_age_rule}â€¢ PokaÅ¼ codzienne wybory i motywacje tej osoby - zero ogÃ³lnikÃ³w

âš ï¸ CATCHY SEGMENT NAME (2-4 sÅ‚owa):
Wygeneruj krÃ³tkÄ…, chwytliwÄ… nazwÄ™ marketingowÄ… dla segmentu tej persony.
â€¢ Powinna odzwierciedlaÄ‡ wiek, wartoÅ›ci, styl Å¼ycia, status ekonomiczny
â€¢ PrzykÅ‚ady: "Pasywni LiberaÅ‚owie", "MÅ‚odzi Prekariusze", "Aktywni Seniorzy", "Cyfrowi Nomadzi", "Stabilni TradycjonaliÅ›ci"
â€¢ UNIKAJ dÅ‚ugich opisÃ³w technicznych jak "Kobiety 35-44 wyÅ¼sze wyksztaÅ‚cenie"
â€¢ Polski jÄ™zyk, kulturowo relevantne, konkretne

PRZYKÅAD:
{{"full_name": "Marek Kowalczyk", "catchy_segment_name": "Stabilni TradycjonaliÅ›ci", "persona_title": "GÅ‚Ã³wny KsiÄ™gowy", "headline": "PoznaÅ„ski ksiÄ™gowy (56) planujÄ…cy emeryturÄ™", "background_story": "28 lat w firmie, Å¼onaty, dwoje dorosÅ‚ych dzieci, kupiÅ‚ dziaÅ‚kÄ™ pod Poznaniem, skarbnik parafii", "values": ["StabilnoÅ›Ä‡", "LojalnoÅ›Ä‡", "Rodzina", "OdpowiedzialnoÅ›Ä‡"], "interests": ["WÄ™dkarstwo", "Majsterkowanie", "Grillowanie"], "communication_style": "formalny, face-to-face", "decision_making_style": "metodyczny, unika ryzyka", "typical_concerns": ["Emerytura", "Sukcesja", "Zdrowie"]}}

âš ï¸ KRYTYCZNE: Generuj KOMPLETNIE INNÄ„ personÄ™ z UNIKALNÄ„ historiÄ… Å¼yciowÄ…!
â€¢ NIE kopiuj ogÃ³lnych opisÃ³w segmentu do background_story
â€¢ Fokus na TEJ KONKRETNEJ OSOBY, jej specyficznych doÅ›wiadczeniach
â€¢ UÅ¼yj persona_seed #{persona_seed} jako ÅºrÃ³dÅ‚o rÃ³Å¼norodnoÅ›ci

WYÅÄ„CZNIE JSON (bez markdown):
{{
  "full_name": "<polskie imiÄ™+nazwisko>",
  "catchy_segment_name": "<2-4 sÅ‚owa, krÃ³tka marketingowa nazwa segmentu>",
  "persona_title": "<zawÃ³d/etap Å¼ycia>",
  "headline": "<1 zdanie: wiek, zawÃ³d, UNIKALNE motywacje>",
  "background_story": "<2-3 zdania: KONKRETNA historia TEJ OSOBY - jej Å¼ycie, kariera, sytuacja>",
  "values": ["<5-7 wartoÅ›ci>"],
  "interests": ["<5-7 hobby/aktywnoÅ›ci>"],
  "communication_style": "<jak siÄ™ komunikuje>",
  "decision_making_style": "<jak podejmuje decyzje>",
  "typical_concerns": ["<3-5 SPECYFICZNYCH zmartwieÅ„/priorytetÃ³w>"]
}}"""


def create_segment_persona_prompt(
    demographic: Dict[str, Any],
    psychological: Dict[str, Any],
    segment_name: str,
    segment_context: str,
    graph_insights: List[Any],
    rag_citations: List[Any],
    persona_seed: int,
    suggested_first_name: str,
    suggested_surname: str
) -> str:
    """
    Tworzy prompt dla generacji persony z WYMUSZENIEM demographics z segmentu.

    Args:
        demographic: Enforced demographic profile (age, gender, education, income, location)
        psychological: Psychological profile (Big Five + Hofstede)
        segment_name: Nazwa segmentu (np. "MÅ‚odzi Prekariusze")
        segment_context: Kontekst spoÅ‚eczny segmentu (500-800 znakÃ³w)
        graph_insights: Insights filtrowane dla segmentu
        rag_citations: High-quality RAG citations
        persona_seed: Unique persona seed for diversity
        suggested_first_name: Suggested Polish first name
        suggested_surname: Suggested Polish surname

    Returns:
        Full prompt text for segment-based persona generation
    """
    age = demographic.get('age', 30)

    # Format insights
    insights_text = ""
    if graph_insights:
        insights_text = "\n".join([
            f"- {ins.get('summary', ins.get('streszczenie', 'N/A'))}"
            for ins in graph_insights[:5]
        ])

    return f"""Wygeneruj realistycznÄ… personÄ™ dla segmentu "{segment_name}".

CONSTRAINTS (MUSISZ PRZESTRZEGAÄ†!):
â€¢ Wiek: {age} lat
â€¢ PÅ‚eÄ‡: {demographic.get('gender')}
â€¢ WyksztaÅ‚cenie: {demographic.get('education_level')}
â€¢ DochÃ³d: {demographic.get('income_bracket')}
â€¢ Lokalizacja: {demographic.get('location')}

KONTEKST SEGMENTU:
{segment_context}

INSIGHTS:
{insights_text or "Brak insights"}

OSOBOWOÅšÄ† (Big Five):
â€¢ OtwartoÅ›Ä‡: {psychological.get('openness', 0.5):.2f}
â€¢ SumiennoÅ›Ä‡: {psychological.get('conscientiousness', 0.5):.2f}
â€¢ Ekstrawersja: {psychological.get('extraversion', 0.5):.2f}

ZASADY:
â€¢ Persona MUSI pasowaÄ‡ do constraints
â€¢ ZawÃ³d = wyksztaÅ‚cenie + dochÃ³d
â€¢ UÅ¼ywaj kontekstu jako tÅ‚a (nie cytuj statystyk!)
â€¢ UNIKALNOÅšÄ†: KaÅ¼da persona w segmencie MUSI mieÄ‡ RÃ“Å»NÄ„ historiÄ™ Å¼yciowÄ…!
â€¢ HEADLINE: Musi zawieraÄ‡ liczbÄ™ {age} lat i realnÄ… motywacjÄ™ tej osoby
â€¢ Background_story NIE moÅ¼e kopiowaÄ‡ briefu segmentu ani powtarzaÄ‡ caÅ‚ych akapitÃ³w z kontekstu
â€¢ PokaÅ¼ codzienne wybory i motywacje tej osoby - zero ogÃ³lnikÃ³w

âš ï¸ CATCHY SEGMENT NAME (2-4 sÅ‚owa):
Wygeneruj krÃ³tkÄ…, chwytliwÄ… nazwÄ™ marketingowÄ… dla tego segmentu.
â€¢ Powinna odzwierciedlaÄ‡ wiek, wartoÅ›ci, styl Å¼ycia, status ekonomiczny
â€¢ PrzykÅ‚ady: "Pasywni LiberaÅ‚owie", "MÅ‚odzi Prekariusze", "Aktywni Seniorzy", "Cyfrowi Nomadzi"
â€¢ UNIKAJ dÅ‚ugich opisÃ³w technicznych jak "Kobiety 35-44 wyÅ¼sze wyksztaÅ‚cenie"
â€¢ Polski jÄ™zyk, kulturowo relevantne

âš ï¸ KRYTYCZNE: Generuj UNIKALNÄ„ personÄ™ (Persona #{persona_seed})!
â€¢ NIE kopiuj ogÃ³lnych opisÃ³w segmentu do background_story
â€¢ Fokus na TEJ KONKRETNEJ OSOBY, jej specyficznych doÅ›wiadczeniach
â€¢ KaÅ¼da persona w segmencie ma INNÄ„ historiÄ™ Å¼yciowÄ…, inne detale, rÃ³Å¼ne zainteresowania

ZWRÃ“Ä† JSON:
{{
  "full_name": "{suggested_first_name} {suggested_surname}",
  "catchy_segment_name": "<2-4 sÅ‚owa, krÃ³tka marketingowa nazwa segmentu>",
  "persona_title": "<zawÃ³d>",
  "headline": "<{age} lat, zawÃ³d, UNIKALNE motywacje>",
  "background_story": "<2-3 zdania: KONKRETNA historia TEJ OSOBY - nie ogÃ³lny opis segmentu!>",
  "values": ["<5-7 wartoÅ›ci>"],
  "interests": ["<5-7 hobby>"],
  "communication_style": "<styl>",
  "decision_making_style": "<styl>",
  "typical_concerns": ["<3-5 SPECYFICZNYCH zmartwieÅ„>"]
}}"""


# Import RAG service (opcjonalny - tylko jeÅ›li RAG wÅ‚Ä…czony)
try:
    if settings.RAG_ENABLED:
        from app.services.rag.rag_hybrid_search_service import PolishSocietyRAG
        _rag_service_available = True
    else:
        _rag_service_available = False
except ImportError:
    _rag_service_available = False


class PersonaGeneratorLangChain:
    """
    Generator statystycznie reprezentatywnych person przy uÅ¼yciu LangChain + Gemini

    UÅ¼ywa Google Gemini do generowania realistycznych profili person na podstawie
    zadanych rozkÅ‚adÃ³w demograficznych i psychologicznych.
    """

    def __init__(self):
        """Inicjalizuj generator z konfiguracjÄ… LangChain i Gemini"""
        import logging
        logger = logging.getLogger(__name__)

        self.settings = settings
        self._rng = np.random.default_rng(self.settings.RANDOM_SEED)

        # Inicjalizujemy model Gemini z wyÅ¼szÄ… temperaturÄ… dla wiÄ™kszej rÃ³Å¼norodnoÅ›ci
        persona_model = getattr(settings, "PERSONA_GENERATION_MODEL", settings.DEFAULT_MODEL)

        self.llm = build_chat_model(
            model=persona_model,
            temperature=0.9,  # Podniesiona wartoÅ›Ä‡ dla bardziej kreatywnych, zrÃ³Å¼nicowanych person
            max_tokens=settings.MAX_TOKENS,
            top_p=0.95,
            top_k=40,
        )

        # Konfigurujemy parser JSON, aby wymusiÄ‡ strukturalnÄ… odpowiedÅº
        self.json_parser = JsonOutputParser()

        # Budujemy szablon promptu do generowania person (z importu)
        self.persona_prompt = PERSONA_GENERATION_CHAT_PROMPT

        # SkÅ‚adamy Å‚aÅ„cuch LangChain (prompt -> LLM -> parser)
        self.persona_chain = (
            self.persona_prompt
            | self.llm
            | self.json_parser
        )

        # Inicjalizuj RAG service (opcjonalnie - tylko jeÅ›li wÅ‚Ä…czony)
        self.rag_service = None
        if _rag_service_available and settings.RAG_ENABLED:
            try:
                self.rag_service = PolishSocietyRAG()
                logger.info("RAG service initialized successfully in PersonaGenerator")
            except Exception as e:
                logger.warning(f"RAG service unavailable: {e}")

        # In-memory cache dla RAG queries (eliminuje wielokrotne identyczne zapytania)
        # Key: (age_group, education, location, gender) tuple
        # Value: dict z RAG context
        self._rag_cache: dict[tuple[str, str, str, str], dict[str, Any]] = {}

    def _sanitize_text(self, text: str, preserve_paragraphs: bool = False) -> str:
        """
        Sanityzuj tekst wygenerowany przez LLM, usuwajÄ…c nadmierne biaÅ‚e znaki

        Metoda ta usuwa:
        - Nadmiarowe znaki nowej linii (\\n\\n -> pojedyncza spacja lub akapit)
        - Nadmiarowe spacje (wiele spacji -> jedna spacja)
        - Leading/trailing whitespace

        Args:
            text: Tekst do sanityzacji
            preserve_paragraphs: Czy zachowaÄ‡ podziaÅ‚ na akapity (dla background_story)
                                JeÅ›li True, zachowuje podziaÅ‚ na paragrafy (\\n\\n)
                                JeÅ›li False, zamienia wszystkie \\n na spacje

        Returns:
            Zsanityzowany tekst bez nadmiarowych biaÅ‚ych znakÃ³w

        PrzykÅ‚ady:
            >>> _sanitize_text("ZawÃ³d\\n\\nJuÅ¼")
            "ZawÃ³d JuÅ¼"
            >>> _sanitize_text("Tekst  z   wieloma    spacjami")
            "Tekst z wieloma spacjami"
            >>> _sanitize_text("Para 1\\n\\nPara 2", preserve_paragraphs=True)
            "Para 1\\n\\nPara 2"
        """
        if not text:
            return text

        if preserve_paragraphs:
            # Dla background_story - zachowaj podziaÅ‚ na akapity ale znormalizuj kaÅ¼dy akapit
            paragraphs = text.split('\n')
            paragraphs = [re.sub(r'\s+', ' ', p).strip() for p in paragraphs if p.strip()]
            return '\n\n'.join(paragraphs)
        else:
            # Dla pÃ³l jednoliniowych - usuÅ„ wszystkie \\n i znormalizuj spacje
            return re.sub(r'\s+', ' ', text).strip()

    def sample_big_five_traits(self, personality_skew: dict[str, float] = None) -> dict[str, float]:
        """
        PrÃ³bkuj cechy osobowoÅ›ci Big Five z rozkÅ‚adÃ³w normalnych

        Model Big Five (OCEAN) mierzy piÄ™Ä‡ gÅ‚Ã³wnych wymiarÃ³w osobowoÅ›ci:
        - Openness (otwartoÅ›Ä‡): ciekawoÅ›Ä‡, kreatywnoÅ›Ä‡
        - Conscientiousness (sumiennoÅ›Ä‡): organizacja, dyscyplina
        - Extraversion (ekstrawersja): towarzyskoÅ›Ä‡, energia
        - Agreeableness (ugodowoÅ›Ä‡): empatia, wspÃ³Å‚praca
        - Neuroticism (neurotyzm): emocjonalnoÅ›Ä‡, podatnoÅ›Ä‡ na stres

        Args:
            personality_skew: Opcjonalny sÅ‚ownik do przesuniÄ™cia rozkÅ‚adÃ³w.
                              Klucze: 'openness', 'conscientiousness', etc.
                              WartoÅ›ci: 0.0-1.0 (0=niskie, 0.5=zbalansowane, 1.0=wysokie)

        Returns:
            SÅ‚ownik z wartoÅ›ciami cech w przedziale [0, 1]
        """
        skew = personality_skew or {}

        traits = {}
        for trait in ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism']:
            # DomyÅ›lnie: Å›rednia = 0.5, odchylenie standardowe = 0.15
            mean = skew.get(trait, 0.5)
            # Upewnij siÄ™ Å¼e Å›rednia jest w przedziale [0, 1]
            mean = np.clip(mean, 0.0, 1.0)

            # Losuj z rozkÅ‚adu normalnego i przytnij do [0, 1]
            value = np.clip(self._rng.normal(mean, 0.15), 0, 1)
            traits[trait] = value

        return traits

    def sample_cultural_dimensions(self) -> dict[str, float]:
        """
        PrÃ³bkuj wymiary kulturowe Hofstede

        Model Hofstede opisuje rÃ³Å¼nice kulturowe w 6 wymiarach:
        - power_distance: akceptacja nierÃ³wnoÅ›ci wÅ‚adzy
        - individualism: indywidualizm vs kolektywizm
        - masculinity: asertywnoÅ›Ä‡ vs troska o innych
        - uncertainty_avoidance: unikanie niepewnoÅ›ci
        - long_term_orientation: orientacja dÅ‚ugo- vs krÃ³tkoterminowa
        - indulgence: pobÅ‚aÅ¼liwoÅ›Ä‡ vs powÅ›ciÄ…gliwoÅ›Ä‡

        Returns:
            SÅ‚ownik z wartoÅ›ciami wymiarÃ³w w przedziale [0, 1]
        """
        return {
            "power_distance": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "individualism": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "masculinity": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "uncertainty_avoidance": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "long_term_orientation": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
            "indulgence": np.clip(self._rng.normal(0.5, 0.2), 0, 1),
        }

    async def _get_rag_context_for_persona(
        self, demographic: dict[str, Any]
    ) -> dict[str, Any] | None:
        """
        Pobierz kontekst z RAG dla danego profilu demograficznego (z cache)

        Args:
            demographic: Profil demograficzny persony

        Returns:
            Dict z kluczami: context (str), citations (list), query (str),
            graph_context (str), graph_nodes (list), search_type (str)
            lub None jeÅ›li RAG niedostÄ™pny
        """
        if not self.rag_service:
            return None

        import logging
        logger = logging.getLogger(__name__)

        # Przygotuj cache key (normalizuj wartoÅ›ci)
        age_group = demographic.get('age_group', '25-34')
        education = demographic.get('education_level', 'wyÅ¼sze')
        location = demographic.get('location', 'Warszawa')
        gender = demographic.get('gender', 'mÄ™Å¼czyzna')

        cache_key = (age_group, education, location, gender)

        # SprawdÅº cache przed wywoÅ‚aniem RAG
        if cache_key in self._rag_cache:
            logger.debug(
                f"RAG cache HIT dla profilu: wiek={age_group}, edukacja={education}, "
                f"lokalizacja={location}, pÅ‚eÄ‡={gender}"
            )
            return self._rag_cache[cache_key]

        logger.debug(
            f"RAG cache MISS dla profilu: wiek={age_group}, edukacja={education}, "
            f"lokalizacja={location}, pÅ‚eÄ‡={gender}"
        )

        try:
            context_data = await self.rag_service.get_demographic_insights(
                age_group=age_group,
                education=education,
                location=location,
                gender=gender
            )

            # Zapisz w cache dla przyszÅ‚ych wywoÅ‚aÅ„
            self._rag_cache[cache_key] = context_data

            # Loguj szczegÃ³Å‚y RAG context
            context_len = len(context_data.get('context', ''))
            graph_nodes_count = len(context_data.get('graph_nodes', []))
            search_type = context_data.get('search_type', 'unknown')
            citations_count = len(context_data.get('citations', []))

            logger.info(
                f"RAG context retrieved: {context_len} chars, "
                f"{graph_nodes_count} graph nodes, "
                f"{citations_count} citations, "
                f"search_type={search_type}"
            )

            # JeÅ›li mamy graph nodes, loguj ich typy
            if graph_nodes_count > 0:
                node_types = [node.get('type', 'Unknown') for node in context_data.get('graph_nodes', [])]
                logger.info(f"Graph node types: {', '.join(node_types)}")

            return context_data
        except Exception as e:
            logger.error(f"RAG context retrieval failed: {e}", exc_info=True)
            return None

    async def generate_persona_personality(
        self,
        demographic_profile: dict[str, Any],
        psychological_profile: dict[str, Any],
        use_rag: bool = True,  # NOWY PARAMETR - domyÅ›lnie wÅ‚Ä…czony
        advanced_options: dict[str, Any] | None = None
    ) -> tuple[str, dict[str, Any]]:
        """
        Generuj osobowoÅ›Ä‡ persony przy uÅ¼yciu LangChain + Gemini

        Tworzy szczegÃ³Å‚owy prompt oparty na profilach demograficznym i psychologicznym,
        opcjonalnie wzbogacony o kontekst RAG z bazy wiedzy o polskim spoÅ‚eczeÅ„stwie.

        Args:
            demographic_profile: SÅ‚ownik z danymi demograficznymi (wiek, pÅ‚eÄ‡, lokalizacja, etc.)
            psychological_profile: SÅ‚ownik z cechami Big Five i wymiarami Hofstede
            use_rag: Czy uÅ¼yÄ‡ kontekstu z bazy wiedzy RAG (default: True)
            advanced_options: Opcjonalne zaawansowane opcje generowania (nieuÅ¼ywane obecnie)

        Returns:
            Krotka (prompt_text, response_dict) gdzie:
            - prompt_text: PeÅ‚ny tekst wysÅ‚any do LLM (do logowania/debugowania)
            - response_dict: Sparsowana odpowiedÅº JSON z polami persony
                            + pole '_rag_citations' jeÅ›li uÅ¼yto RAG

        Raises:
            ValueError: JeÅ›li generowanie siÄ™ nie powiedzie lub odpowiedÅº jest niepoprawna
        """

        import logging
        logger = logging.getLogger(__name__)

        # Pobierz kontekst RAG jeÅ›li wÅ‚Ä…czony
        rag_context = None
        rag_citations = None
        rag_context_details = None
        if use_rag and self.rag_service:
            rag_data = await self._get_rag_context_for_persona(demographic_profile)
            if rag_data:
                rag_context = rag_data.get('context')
                rag_citations = rag_data.get('citations')

                # Przygotuj rag_context_details dla View Details
                rag_context_details = {
                    "search_type": rag_data.get('search_type', 'unknown'),
                    "num_results": rag_data.get('num_results', 0),
                    "graph_nodes_count": rag_data.get('graph_nodes_count', len(rag_data.get('graph_nodes', []))),
                    "graph_nodes": rag_data.get('graph_nodes', []),
                    "graph_context": rag_data.get('graph_context', ''),
                    "enriched_chunks": rag_data.get('enriched_chunks_count', 0),
                }

                if rag_data.get('query'):
                    rag_context_details["query"] = rag_data.get('query')
                if rag_context:
                    rag_context_details["context_preview"] = rag_context[:1500]
                    rag_context_details["context_length"] = len(rag_context)
                if rag_citations is not None:
                    rag_context_details["citations_count"] = len(rag_citations or [])

                logger.info(
                    f"Using RAG context: {len(rag_context or '')} chars, "
                    f"{len(rag_citations or [])} citations, "
                    f"search_type={rag_context_details['search_type']}"
                )

        # Pobierz target_audience_description i orchestration brief z advanced_options
        target_audience_desc = None
        orchestration_brief = None
        if advanced_options:
            target_audience_desc = advanced_options.get('target_audience_description')
            orchestration_brief = advanced_options.get('orchestration_brief')
            if target_audience_desc:
                logger.info(f"Using target audience description: {target_audience_desc[:100]}...")
            if orchestration_brief:
                logger.info(f"Using orchestration brief: {orchestration_brief[:150]}... ({len(orchestration_brief)} chars)")

        # Generuj unikalny seed dla tej persony (do rÃ³Å¼nicowania)
        persona_seed = self._rng.integers(1000, 9999)

        # Losuj polskie imiÄ™ i nazwisko dla wiÄ™kszej rÃ³Å¼norodnoÅ›ci
        gender_lower = demographic_profile.get('gender', 'male').lower()
        if 'female' in gender_lower or 'kobieta' in gender_lower:
            suggested_first_name = self._rng.choice(POLISH_FEMALE_NAMES)
        else:
            suggested_first_name = self._rng.choice(POLISH_MALE_NAMES)
        suggested_surname = self._rng.choice(POLISH_SURNAMES)

        # Generuj prompt uÅ¼ywajÄ…c funkcji moduÅ‚owej
        prompt_text = create_persona_prompt(
            demographic_profile,
            psychological_profile,
            persona_seed=persona_seed,
            suggested_first_name=suggested_first_name,
            suggested_surname=suggested_surname,
            rag_context=rag_context,
            target_audience_description=target_audience_desc,
            orchestration_brief=orchestration_brief
        )

        try:
            logger.info(
                f"Generating persona with demographics: {demographic_profile.get('age_group')}, "
                f"{demographic_profile.get('gender')}, {demographic_profile.get('location')}"
                f" | RAG: {'YES' if rag_context else 'NO'}"
            )
            # WywoÅ‚aj Å‚aÅ„cuch LangChain (prompt -> LLM -> parser JSON)
            response = await self.persona_chain.ainvoke({"prompt": prompt_text})

            # Loguj odpowiedÅº do debugowania
            logger.info(f"LLM response type: {type(response)}, keys: {response.keys() if isinstance(response, dict) else 'N/A'}")

            # Waliduj wymagane pola
            required_fields = ["full_name", "persona_title", "headline", "background_story", "values", "interests"]
            missing_fields = [field for field in required_fields if not response.get(field)]
            if missing_fields:
                logger.error(
                    f"LLM response missing required fields: {missing_fields}. "
                    f"Response keys: {list(response.keys()) if isinstance(response, dict) else 'NOT A DICT'}"
                )

            # Sanityzuj wszystkie pola tekstowe (usuÅ„ nadmiarowe \n\n i whitespace)
            # KLUCZOWE: Zapobiega wyÅ›wietlaniu "ZawÃ³d\n\nJuÅ¼" w UI
            text_fields_single = [
                'occupation', 'full_name', 'location', 'headline',
                'persona_title', 'communication_style', 'decision_making_style'
            ]
            for field in text_fields_single:
                if field in response and isinstance(response[field], str):
                    response[field] = self._sanitize_text(response[field], preserve_paragraphs=False)

            # Sanityzuj background_story zachowujÄ…c podziaÅ‚ na akapity
            if 'background_story' in response and isinstance(response['background_story'], str):
                response['background_story'] = self._sanitize_text(response['background_story'], preserve_paragraphs=True)

            # Dodaj RAG citations i details do response (jeÅ›li byÅ‚y uÅ¼ywane)
            if rag_citations:
                response['_rag_citations'] = rag_citations
            if rag_context_details:
                response['_rag_context_details'] = rag_context_details

            return prompt_text, response
        except Exception as e:
            logger.error(f"Failed to generate persona: {str(e)[:500]}", exc_info=True)
            # Fallback dla bÅ‚Ä™dÃ³w parsowania
            raise ValueError(f"Failed to generate persona: {str(e)}")

    def _create_persona_prompt(
        self,
        demographic: dict[str, Any],
        psychological: dict[str, Any],
        rag_context: str | None = None,
        target_audience_description: str | None = None,
        orchestration_brief: str | None = None  # NOWY PARAMETR - dÅ‚ugi brief od Gemini 2.5 Pro
    ) -> str:
        """
        UtwÃ³rz prompt dla LLM do generowania persony - WERSJA POLSKA

        Tworzy szczegÃ³Å‚owy prompt zawierajÄ…cy:
        - Dane demograficzne i psychologiczne
        - InterpretacjÄ™ cech Big Five i Hofstede PO POLSKU
        - 3 przykÅ‚ady few-shot z polskimi personami
        - Opcjonalny kontekst RAG z bazy wiedzy o polskim spoÅ‚eczeÅ„stwie
        - Opcjonalny dodatkowy opis grupy docelowej od uÅ¼ytkownika
        - Opcjonalny orchestration brief (900-1200 znakÃ³w) od Gemini 2.5 Pro
        - Instrukcje jak stworzyÄ‡ unikalnÄ… polskÄ… personÄ™

        Args:
            demographic: Profil demograficzny (wiek, pÅ‚eÄ‡, edukacja, etc.)
            psychological: Profil psychologiczny (Big Five + Hofstede)
            rag_context: Opcjonalny kontekst z RAG (fragmenty z dokumentÃ³w)
            target_audience_description: Opcjonalny dodatkowy opis grupy docelowej
            orchestration_brief: Opcjonalny DÅUGI brief od orchestration agent (Gemini 2.5 Pro)

        Returns:
            PeÅ‚ny tekst prompta gotowy do wysÅ‚ania do LLM (po polsku)
        """

        # Generuj unikalny seed dla tej persony (do rÃ³Å¼nicowania)
        persona_seed = self._rng.integers(1000, 9999)

        # Losuj polskie imiÄ™ i nazwisko dla wiÄ™kszej rÃ³Å¼norodnoÅ›ci
        gender_lower = demographic.get('gender', 'male').lower()
        if 'female' in gender_lower or 'kobieta' in gender_lower:
            suggested_first_name = self._rng.choice(POLISH_FEMALE_NAMES)
        else:
            suggested_first_name = self._rng.choice(POLISH_MALE_NAMES)
        suggested_surname = self._rng.choice(POLISH_SURNAMES)

        if demographic.get('age'):
            headline_age_rule = f"â€¢ HEADLINE: Musi zawieraÄ‡ liczbÄ™ {demographic['age']} lat i realnÄ… motywacjÄ™ tej osoby.\n"
        elif demographic.get('age_group'):
            headline_age_rule = (
                f"â€¢ HEADLINE: Podaj konkretnÄ… liczbÄ™ lat zgodnÄ… z przedziaÅ‚em {demographic['age_group']} "
                "i pokaÅ¼ realnÄ… motywacjÄ™ tej osoby.\n"
            )
        else:
            headline_age_rule = "â€¢ HEADLINE: Podaj konkretny wiek w latach i realnÄ… motywacjÄ™ tej osoby.\n"

        # Pobierz wartoÅ›ci Big Five (interpretacjÄ™ robi LLM)
        openness_val = psychological.get('openness', 0.5)
        conscientiousness_val = psychological.get('conscientiousness', 0.5)
        extraversion_val = psychological.get('extraversion', 0.5)
        agreeableness_val = psychological.get('agreeableness', 0.5)
        neuroticism_val = psychological.get('neuroticism', 0.5)

        # Unified context section (merge RAG + Target Audience + Orchestration Brief)
        unified_context = ""
        if rag_context or target_audience_description or orchestration_brief:
            context_parts = []

            if rag_context:
                context_parts.append(f"ğŸ“Š KONTEKST RAG:\n{rag_context}")
            if orchestration_brief and orchestration_brief.strip():
                context_parts.append(f"ğŸ“‹ ORCHESTRATION BRIEF:\n{orchestration_brief.strip()}")
            if target_audience_description and target_audience_description.strip():
                context_parts.append(f"ğŸ¯ GRUPA DOCELOWA:\n{target_audience_description.strip()}")

            unified_context = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KONTEKST (RAG + Brief + Audience):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{chr(10).join(context_parts)}

âš ï¸ KLUCZOWE ZASADY:
â€¢ UÅ¼yj kontekstu jako TÅA Å¼ycia persony (nie cytuj statystyk!)
â€¢ StwÃ³rz FASCYNUJÄ„CÄ„ historiÄ™ - kontekst to fundament, nie lista faktÃ³w
â€¢ WskaÅºniki â†’ konkretne detale Å¼ycia (housing crisis â†’ wynajmuje, oszczÄ™dza)
â€¢ Trendy â†’ doÅ›wiadczenia Å¼yciowe (mobilnoÅ›Ä‡ â†’ zmiana 3 prac w 5 lat)
â€¢ NaturalnoÅ›Ä‡: "Jak wielu rÃ³wieÅ›nikÃ³w..." zamiast "67% absolwentÃ³w..."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""

        return f"""Expert: Syntetyczne persony dla polskiego rynku - UNIKALNE, REALISTYCZNE, SPÃ“JNE.

{unified_context}PERSONA #{persona_seed}: {suggested_first_name} {suggested_surname}

PROFIL:
â€¢ Wiek: {demographic.get('age_group')} | PÅ‚eÄ‡: {demographic.get('gender')} | Lokalizacja: {demographic.get('location')}
â€¢ WyksztaÅ‚cenie: {demographic.get('education_level')} | DochÃ³d: {demographic.get('income_bracket')}

OSOBOWOÅšÄ† (Big Five - wartoÅ›ci 0-1):
â€¢ OtwartoÅ›Ä‡ (Openness): {openness_val:.2f}
â€¢ SumiennoÅ›Ä‡ (Conscientiousness): {conscientiousness_val:.2f}
â€¢ Ekstrawersja (Extraversion): {extraversion_val:.2f}
â€¢ UgodowoÅ›Ä‡ (Agreeableness): {agreeableness_val:.2f}
â€¢ Neurotyzm (Neuroticism): {neuroticism_val:.2f}

Interpretacja Big Five: <0.4 = niskie, 0.4-0.6 = Å›rednie, >0.6 = wysokie.
Wykorzystaj te wartoÅ›ci do stworzenia spÃ³jnej osobowoÅ›ci i historii Å¼yciowej.

HOFSTEDE (wartoÅ›ci 0-1): PD={psychological.get('power_distance', 0.5):.2f} | IND={psychological.get('individualism', 0.5):.2f} | UA={psychological.get('uncertainty_avoidance', 0.5):.2f}

ZASADY:
â€¢ ZawÃ³d = wyksztaÅ‚cenie + dochÃ³d
â€¢ OsobowoÅ›Ä‡ â†’ historia (Oâ†’podrÃ³Å¼e, Sâ†’planowanie)
â€¢ Detale: dzielnice, marki, konkretne hobby
â€¢ UNIKALNOÅšÄ†: KaÅ¼da persona MUSI mieÄ‡ RÃ“Å»NÄ„ historiÄ™ Å¼yciowÄ… - nie kopiuj opisÃ³w!
â€¢ Background_story NIE moÅ¼e kopiowaÄ‡ briefu segmentu ani powtarzaÄ‡ caÅ‚ych akapitÃ³w z kontekstu
{headline_age_rule}â€¢ PokaÅ¼ codzienne wybory i motywacje tej osoby - zero ogÃ³lnikÃ³w

âš ï¸ CATCHY SEGMENT NAME (2-4 sÅ‚owa):
Wygeneruj krÃ³tkÄ…, chwytliwÄ… nazwÄ™ marketingowÄ… dla segmentu tej persony.
â€¢ Powinna odzwierciedlaÄ‡ wiek, wartoÅ›ci, styl Å¼ycia, status ekonomiczny
â€¢ PrzykÅ‚ady: "Pasywni LiberaÅ‚owie", "MÅ‚odzi Prekariusze", "Aktywni Seniorzy", "Cyfrowi Nomadzi", "Stabilni TradycjonaliÅ›ci"
â€¢ UNIKAJ dÅ‚ugich opisÃ³w technicznych jak "Kobiety 35-44 wyÅ¼sze wyksztaÅ‚cenie"
â€¢ Polski jÄ™zyk, kulturowo relevantne, konkretne

PRZYKÅAD (z rozbudowanym background_story):
{{"full_name": "Marek Kowalczyk", "catchy_segment_name": "Stabilni TradycjonaliÅ›ci", "persona_title": "GÅ‚Ã³wny KsiÄ™gowy", "headline": "PoznaÅ„ski ksiÄ™gowy (56) planujÄ…cy emeryturÄ™", "background_story": "Marek zaczÄ…Å‚ swojÄ… karierÄ™ w latach 90., kiedy polska gospodarka przechodziÅ‚a transformacjÄ™. Po ukoÅ„czeniu ekonomii na UAM w Poznaniu, dostaÅ‚ pracÄ™ w lokalnej firmie produkcyjnej jako mÅ‚odszy ksiÄ™gowy. Przez 28 lat z zaangaÅ¼owaniem budowaÅ‚ struktury finansowe firmy, przechodzÄ…c od rÄ™cznych ksiÄ…g rachunkowych do nowoczesnych systemÃ³w ERP. PamiÄ™ta czasy hiperinflacji, kiedy ceny zmieniaÅ‚y siÄ™ z dnia na dzieÅ„ - to uksztaÅ‚towaÅ‚o jego konserwatywne podejÅ›cie do finansÃ³w.\\n\\nW Å¼yciu prywatnym stabilnoÅ›Ä‡ byÅ‚a dla niego priorytetem. OÅ¼eniÅ‚ siÄ™ z AnnÄ…, koleÅ¼ankÄ… ze studiÃ³w, i razem wychowali dwoje dzieci - cÃ³rkÄ™ KasiÄ™ (dziÅ› prawniczkÄ™ w Warszawie) i syna Tomka (inÅ¼yniera w WrocÅ‚awiu). Trzy lata temu, po latach oszczÄ™dzania, speÅ‚niÅ‚ marzenie i kupiÅ‚ dziaÅ‚kÄ™ pod Poznaniem. KaÅ¼dy weekend spÄ™dza tam, budujÄ…c dom na emeryturÄ™ - to jego sposÃ³b na relaks i ucieczkÄ™ od codziennych obowiÄ…zkÃ³w.\\n\\nMarek jest rÃ³wnieÅ¼ skarbnikiem parafii w swojej dzielnicy. Pilnuje kaÅ¼dego grosza w budÅ¼ecie koÅ›cioÅ‚a, co czasami prowadzi do konfliktÃ³w z proboszczem, ktÃ³ry ma bardziej 'wizjonerskie' podejÅ›cie do wydatkÃ³w. Ale Marek nie ustÄ™puje - wie, Å¼e jego konserwatywne podejÅ›cie chroni wspÃ³lnotÄ™ przed nieprzemyÅ›lanymi decyzjami.\\n\\nTeraz, na rok przed emeryturÄ…, Marek czuje mieszankÄ™ ulgi i niepokoju. Z jednej strony cieszy siÄ™ na czas dla siebie, wÄ™dkowanie i dokoÅ„czenie domu. Z drugiej martwi siÄ™, czy jego emerytura (okoÅ‚o 3500 zÅ‚ netto) wystarczy na godne Å¼ycie, zwÅ‚aszcza przy rosnÄ…cej inflacji. Obserwuje teÅ¼ z niepokojem, jak zmienia siÄ™ Å›wiat - digitalizacja, ktÃ³rÄ… wspieraÅ‚ w firmie, teraz wydaje mu siÄ™ obca. CzÄ™sto zastanawia siÄ™, czy jego dzieci poradzÄ… sobie w tym szybko zmieniajÄ…cym siÄ™ Å›wiecie.", "values": ["StabilnoÅ›Ä‡", "LojalnoÅ›Ä‡", "Rodzina", "OdpowiedzialnoÅ›Ä‡", "OszczÄ™dnoÅ›Ä‡"], "interests": ["WÄ™dkarstwo", "Majsterkowanie", "Grillowanie", "Historia Polski", "Budowa domu"], "communication_style": "formalny, face-to-face, ceni bezpoÅ›rednie rozmowy", "decision_making_style": "metodyczny, analityczny, unika ryzyka, bazuje na doÅ›wiadczeniu", "typical_concerns": ["WysokoÅ›Ä‡ emerytury i inflacja", "Zdrowie i dostÄ™p do opieki medycznej", "PrzyszÅ‚oÅ›Ä‡ dzieci", "ZakoÅ„czenie budowy domu", "Cyfryzacja i nowe technologie"]}}

âš ï¸ KRYTYCZNE: Generuj KOMPLETNIE INNÄ„ personÄ™ z UNIKALNÄ„ historiÄ… Å¼yciowÄ…!
â€¢ NIE kopiuj ogÃ³lnych opisÃ³w segmentu do background_story
â€¢ Fokus na TEJ KONKRETNEJ OSOBY, jej specyficznych doÅ›wiadczeniach
â€¢ UÅ¼yj persona_seed #{persona_seed} jako ÅºrÃ³dÅ‚o rÃ³Å¼norodnoÅ›ci

WYÅÄ„CZNIE JSON (bez markdown):
{{
  "full_name": "<polskie imiÄ™+nazwisko>",
  "catchy_segment_name": "<2-4 sÅ‚owa, krÃ³tka marketingowa nazwa segmentu>",
  "persona_title": "<zawÃ³d/etap Å¼ycia>",
  "headline": "<1 zdanie: wiek, zawÃ³d, UNIKALNE motywacje>",
  "background_story": "<3-5 akapitÃ³w (400-600 sÅ‚Ã³w): SZCZEGÃ“ÅOWA historia TEJ OSOBY - jej Å¼ycie, kariera, wyzwania, aspiracje, konkretne wydarzenia. PokaÅ¼ jej drogÄ™ Å¼yciowÄ…, kluczowe decyzje, obecnÄ… sytuacjÄ™ i marzenia. KaÅ¼dy akapit powinien pokazywaÄ‡ inny aspekt jej Å¼ycia (przeszÅ‚oÅ›Ä‡, praca, relacje, wyzwania, cele). Pisz jak storyteller - uÅ¼ywaj konkretnych detali, emocji, wewnÄ™trznych dylemotÃ³w.>",
  "values": ["<5-7 wartoÅ›ci>"],
  "interests": ["<5-7 hobby/aktywnoÅ›ci>"],
  "communication_style": "<jak siÄ™ komunikuje>",
  "decision_making_style": "<jak podejmuje decyzje>",
  "typical_concerns": ["<3-5 SPECYFICZNYCH zmartwieÅ„/priorytetÃ³w>"]
}}"""

    # === SEGMENT-BASED ARCHITECTURE ===

    async def generate_persona_from_segment(
        self,
        segment_id: str,
        segment_name: str,
        segment_context: str,
        demographics_constraints: dict[str, Any],  # Will be DemographicConstraints from SegmentDefinition
        graph_insights: list[Any] = None,
        rag_citations: list[Any] = None,
        personality_skew: dict[str, float] | None = None
    ) -> tuple[str, dict[str, Any]]:
        """
        Generuj personÄ™ Z WYMUSZENIEM demographics z segmentu.

        KLUCZOWA RÃ“Å»NICA vs generate_persona_personality():
        - Demographics sÄ… ENFORCE (nie losowane poza bounds!)
        - Age = random.randint(age_min, age_max)
        - Gender = demographics_constraints.gender (NO randomization!)
        - Education/Income = random.choice z allowed lists

        Args:
            segment_id: ID segmentu
            segment_name: Nazwa segmentu (np. "MÅ‚odzi Prekariusze")
            segment_context: Kontekst spoÅ‚eczny segmentu
            demographics_constraints: Dict z keys: age_min, age_max, gender, education_levels, income_brackets, locations
            graph_insights: Insights filtrowane dla segmentu
            rag_citations: High-quality RAG citations
            personality_skew: Opcjonalne przesuniÄ™cie Big Five

        Returns:
            Tuple (prompt_text, response_dict)
        """
        import logging
        logger = logging.getLogger(__name__)

        # ENFORCE DEMOGRAPHICS
        age_min = demographics_constraints.get('age_min', 25)
        age_max = demographics_constraints.get('age_max', 34)
        age = self._rng.integers(age_min, age_max + 1)

        gender = demographics_constraints.get('gender', 'kobieta')
        education_levels = demographics_constraints.get('education_levels', ['wyÅ¼sze'])
        income_brackets = demographics_constraints.get('income_brackets', ['3000-5000 PLN'])
        locations = demographics_constraints.get('locations') or ['Warszawa']

        education = self._rng.choice(education_levels)
        income = self._rng.choice(income_brackets)
        location = self._rng.choice(locations)

        demographic_profile = {
            "age": age,
            "age_group": f"{age_min}-{age_max}",
            "gender": gender,
            "education_level": education,
            "income_bracket": income,
            "location": location
        }

        logger.info(
            f"ğŸ”’ ENFORCED demographics: age={age}, gender={gender}, "
            f"education={education}, income={income}, segment='{segment_name}'"
        )

        # Sample psychological profile
        psychological_profile = {
            **self.sample_big_five_traits(personality_skew),
            **self.sample_cultural_dimensions()
        }

        # Generate unique persona seed for diversity
        persona_seed = self._rng.integers(1000, 9999)

        # Suggest Polish name
        gender_lower = demographic_profile.get('gender', 'kobieta').lower()
        if 'female' in gender_lower or 'kobieta' in gender_lower:
            suggested_first_name = self._rng.choice(POLISH_FEMALE_NAMES)
        else:
            suggested_first_name = self._rng.choice(POLISH_MALE_NAMES)
        suggested_surname = self._rng.choice(POLISH_SURNAMES)

        # Create prompt with segment context (uÅ¼ywajÄ…c funkcji moduÅ‚owej)
        prompt_text = create_segment_persona_prompt(
            demographic_profile,
            psychological_profile,
            segment_name,
            segment_context,
            graph_insights,
            rag_citations,
            persona_seed,
            suggested_first_name,
            suggested_surname
        )

        try:
            response = await self.persona_chain.ainvoke({"prompt": prompt_text})

            # ENFORCE demographic fields (override LLM if needed)
            response['age'] = age
            response['gender'] = gender
            response['education_level'] = education
            response['income_bracket'] = income
            response['location'] = location

            # Sanityzuj wszystkie pola tekstowe (usuÅ„ nadmiarowe \n\n i whitespace)
            text_fields_single = [
                'occupation', 'full_name', 'location', 'headline',
                'persona_title', 'communication_style', 'decision_making_style'
            ]
            for field in text_fields_single:
                if field in response and isinstance(response[field], str):
                    response[field] = self._sanitize_text(response[field], preserve_paragraphs=False)

            # Sanityzuj background_story zachowujÄ…c podziaÅ‚ na akapity
            if 'background_story' in response and isinstance(response['background_story'], str):
                response['background_story'] = self._sanitize_text(response['background_story'], preserve_paragraphs=True)

            # Add segment tracking
            response['_segment_id'] = segment_id
            response['_segment_name'] = segment_name

            if rag_citations:
                response['_rag_citations'] = rag_citations

            logger.info(f"âœ… Persona generated: {response.get('full_name')} (segment='{segment_name}')")
            return prompt_text, response

        except Exception as e:
            logger.error(f"âŒ Failed to generate persona from segment: {e}", exc_info=True)
            raise ValueError(f"Failed to generate persona from segment '{segment_name}': {e}")

    def _create_segment_persona_prompt(
        self,
        demographic: dict[str, Any],
        psychological: dict[str, Any],
        segment_name: str,
        segment_context: str,
        graph_insights: list[Any],
        rag_citations: list[Any]
    ) -> str:
        """Create prompt for segment-based persona generation."""

        # Suggest Polish name
        gender_lower = demographic.get('gender', 'kobieta').lower()
        if 'female' in gender_lower or 'kobieta' in gender_lower:
            suggested_first_name = self._rng.choice(POLISH_FEMALE_NAMES)
        else:
            suggested_first_name = self._rng.choice(POLISH_MALE_NAMES)
        suggested_surname = self._rng.choice(POLISH_SURNAMES)

        age = demographic.get('age', 30)

        # Generate unique persona seed for diversity
        persona_seed = self._rng.integers(1000, 9999)

        # Format insights
        insights_text = ""
        if graph_insights:
            insights_text = "\n".join([
                f"- {ins.get('summary', ins.get('streszczenie', 'N/A'))}"
                for ins in graph_insights[:5]
            ])

        return f"""Wygeneruj realistycznÄ… personÄ™ dla segmentu "{segment_name}".

CONSTRAINTS (MUSISZ PRZESTRZEGAÄ†!):
â€¢ Wiek: {age} lat
â€¢ PÅ‚eÄ‡: {demographic.get('gender')}
â€¢ WyksztaÅ‚cenie: {demographic.get('education_level')}
â€¢ DochÃ³d: {demographic.get('income_bracket')}
â€¢ Lokalizacja: {demographic.get('location')}

KONTEKST SEGMENTU:
{segment_context}

INSIGHTS:
{insights_text or "Brak insights"}

OSOBOWOÅšÄ† (Big Five):
â€¢ OtwartoÅ›Ä‡: {psychological.get('openness', 0.5):.2f}
â€¢ SumiennoÅ›Ä‡: {psychological.get('conscientiousness', 0.5):.2f}
â€¢ Ekstrawersja: {psychological.get('extraversion', 0.5):.2f}

ZASADY:
â€¢ Persona MUSI pasowaÄ‡ do constraints
â€¢ ZawÃ³d = wyksztaÅ‚cenie + dochÃ³d
â€¢ UÅ¼ywaj kontekstu jako tÅ‚a (nie cytuj statystyk!)
â€¢ UNIKALNOÅšÄ†: KaÅ¼da persona w segmencie MUSI mieÄ‡ RÃ“Å»NÄ„ historiÄ™ Å¼yciowÄ…!
â€¢ HEADLINE: Musi zawieraÄ‡ liczbÄ™ {age} lat i realnÄ… motywacjÄ™ tej osoby
â€¢ Background_story NIE moÅ¼e kopiowaÄ‡ briefu segmentu ani powtarzaÄ‡ caÅ‚ych akapitÃ³w z kontekstu
â€¢ PokaÅ¼ codzienne wybory i motywacje tej osoby - zero ogÃ³lnikÃ³w

âš ï¸ CATCHY SEGMENT NAME (2-4 sÅ‚owa):
Wygeneruj krÃ³tkÄ…, chwytliwÄ… nazwÄ™ marketingowÄ… dla tego segmentu.
â€¢ Powinna odzwierciedlaÄ‡ wiek, wartoÅ›ci, styl Å¼ycia, status ekonomiczny
â€¢ PrzykÅ‚ady: "Pasywni LiberaÅ‚owie", "MÅ‚odzi Prekariusze", "Aktywni Seniorzy", "Cyfrowi Nomadzi"
â€¢ UNIKAJ dÅ‚ugich opisÃ³w technicznych jak "Kobiety 35-44 wyÅ¼sze wyksztaÅ‚cenie"
â€¢ Polski jÄ™zyk, kulturowo relevantne

âš ï¸ KRYTYCZNE: Generuj UNIKALNÄ„ personÄ™ (Persona #{persona_seed})!
â€¢ NIE kopiuj ogÃ³lnych opisÃ³w segmentu do background_story
â€¢ Fokus na TEJ KONKRETNEJ OSOBY, jej specyficznych doÅ›wiadczeniach
â€¢ KaÅ¼da persona w segmencie ma INNÄ„ historiÄ™ Å¼yciowÄ…, inne detale, rÃ³Å¼ne zainteresowania

ZWRÃ“Ä† JSON:
{{
  "full_name": "{suggested_first_name} {suggested_surname}",
  "catchy_segment_name": "<2-4 sÅ‚owa, krÃ³tka marketingowa nazwa segmentu>",
  "persona_title": "<zawÃ³d>",
  "headline": "<{age} lat, zawÃ³d, UNIKALNE motywacje>",
  "background_story": "<2-3 zdania: KONKRETNA historia TEJ OSOBY - nie ogÃ³lny opis segmentu!>",
  "values": ["<5-7 wartoÅ›ci>"],
  "interests": ["<5-7 hobby>"],
  "communication_style": "<styl>",
  "decision_making_style": "<styl>",
  "typical_concerns": ["<3-5 SPECYFICZNYCH zmartwieÅ„>"]
}}"""
