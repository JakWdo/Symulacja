"""Serwis orkiestracji generowania person u≈ºywajƒÖcy Gemini 2.5 Pro.

Ten modu≈Ç zawiera `PersonaOrchestrationService`, kt√≥ry wykorzystuje Gemini 2.5 Pro
do przeprowadzenia g≈Çƒôbokiej analizy Graph RAG i tworzenia szczeg√≥≈Çowych brief√≥w
(900-1200 znak√≥w) dla ka≈ºdej grupy demograficznej person.

Filozofia:
- Orchestration Agent (Gemini 2.5 Pro) = complex reasoning, d≈Çugie analizy
- Individual Generators (Gemini 2.5 Flash) = szybkie generowanie konkretnych person
- Output style: Edukacyjny - wyja≈õnia "dlaczego", konwersacyjny ton
"""

from __future__ import annotations

import asyncio
import json
import logging
from typing import Any

from pydantic import BaseModel, Field

from app.core.config import get_settings
from app.services.rag.rag_hybrid_search_service import PolishSocietyRAG
from app.services.shared.clients import build_chat_model

settings = get_settings()
logger = logging.getLogger(__name__)


def _map_graph_node_to_insight(node: dict[str, Any]) -> "GraphInsight" | None:
    """Konwertuje graph node z polskimi property names na GraphInsight z angielskimi.

    Mapowanie:
    - streszczenie ‚Üí summary
    - skala ‚Üí magnitude
    - pewnosc ‚Üí confidence ("wysoka"‚Üí"high", "srednia"‚Üí"medium", "niska"‚Üí"low")
    - okres_czasu ‚Üí time_period
    - kluczowe_fakty ‚Üí why_matters (z dodatkowym kontekstem)

    Args:
        node: Dict z grafu Neo4j (polskie property names)

    Returns:
        GraphInsight object lub None je≈õli dane niepe≈Çne
    """
    if not node:
        return None

    # Graf u≈ºywa polskich property names
    node_type = node.get('type', 'Unknown')
    summary = node.get('streszczenie')

    if not summary:
        logger.warning(f"Graph node bez streszczenia: {node}")
        return None

    # Mapowanie pewno≈õci PL‚ÜíEN
    pewnosc_pl = node.get('pewnosc', '').lower()
    confidence_map = {'wysoka': 'high', 'srednia': 'medium', 'niska': 'low'}
    confidence = confidence_map.get(pewnosc_pl, 'medium')

    # Dane wƒôz≈Ça (polskie property names)
    magnitude = node.get('skala')
    time_period = node.get('okres_czasu')
    source = node.get('source', node.get('document_title'))

    # why_matters - u≈ºyj kluczowych fakt√≥w lub summary jako fallback
    kluczowe_fakty = node.get('kluczowe_fakty', '')
    why_matters = f"Ten wska≈∫nik pokazuje: {kluczowe_fakty}" if kluczowe_fakty else summary

    try:
        return GraphInsight(
            type=node_type,
            summary=summary,
            magnitude=magnitude,
            confidence=confidence,
            time_period=time_period,
            source=source,
            why_matters=why_matters
        )
    except Exception as e:
        logger.error(f"Nie mo≈ºna utworzyƒá GraphInsight z node: {node}, error: {e}")
        return None


class GraphInsight(BaseModel):
    """Pojedynczy insight z grafu wiedzy (Wskaznik, Obserwacja, Trend).

    UWAGA: Ten schema u≈ºywa ANGIELSKICH property names dla API consistency.
    Dane w grafie Neo4j u≈ºywajƒÖ POLSKICH nazw (streszczenie, skala, pewnosc, etc.).

    Konwersja wykonywana przez funkcjƒô _map_graph_node_to_insight():
    - streszczenie ‚Üí summary
    - skala ‚Üí magnitude
    - pewnosc ‚Üí confidence ("wysoka"‚Üí"high", "srednia"‚Üí"medium", "niska"‚Üí"low")
    - okres_czasu ‚Üí time_period
    - kluczowe_fakty ‚Üí why_matters (z dodatkowym edukacyjnym kontekstem)
    """

    type: str = Field(description="Typ wƒôz≈Ça (Wskaznik, Obserwacja, Trend, etc.)")
    summary: str = Field(description="Jednozdaniowe podsumowanie")
    magnitude: str | None = Field(default=None, description="Warto≈õƒá liczbowa je≈õli istnieje (np. '78.4%')")
    confidence: str = Field(default="medium", description="Poziom pewno≈õci: high, medium, low")
    time_period: str | None = Field(default=None, description="Okres czasu (np. '2022')")
    source: str | None = Field(default=None, description="≈πr√≥d≈Ço danych (np. 'GUS', 'CBOS')")
    why_matters: str = Field(description="Edukacyjne wyja≈õnienie dlaczego to wa≈ºne dla person")


class DemographicGroup(BaseModel):
    """Grupa demograficzna z briefem i insightami."""

    count: int = Field(description="Liczba person do wygenerowania w tej grupie")
    demographics: dict[str, Any] = Field(description="Cechy demograficzne (age, gender, education, etc.)")
    brief: str = Field(description="D≈Çugi (900-1200 znak√≥w) edukacyjny brief dla generator√≥w")
    graph_insights: list[GraphInsight] = Field(default_factory=list, description="Insighty z Graph RAG")
    allocation_reasoning: str = Field(description="Dlaczego tyle person w tej grupie")
    segment_characteristics: list[str] = Field(default_factory=list, description="4-6 kluczowych cech tego segmentu (np. 'Profesjonali≈õci z wielkich miast')")


class PersonaAllocationPlan(BaseModel):
    """Plan alokacji person z szczeg√≥≈Çowymi briefami dla ka≈ºdej grupy."""

    total_personas: int = Field(description="Ca≈Çkowita liczba person do wygenerowania")
    groups: list[DemographicGroup] = Field(description="Grupy demograficzne z briefami")
    overall_context: str = Field(description="Og√≥lny kontekst spo≈Çeczny Polski z Graph RAG")


class PersonaOrchestrationService:
    """Serwis orkiestracji u≈ºywajƒÖcy Gemini 2.5 Pro do tworzenia brief√≥w.

    Ten serwis:
    1. Pobiera comprehensive Graph RAG context (Wskazniki, Grupy_Demograficzne, Trendy)
    2. Przeprowadza g≈ÇƒôbokƒÖ socjologicznƒÖ analizƒô u≈ºywajƒÖc Gemini 2.5 Pro
    3. Tworzy szczeg√≥≈Çowe briefe (900-1200 znak√≥w) dla ka≈ºdej grupy person
    4. Wyja≈õnia "dlaczego" (edukacyjny output style) dla wszystkich decyzji

    Output style: Konwersacyjny, edukacyjny, wyja≈õniajƒÖcy, production-ready.
    """

    def __init__(self) -> None:
        """Inicjalizuje orchestration agent (Gemini 2.5 Pro) i RAG service."""

        # Gemini 2.5 Pro dla complex reasoning i d≈Çugich analiz
        self.llm = build_chat_model(
            model="gemini-2.5-pro",
            temperature=0.0,  # Deterministyczny output dla JSON generation (zero creativity needed)
            max_tokens=8000,  # WystarczajƒÖco na pe≈Çny plan + briefy
            timeout=120,  # 2 minuty dla complex reasoning
        )

        # RAG service dla hybrid search kontekstu
        self.rag_service = PolishSocietyRAG()

        logger.info("PersonaOrchestrationService zainicjalizowany (Gemini 2.5 Pro)")

    async def create_persona_allocation_plan(
        self,
        target_demographics: dict[str, Any],
        num_personas: int,
        project_description: str | None = None,
        additional_context: str | None = None,
    ) -> PersonaAllocationPlan:
        """Tworzy szczeg√≥≈Çowy plan alokacji person z d≈Çugimi briefami.

        Gemini 2.5 Pro przeprowadza g≈ÇƒôbokƒÖ analizƒô:
        1. Pobiera Graph RAG context (hybrid search dla rozk≈Çad√≥w demograficznych)
        2. Analizuje trendy spo≈Çeczne i wska≈∫niki statystyczne
        3. Tworzy sp√≥jne (900-1200 znak√≥w) edukacyjne briefe
        4. Wyja≈õnia "dlaczego" dla ka≈ºdej decyzji alokacyjnej

        Args:
            target_demographics: Rozk≈Çad demograficzny projektu (age_group, gender, etc.)
            num_personas: Ca≈Çkowita liczba person do wygenerowania
            project_description: Opis projektu badawczego
            additional_context: Dodatkowy kontekst od u≈ºytkownika (z AI Wizard)

        Returns:
            PersonaAllocationPlan z grupami demograficznymi i szczeg√≥≈Çowymi briefami

        Raises:
            Exception: Je≈õli LLM nie mo≈ºe wygenerowaƒá planu lub JSON parsing fails
        """
        logger.info(f"üéØ Orchestration: Tworzenie planu alokacji dla {num_personas} person...")

        # Krok 1: Pobierz comprehensive Graph RAG context
        graph_context = await self._get_comprehensive_graph_context(target_demographics)
        logger.info(f"üìä Pobrano {len(graph_context)} fragment√≥w z Graph RAG")

        # Krok 2: Zbuduj prompt w stylu edukacyjnym
        prompt = self._build_orchestration_prompt(
            target_demographics=target_demographics,
            num_personas=num_personas,
            graph_context=graph_context,
            project_description=project_description,
            additional_context=additional_context,
        )

        # Krok 3: Gemini 2.5 Pro generuje plan z retry logic
        max_retries = 2
        last_error = None

        for attempt in range(1, max_retries + 1):
            try:
                logger.info(f"ü§ñ Gemini 2.5 Pro attempt {attempt}/{max_retries} (max_tokens=8000, timeout=120s)...")
                response = await self.llm.ainvoke(prompt)

                # DEBUG: Log surowej odpowiedzi od Gemini
                response_text = response.content if hasattr(response, 'content') else str(response)
                logger.info(f"üìù Gemini response length: {len(response_text)} chars")
                logger.info(f"üìù Gemini response preview (first 500 chars): {response_text[:500]}")
                logger.info(f"üìù Gemini response preview (last 500 chars): {response_text[-500:]}")

                plan_json = self._extract_json_from_response(response_text)

                # DEBUG: Log sparsowanego JSON
                logger.info(f"‚úÖ JSON parsed successfully: {len(plan_json)} top-level keys")
                logger.info(f"‚úÖ JSON keys: {list(plan_json.keys())}")

                # Parse do Pydantic model (walidacja)
                plan = PersonaAllocationPlan(**plan_json)

                logger.info(f"‚úÖ Plan alokacji utworzony: {len(plan.groups)} grup demograficznych")
                return plan

            except json.JSONDecodeError as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è  Attempt {attempt}/{max_retries} - JSON syntax error: {e}")
                logger.warning(f"   Error at: line {e.lineno} col {e.colno} (pos {e.pos})")

                if attempt < max_retries:
                    logger.info("   Retrying with enhanced error feedback in prompt...")
                    # Dodaj do promptu feedback o b≈Çƒôdzie (dla retry)
                    error_context = f"""

‚ö†Ô∏è  **PREVIOUS ATTEMPT FAILED - FIX THIS ERROR:**
- JSON syntax error at line {e.lineno}, column {e.colno}
- Error: {str(e)}
- CRITICAL: Check for trailing commas, unclosed brackets, or invalid escapes
- Return ONLY valid JSON, no preamble, no explanations!
"""
                    prompt = prompt + error_context
                else:
                    logger.error(f"‚ùå All {max_retries} attempts failed with JSON syntax errors")
                    logger.error(f"‚ùå Last error: {e}")
                    raise

            except Exception as e:
                last_error = e
                logger.error(f"‚ùå Attempt {attempt}/{max_retries} - Unexpected error: {e}")
                logger.error(f"‚ùå Exception type: {type(e).__name__}")
                logger.error(f"‚ùå Exception details: {str(e)[:1000]}")

                if attempt < max_retries:
                    logger.info("   Retrying...")
                else:
                    logger.error(f"‚ùå All {max_retries} attempts failed")
                    raise

        # Je≈õli tu dojdziemy, znaczy ≈ºe wszystkie retries failed
        if last_error:
            raise last_error
        else:
            raise Exception("Failed to create persona allocation plan after all retries")

    async def _get_comprehensive_graph_context(
        self,
        target_demographics: dict[str, Any]
    ) -> str:
        """Pobiera comprehensive Graph RAG context dla rozk≈Çad√≥w demograficznych.

        Hybrid search (vector + keyword + RRF) dla ka≈ºdej grupy demograficznej:
        - Age groups (18-24, 25-34, etc.)
        - Gender
        - Education levels
        - Locations

        Args:
            target_demographics: Rozk≈Çad demograficzny (age_group, gender, etc.)

        Returns:
            Sformatowany string z Graph RAG context (Wskazniki, Obserwacje, Trendy)
        """
        # Przygotuj queries dla hybrid search
        queries = []

        # Age groups
        if "age_group" in target_demographics:
            for age_group in target_demographics["age_group"].keys():
                queries.append(f"demographics statistics age {age_group} Poland")

        # Gender
        if "gender" in target_demographics:
            for gender in target_demographics["gender"].keys():
                queries.append(f"gender {gender} demographics Poland workforce")

        # Education
        if "education_level" in target_demographics:
            for education in target_demographics["education_level"].keys():
                queries.append(f"education level {education} Poland employment")

        # Og√≥lne trendy spo≈Çeczne
        queries.extend([
            "Polish society trends 2023 2024 demographics",
            "workforce statistics Poland employment rates",
            "income housing costs Poland urban areas",
            "work-life balance trends Poland young professionals",
        ])

        # Wykonaj parallel hybrid searches z timeout
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*[
                    self.rag_service.hybrid_search(query=q, top_k=3)
                    for q in queries[:8]  # Limit do 8 queries (24 results max)
                ]),
                timeout=30.0  # 30 sekund dla wszystkich queries
            )
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è Graph RAG queries przekroczy≈Çy timeout (30s) - zwracam pusty kontekst")
            return "Brak dostƒôpnego kontekstu z Graph RAG (timeout)."

        # Deduplikuj i formatuj
        all_docs = []
        seen_texts = set()
        for docs_list in results:
            for doc in docs_list:
                if doc.page_content not in seen_texts:
                    all_docs.append(doc)
                    seen_texts.add(doc.page_content)

        # Formatuj jako czytelny context
        formatted_context = self._format_graph_context(all_docs[:15])  # Top 15 unique
        return formatted_context

    def _format_graph_context(self, documents: list[Any]) -> str:
        """Formatuje Graph RAG documents jako czytelny context dla LLM.

        Args:
            documents: Lista Document objects z Graph RAG

        Returns:
            Sformatowany string z numbered entries
        """
        if not documents:
            return "Brak dostƒôpnego kontekstu z Graph RAG."

        formatted = "=== KONTEKST Z GRAPH RAG (Raporty o polskim spo≈Çecze≈Ñstwie) ===\n\n"

        for idx, doc in enumerate(documents, 1):
            formatted += f"[{idx}] {doc.page_content}\n"

            # Dodaj metadata je≈õli istnieje
            if hasattr(doc, 'metadata') and doc.metadata:
                meta = doc.metadata
                if 'source' in meta:
                    formatted += f"    ≈πr√≥d≈Ço: {meta['source']}\n"
                if 'document_title' in meta:
                    formatted += f"    Tytu≈Ç: {meta['document_title']}\n"

            formatted += "\n"

        return formatted

    def _build_orchestration_prompt(
        self,
        target_demographics: dict[str, Any],
        num_personas: int,
        graph_context: str,
        project_description: str | None,
        additional_context: str | None,
    ) -> str:
        """Buduje prompt w stylu edukacyjnym dla Gemini 2.5 Pro.

        Prompt instruuje LLM aby:
        1. Przeanalizowaƒá Graph RAG context (Wskazniki, Obserwacje)
        2. Wyja≈õniƒá "dlaczego" dla ka≈ºdej decyzji (edukacyjny styl)
        3. Utworzyƒá sp√≥jne (900-1200 znak√≥w) briefe dla ka≈ºdej grupy
        4. U≈ºyƒá konwersacyjnego tonu (jak kolega z zespo≈Çu)

        Args:
            target_demographics: Rozk≈Çad demograficzny
            num_personas: Liczba person
            graph_context: Kontekst z Graph RAG
            project_description: Opis projektu
            additional_context: Dodatkowy kontekst od u≈ºytkownika

        Returns:
            D≈Çugi prompt string (production-ready instrukcje)
        """
        prompt = f"""
Jeste≈õ ekspertem od socjologii i bada≈Ñ spo≈Çecznych w Polsce. Twoim zadaniem jest
przeanalizowanie danych demograficznych i Graph RAG context, a nastƒôpnie stworzenie
szczeg√≥≈Çowego, EDUKACYJNEGO planu alokacji {num_personas} syntetycznych person.

=== STYL KOMUNIKACJI (KRYTYCZNY!) ===

WA≈ªNE: Twoim outputem bƒôdzie u≈ºywany bezpo≈õrednio przez innych agent√≥w AI oraz
pokazywany u≈ºytkownikom w interfejsie. Dlatego MUSISZ:

‚úÖ **Konwersacyjny ton** - M√≥wisz jak kolega z zespo≈Çu, nie jak suchy raport
‚úÖ **Wyja≈õniaj "dlaczego"** - Nie podawaj tylko fakt√≥w, ale ich znaczenie i kontekst
‚úÖ **U≈ºywaj przyk≈Çad√≥w z ≈ºycia** - "Wyobra≈∫ sobie Annƒô z Warszawy, kt√≥ra..."
‚úÖ **Production-ready** - Tre≈õƒá mo≈ºe i≈õƒá bezpo≈õrednio do u≈ºytkownika bez edycji
‚úÖ **Edukacyjny** - User ma siƒô UCZYƒÜ o polskim spo≈Çecze≈Ñstwie, nie tylko dostaƒá dane
‚úÖ **PO POLSKU** - Naturalnie, bez anglicyzm√≥w gdzie niepotrzebne

    D≈ÅUGO≈öƒÜ BRIEF√ìW: Ka≈ºdy brief dla grupy demograficznej ma mieƒá 900-1200 znak√≥w.
    To ma byƒá edukacyjny mini-esej, kt√≥ry wyja≈õnia kontekst spo≈Çeczny bez lania wody.

=== DANE WEJ≈öCIOWE ===

**Projekt badawczy:**
{project_description or "Badanie person syntetycznych"}

**Dodatkowy kontekst od u≈ºytkownika:**
{additional_context or "Brak dodatkowego kontekstu"}

**Rozk≈Çad demograficzny docelowy:**
```json
{json.dumps(target_demographics, indent=2, ensure_ascii=False)}
```

**Liczba person do wygenerowania:** {num_personas}

{graph_context}

=== TWOJE ZADANIE ===

Przeprowad≈∫ g≈ÇƒôbokƒÖ socjologicznƒÖ analizƒô i stw√≥rz plan alokacji person kt√≥ry zawiera:

### 1. OG√ìLNY KONTEKST SPO≈ÅECZNY (500-800 znak√≥w)

Zr√≥b overview polskiego spo≈Çecze≈Ñstwa bazujƒÖc na Graph RAG context:
- Jakie sƒÖ kluczowe trendy demograficzne w Polsce?
- Co pokazujƒÖ wska≈∫niki ekonomiczne (zatrudnienie, dochody, housing)?
- Jakie warto≈õci i wyzwania ma polskie spo≈Çecze≈Ñstwo 2025?
- Dlaczego to ma znaczenie dla generowania person?
- Dla kazdej osoby tw√≥rz opis dlaczego akurat do niej siƒô to tyczy.

### 2. GRUPY DEMOGRAFICZNE Z D≈ÅUGIMI BRIEFAMI

Dla ka≈ºdej znaczƒÖcej grupy demograficznej (na podstawie rozk≈Çadu docelowego), stw√≥rz:

**Ka≈ºdy brief MUSI zawieraƒá (900-1200 znak√≥w):**

a) **Dlaczego ta grupa?** (180-220 znak√≥w)
   - Jaki % populacji stanowi ta grupa (z Graph RAG)
   - Dlaczego sƒÖ wa≈ºni dla badania
   - Jak rozk≈Çad pasuje do reali√≥w polskiego spo≈Çecze≈Ñstwa
   - Statystyki z Graph RAG (magnitude, confidence)

b) **Kontekst zawodowy i ≈ºyciowy** (260-320 znak√≥w)
   - Typowe zawody dla tej grupy
   - Zarobki (realne liczby w PLN z Graph RAG je≈õli dostƒôpne)
   - Housing situation (w≈Çasne/wynajem, ceny mieszka≈Ñ)
   - Wyzwania ekonomiczne (kredyty, oszczƒôdno≈õci, koszty ≈ºycia)
   - Dlaczego tak jest? (spo≈Çeczno-ekonomiczny kontekst)

c) **Warto≈õci i aspiracje** (260-320 znak√≥w)
   - Jakie warto≈õci sƒÖ wa≈ºne dla tej grupy (z bada≈Ñ spo≈Çecznych)
   - Aspiracje i life goals
   - Dlaczego te warto≈õci? (kontekst pokoleniowy, historyczny)
   - Jak zmienia siƒô to w czasie (trendy)

d) **Typowe wyzwania i zainteresowania** (180-240 znak√≥w)
   - Realne problemy ≈ºyciowe tej grupy
   - Typowe hobby i spos√≥b spƒôdzania wolnego czasu
   - Dlaczego te zainteresowania pasujƒÖ do profilu

e) **Segment Characteristics** (4-6 kluczowych cech tego segmentu)
   - Kr√≥tkie, m√≥wiƒÖce cechy charakterystyczne dla tej grupy
   - Format: Lista string√≥w (np. ["Profesjonali≈õci z wielkich miast", "Wysoko wykszta≈Çceni", "Stabilna kariera"])
   - Cechy powinny byƒá KONKRETNE dla tej grupy (nie og√≥lne!)
   - Bazowane na demographics + insights z grafu

f) **Graph Insights** (structured data)
   - Lista 3-5 kluczowych wska≈∫nik√≥w z Graph RAG
   - Ka≈ºdy z wyja≈õnieniem "why_matters"

g) **Allocation Reasoning**
   - Dlaczego tyle person w tej grupie (X z {num_personas})?
   - Jak to odnosi siƒô do % populacji vs. relevance dla badania?

### 3. PRZYK≈ÅAD DOBREGO BRIEFU

```
# Grupa: Kobiety 25-34, wy≈ºsze wykszta≈Çcenie, Warszawa (6 person)

## Dlaczego ta grupa?

W polskim spo≈Çecze≈Ñstwie kobiety 25-34 z wy≈ºszym wykszta≈Çceniem stanowiƒÖ
oko≈Ço 17.3% populacji miejskiej wed≈Çug danych GUS z 2022 roku. To fascynujƒÖca
grupa spo≈Çeczna kt√≥ra znajduje siƒô w momencie ≈ºycia pe≈Çnym zmian - balansujƒÖ
miƒôdzy budowaniem kariery a decyzjami o rodzinie, miƒôdzy niezale≈ºno≈õciƒÖ finansowƒÖ
a realiami rynku nieruchomo≈õci.

Dla tego badania ta grupa jest kluczowa bo to oni sƒÖ early adopters nowych
produkt√≥w i us≈Çug. Wska≈∫niki pokazujƒÖ ≈ºe 78.4% tej grupy jest zatrudnionych
(najwy≈ºsza stopa w Polsce!), co oznacza ≈ºe majƒÖ purchasing power. Jednocze≈õnie
63% wykazuje wysokƒÖ mobilno≈õƒá zawodowƒÖ - czƒôsto zmieniajƒÖ pracƒô, co czyni ich
otwartymi na nowe rozwiƒÖzania.

## Kontekst zawodowy i ≈ºyciowy

Warszawa koncentruje 35% polskiego rynku tech, fintech i consulting. Dla m≈Çodych
kobiet z wy≈ºszym wykszta≈Çceniem to oznacza szeroki wyb√≥r mo≈ºliwo≈õci kariery - od
project manager√≥w przez UX designer√≥w po analityk√≥w danych. Typowe zarobki w tej
grupie to 7000-12000 z≈Ç netto, co brzmi nie≈∫le, ale...

...ale tu zaczyna siƒô problem. Cena m2 w Warszawie to ~15000 z≈Ç. Dla osoby
zarabiajƒÖcej 9000 z≈Ç netto (mediana), zakup 50m2 mieszkania wymaga od≈Ço≈ºenia
~750000 z≈Ç, co przy oszczƒôdzaniu 2000 z≈Ç miesiƒôcznie daje... 31 lat. Nie dziwi
wiƒôc ≈ºe 45% tej grupy wynajmuje mieszkania. To nie wyb√≥r stylu ≈ºycia - to
konieczno≈õƒá ekonomiczna.

[... dalszy tekst 1000+ znak√≥w ...]
```

=== CRITICAL: JSON OUTPUT REQUIREMENTS ===

‚ö†Ô∏è  **BARDZO WA≈ªNE - PRZECZYTAJ UWA≈ªNIE:**

Your output will be parsed by `json.loads()`. MUSISZ przestrzegaƒá tych zasad:

1. **TYLKO JSON** - Zwr√≥ƒá WY≈ÅƒÑCZNIE obiekt JSON, bez ≈ªADNEGO dodatkowego tekstu:
   - ‚ùå NIE: "Jasne, rozumiem zadanie. Zaczynajmy!\\n```json\\n{{...}}"
   - ‚úÖ TAK: "{{...}}" (tylko czysty JSON)
   - ‚ùå NIE: Dodawanie preambu≈Çy, wyja≈õnie≈Ñ przed JSON
   - ‚úÖ TAK: Start response bezpo≈õrednio z `{{`

2. **Poprawna sk≈Çadnia JSON:**
   - ‚ùå NIE: trailing commas: `"key": "value",]` lub `{{"x": 1,}}`
   - ‚úÖ TAK: brak trailing comma: `"key": "value"]` i `{{"x": 1}}`
   - ‚ùå NIE: single quotes: `{{'key': 'value'}}`
   - ‚úÖ TAK: double quotes: `{{"key": "value"}}`
   - ‚ùå NIE: comments: `// this is comment`
   - ‚úÖ TAK: tylko valid JSON (brak komentarzy)

3. **Zamkniƒôte nawiasy** - ka≈ºdy `{{` ma swoje `}}`, ka≈ºdy `[` ma swoje `]`
   - Sprawd≈∫ szczeg√≥lnie d≈Çugie listy (graph_insights!)

4. **Escaped characters** - u≈ºyj `\\n` dla newlines w d≈Çugich tekstach
   - Brief mo≈ºe mieƒá 1200 znak√≥w ‚Üí u≈ºyj `\\n` dla nowych linii

5. **Valid Unicode** - polskie znaki (ƒÖ, ƒô, ≈õ, etc.) sƒÖ OK w UTF-8

**BAD Example (WILL CRASH):**
```
Cze≈õƒá! Przeanalizowa≈Çem dane. Oto plan:
```json
{{
  "groups": [
    {{"count": 2, "demographics": {{...}},}}  // trailing comma!
  ]
}}
```
```

**GOOD Example (VALID):**
```json
{{
  "total_personas": 4,
  "overall_context": "Tekst...",
  "groups": [
    {{"count": 2, "demographics": {{"age": "25-34"}}}}
  ]
}}
```

Je≈õli masz wƒÖtpliwo≈õci, mentalnie zwaliduj output przez https://jsonlint.com/

=== OUTPUT FORMAT ===

Generuj JSON zgodny z tym schematem:

```json
{{
  "total_personas": {num_personas},
  "overall_context": "D≈ÅUGI (500-800 znak√≥w) overview polskiego spo≈Çecze≈Ñstwa...",
  "groups": [
    {{
      "count": 6,
      "demographics": {{
        "age": "25-34",
        "gender": "kobieta",
        "education": "wy≈ºsze",
        "location": "Warszawa"
      }},
      "brief": "Edukacyjny brief (900-1200 znak√≥w) jak w przyk≈Çadzie...",
      "segment_characteristics": [
        "Profesjonali≈õci z wielkich miast",
        "Wysoko wykszta≈Çceni",
        "Stabilna kariera",
        "Wysokie zaanga≈ºowanie spo≈Çeczne"
      ],
      "graph_insights": [
        {{
          "type": "Wskaznik",
          "summary": "Stopa zatrudnienia kobiet 25-34 z wy≈ºszym",
          "magnitude": "78.4%",
          "confidence": "high",
          "time_period": "2022",
          "source": "GUS",
          "why_matters": "Wysoka stopa zatrudnienia oznacza ≈ºe ta grupa ma..."
        }}
      ],
      "allocation_reasoning": "Dlaczego 6 z {num_personas}? Bo ta grupa stanowi..."
    }}
  ]
}}
```

KLUCZOWE ZASADY:

1. **Briefe majƒÖ byƒá KONKRETNE** (900-1200 znak√≥w ka≈ºdy) - mini-eseje, nie listy
2. **Wyja≈õniaj "dlaczego"** dla WSZYSTKIEGO - user ma siƒô uczyƒá
3. **Konwersacyjny ton** - jak kolega t≈Çumaczy przy kawie, nie jak raport naukowy
4. **U≈ºywaj danych z Graph RAG** - magnitude, confidence, time_period, sources
5. **Production-ready** - ten output idzie bezpo≈õrednio do u≈ºytkownik√≥w
6. **Realne liczby** - PLN, %, lata, konkretne wska≈∫niki (nie "wysoki" ale "78.4%")
7. **Kontekst spo≈Çeczny** - wyja≈õniaj T≈ÅO (historia, ekonomia, trendy)

Generuj plan alokacji:
"""
        return prompt

    def _extract_json_from_response(self, response_text: str) -> dict[str, Any]:
        """Ekstraktuje JSON z odpowiedzi LLM (mo≈ºe byƒá otoczony markdown lub preambu≈ÇƒÖ).

        Pr√≥buje 4 strategii parsowania w kolejno≈õci:
        1. ```json ... ``` blok markdown
        2. ``` ... ``` blok kodu bez typu
        3. Pierwszy { ... } (mo≈ºe byƒá po preambule)
        4. Ca≈Çy tekst (fallback)

        Args:
            response_text: Surowa odpowied≈∫ od LLM

        Returns:
            Parsed JSON jako dict

        Raises:
            ValueError: Je≈õli ≈ºadna strategia nie zadzia≈Ça
        """
        text = response_text.strip()
        import re

        # Strategia 1: Znajd≈∫ blok ```json ... ``` (may be embedded in text)
        logger.debug("Trying strategy 1: ```json ... ``` block")
        json_block_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
        if json_block_match:
            json_text = json_block_match.group(1).strip()
            logger.debug(f"Found ```json block, length: {len(json_text)} chars")
            logger.debug(f"JSON preview: {json_text[:200]}...")

            try:
                parsed = json.loads(json_text)
                logger.info("‚úÖ JSON parsed successfully via strategy 1 (```json block)")
                return parsed
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è  Strategy 1 failed: {e}")
                logger.warning(f"   At position: line {e.lineno}, col {e.colno}")
                if e.pos < len(json_text):
                    error_snippet = json_text[max(0, e.pos-50):min(len(json_text), e.pos+50)]
                    logger.warning(f"   Error context: ...{error_snippet}...")
                # Kontynuuj do nastƒôpnej strategii

        # Strategia 2: Znajd≈∫ blok ``` ... ``` (without json marker)
        logger.debug("Trying strategy 2: ``` ... ``` code block")
        code_block_match = re.search(r'```\s*(.*?)\s*```', text, re.DOTALL)
        if code_block_match:
            json_text = code_block_match.group(1).strip()
            logger.debug(f"Found code block, length: {len(json_text)} chars")

            try:
                parsed = json.loads(json_text)
                logger.info("‚úÖ JSON parsed successfully via strategy 2 (code block)")
                return parsed
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è  Strategy 2 failed: {e}")
                logger.warning(f"   At position: line {e.lineno}, col {e.colno}")
                # Kontynuuj do nastƒôpnej strategii

        # Strategia 3: Znajd≈∫ pierwszy { ... } (after potential preamble)
        logger.debug("Trying strategy 3: First { ... } braces")
        brace_match = re.search(r'\{.*\}', text, re.DOTALL)
        if brace_match:
            json_text = brace_match.group(0).strip()
            logger.debug(f"Found braces block, length: {len(json_text)} chars")
            logger.debug(f"JSON preview: {json_text[:200]}...")

            try:
                parsed = json.loads(json_text)
                logger.info("‚úÖ JSON parsed successfully via strategy 3 (braces)")
                return parsed
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è  Strategy 3 failed: {e}")
                logger.warning(f"   At position: line {e.lineno}, col {e.colno}")
                if e.pos < len(json_text):
                    error_snippet = json_text[max(0, e.pos-50):min(len(json_text), e.pos+50)]
                    logger.warning(f"   Error context: ...{error_snippet}...")
                # Kontynuuj do nastƒôpnej strategii

        # Strategia 4: Spr√≥buj sparsowaƒá ca≈Çy tekst (fallback)
        logger.debug("Trying strategy 4: Full text parsing")
        try:
            parsed = json.loads(text)
            logger.info("‚úÖ JSON parsed successfully via strategy 4 (full text)")
            return parsed
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå ALL 4 STRATEGIES FAILED")
            logger.error(f"‚ùå Final error: {e}")
            logger.error(f"‚ùå At position: line {e.lineno}, col {e.colno}")
            logger.error(f"‚ùå Response text length: {len(text)} chars")
            logger.error(f"‚ùå Response text (first 1000 chars): {text[:1000]}")
            logger.error(f"‚ùå Response text (last 1000 chars): {text[-1000:]}")
            raise ValueError(f"LLM nie zwr√≥ci≈Ç poprawnego JSON: {e}")

    # === NEW METHODS FOR SEGMENT-BASED ARCHITECTURE ===

    async def _generate_segment_name(
        self,
        demographics: dict[str, Any],
        graph_insights: list[GraphInsight],
        rag_citations: list[Any]
    ) -> str:
        """Generuje m√≥wiƒÖcƒÖ nazwƒô segmentu u≈ºywajƒÖc Gemini 2.5 Flash.

        Nazwa powinna byƒá kr√≥tka (2-4 s≈Çowa), m√≥wiƒÖca i odzwierciedlaƒá
        kluczowe cechy grupy demograficznej bazujƒÖc na insightach.

        Args:
            demographics: Cechy demograficzne (age, gender, education, income)
            graph_insights: Graph insights dla tej grupy
            rag_citations: RAG citations dla kontekstu

        Returns:
            Nazwa segmentu (np. "M≈Çodzi Prekariusze", "AspirujƒÖce Profesjonalistki 35-44")

        Raises:
            ValueError: Je≈õli LLM nie zwr√≥ci poprawnej nazwy
        """
        # Extract key demographics
        age_range = demographics.get('age', demographics.get('age_group', 'nieznany'))
        gender = demographics.get('gender', 'nieznana')
        education = demographics.get('education', demographics.get('education_level', 'nieznane'))
        income = demographics.get('income', demographics.get('income_bracket', 'nieznany'))

        # Format insights
        insights_text = "\n".join([
            f"- {ins.summary} ({ins.confidence})"
            for ins in graph_insights[:3]  # Top 3
        ]) if graph_insights else "Brak insights"

        # Format citations (first 2 max)
        citations_text = "\n".join([
            f"- {cit.page_content[:100]}..."
            for cit in rag_citations[:2]
        ]) if hasattr(rag_citations[0] if rag_citations else None, 'page_content') else "Brak cytat√≥w"

        prompt = f"""Stw√≥rz trafnƒÖ, M√ìWIƒÑCƒÑ nazwƒô dla poni≈ºszego segmentu demograficznego.

DANE SEGMENTU:
- Wiek: {age_range}
- P≈Çeƒá: {gender}
- Wykszta≈Çcenie: {education}
- Doch√≥d: {income}

INSIGHTS Z GRAFU:
{insights_text}

CYTATY Z RAG:
{citations_text}

ZASADY:
1. Nazwa powinna byƒá 2-4 s≈Çowa (np. "M≈Çodzi Prekariusze", "AspirujƒÖce Profesjonalistki 35-44")
2. Oddaje kluczowƒÖ charakterystykƒô grupy (wiek + status spo≈Çeczno-ekonomiczny)
3. U≈ºywa polskiego jƒôzyka, brzmi naturalnie
4. Bazuje na insightach (np. je≈õli grupa ma niskie dochody + m≈Çody wiek ‚Üí "M≈Çodzi Prekariusze")
5. Unikaj og√≥lnik√≥w ("Grupa A", "Segment 1")
6. Je≈õli wiek jest istotny, w≈ÇƒÖcz go (np. "35-44")

PRZYK≈ÅADY DOBRYCH NAZW:
- "M≈Çodzi Prekariusze" (18-24, niskie dochody)
- "AspirujƒÖce Profesjonalistki 35-44" (kobiety, wy≈ºsze wykszta≈Çcenie, ≈õrednie dochody)
- "Dojrzali Eksperci" (45-54, wysokie dochody, stabilna kariera)
- "PoczƒÖtkujƒÖcy Profesjonali≈õci" (25-34, pierwsze kroki w karierze)

ZWR√ìƒÜ TYLKO NAZWƒò (bez cudzys≈Çow√≥w, bez dodatkowych wyja≈õnie≈Ñ):"""

        try:
            # Use Gemini Flash for quick naming (cheap, fast)
            llm_flash = build_chat_model(
                model=settings.DEFAULT_MODEL,
                temperature=0.7,
                max_tokens=50,
                timeout=10,
            )

            response = await llm_flash.ainvoke(prompt)
            segment_name = response.content.strip() if hasattr(response, 'content') else str(response).strip()

            # Clean up (remove quotes if present)
            segment_name = segment_name.strip('"\'')

            # Validation: nazwa powinna mieƒá 5-60 znak√≥w
            if len(segment_name) < 5 or len(segment_name) > 60:
                logger.warning(f"Generated segment name too short/long: '{segment_name}', using fallback")
                # Fallback: template name
                segment_name = f"Segment {age_range}, {gender}"

            logger.info(f"‚úÖ Generated segment name: '{segment_name}'")
            return segment_name

        except Exception as e:
            logger.error(f"‚ùå Failed to generate segment name: {e}")
            # Fallback: template name
            fallback_name = f"Segment {age_range}, {gender}"
            logger.warning(f"Using fallback segment name: '{fallback_name}'")
            return fallback_name

    async def _generate_segment_context(
        self,
        segment_name: str,
        demographics: dict[str, Any],
        graph_insights: list[GraphInsight],
        rag_citations: list[Any],
        project_goal: str | None = None
    ) -> str:
        """Generuje kontekst spo≈Çeczny dla segmentu u≈ºywajƒÖc Gemini 2.5 Pro.

        Kontekst powinien byƒá 500-800 znak√≥w, edukacyjny i specyficzny dla TEJ grupy.

        Args:
            segment_name: Nazwa segmentu
            demographics: Cechy demograficzne
            graph_insights: Graph insights dla tej grupy
            rag_citations: RAG citations dla kontekstu
            project_goal: Cel projektu (opcjonalny)

        Returns:
            Kontekst spo≈Çeczny (500-800 znak√≥w)

        Raises:
            ValueError: Je≈õli LLM nie zwr√≥ci poprawnego kontekstu
        """
        # Extract key demographics
        age_range = demographics.get('age', demographics.get('age_group', 'nieznany'))
        gender = demographics.get('gender', 'nieznana')
        education = demographics.get('education', demographics.get('education_level', 'nieznane'))
        income = demographics.get('income', demographics.get('income_bracket', 'nieznany'))

        # Format insights with details
        insights_text = "\n".join([
            f"- **{ins.summary}**\n  Magnitude: {ins.magnitude or 'N/A'}, Confidence: {ins.confidence}, "
            f"Source: {ins.source or 'N/A'}, Year: {ins.time_period or 'N/A'}\n  "
            f"Why it matters: {ins.why_matters[:150]}..."
            for ins in graph_insights[:5]  # Top 5
        ]) if graph_insights else "Brak insights"

        # Format citations (first 3 max)
        citations_text = "\n".join([
            f"[{idx+1}] {cit.page_content[:200]}..."
            for idx, cit in enumerate(rag_citations[:3])
        ]) if hasattr(rag_citations[0] if rag_citations else None, 'page_content') else "Brak cytat√≥w"

        prompt = f"""Stw√≥rz kontekst spo≈Çeczny dla segmentu "{segment_name}".

DEMOGRAFIA SEGMENTU:
- Wiek: {age_range}
- P≈Çeƒá: {gender}
- Wykszta≈Çcenie: {education}
- Doch√≥d: {income}

INSIGHTS Z GRAFU WIEDZY:
{insights_text}

CYTATY Z RAG:
{citations_text}

CEL PROJEKTU:
{project_goal or "Badanie syntetycznych person"}

WYTYCZNE:
1. D≈Çugo≈õƒá: 500-800 znak√≥w (WA≈ªNE!)
2. Kontekst SPECYFICZNY dla KONKRETNEJ GRUPY (nie og√≥lny opis Polski!)
3. Zacznij od opisu charakterystyki grupy (jak w przyk≈Çadzie)
4. Struktura:
   a) Pierwsza czƒô≈õƒá (2-3 zdania): KIM sƒÖ te osoby, co ich charakteryzuje
   b) Druga czƒô≈õƒá (2-3 zdania): Ich WARTO≈öCI i ASPIRACJE
   c) Trzecia czƒô≈õƒá (2-3 zdania): WYZWANIA i kontekst ekonomiczny z konkretnymi liczbami
5. Ton: konkretny, praktyczny, opisujƒÖcy TYCH ludzi (nie teoretyczny!)
6. U≈ºywaj konkretnych liczb z insights tam gdzie dostƒôpne
7. Unikaj: og√≥lnik√≥w ("polska spo≈Çecze≈Ñstwo"), teoretyzowania

PRZYK≈ÅAD DOBREGO KONTEKSTU (na wz√≥r Figmy):
"Tech-Savvy Profesjonali≈õci to osoby w wieku 28 lat, pracujƒÖce jako Marketing Manager w du≈ºych miastach jak Warszawa czy Krak√≥w. CharakteryzujƒÖ siƒô wysokim wykszta≈Çceniem (licencjat lub wy≈ºej), stabilnƒÖ karierƒÖ w bran≈ºy technologicznej i dochodami 8k-12k PLN netto. SƒÖ early adopters nowych technologii i ceniƒÖ sobie work-life balance. Ich g≈Ç√≥wne warto≈õci to innovation, ciƒÖg≈Çy rozw√≥j i sustainability. AspirujƒÖ do awansu na wy≈ºsze stanowiska (senior manager, director), w≈Çasnego mieszkania w atrakcyjnej lokalizacji (co przy cenach 15-20k PLN/m2 wymaga oszczƒôdzania przez 10+ lat) i rozwoju kompetencji w digital marketing oraz AI tools. Wyzwania: rosnƒÖca konkurencja na rynku pracy (wed≈Çug GUS 78% os√≥b z tej grupy ma wy≈ºsze wykszta≈Çcenie), wysokie koszty ≈ºycia w du≈ºych miastach (≈õredni czynsz ~3500 PLN), presja na ciƒÖg≈Çy rozw√≥j i keeping up with tech trends."

WA≈ªNE: Pisz o KONKRETNEJ grupie ludzi, u≈ºywaj przyk≈Çad√≥w zawod√≥w, konkretnych liczb, opisuj ICH ≈ºycie.

ZWR√ìƒÜ TYLKO KONTEKST (bez nag≈Ç√≥wk√≥w, bez komentarzy, 500-800 znak√≥w):"""

        try:
            response = await self.llm.ainvoke(prompt)  # Use Gemini 2.5 Pro
            segment_context = response.content.strip() if hasattr(response, 'content') else str(response).strip()

            # Validation: kontekst powinien mieƒá 400-1200 znak√≥w
            if len(segment_context) < 400 or len(segment_context) > 1200:
                logger.warning(
                    f"Generated segment context length ({len(segment_context)}) outside range 400-1200, "
                    "but accepting anyway"
                )

            logger.info(f"‚úÖ Generated segment context: {len(segment_context)} chars")
            return segment_context

        except Exception as e:
            logger.error(f"‚ùå Failed to generate segment context: {e}")
            # Fallback: minimal context
            fallback_context = (
                f"Segment '{segment_name}' obejmuje osoby w wieku {age_range}, {gender}, "
                f"z wykszta≈Çceniem {education} i dochodami {income}. "
                f"Ta grupa stanowi istotnƒÖ czƒô≈õƒá polskiego spo≈Çecze≈Ñstwa i wymaga szczeg√≥lnej uwagi "
                f"w kontek≈õcie bada≈Ñ rynkowych."
            )
            logger.warning(f"Using fallback segment context: {len(fallback_context)} chars")
            return fallback_context

    def _filter_graph_insights_for_segment(
        self,
        insights: list[GraphInsight],
        demographics: dict[str, Any]
    ) -> list[GraphInsight]:
        """Filtruje graph insights dla konkretnego segmentu demograficznego.

        Zwraca tylko insights relevantne dla tego segmentu (np. insights o m≈Çodych
        dla segmentu 18-24).

        Args:
            insights: Wszystkie graph insights
            demographics: Demografia segmentu

        Returns:
            Filtrowana lista insights (max 10)
        """
        if not insights:
            return []

        # Extract age range for filtering
        age_str = demographics.get('age', demographics.get('age_group', ''))

        filtered = []
        for insight in insights:
            # Filter by age relevance (check if age range mentioned in summary)
            age_relevant = True
            if age_str:
                # Simple heuristic: if insight mentions age, check if it's relevant
                summary_lower = insight.summary.lower()
                if any(age_term in summary_lower for age_term in ['wiek', 'lat', 'young', 'old', 'm≈Çod', 'star']):
                    # Check if age range overlaps (simplified)
                    age_relevant = age_str.lower() in summary_lower or not any(
                        other_age in summary_lower
                        for other_age in ['18-24', '25-34', '35-44', '45-54', '55+']
                        if other_age != age_str
                    )

            if age_relevant:
                filtered.append(insight)

        # Sort by confidence (high first) and return top 10
        confidence_order = {'high': 3, 'medium': 2, 'low': 1}
        filtered.sort(key=lambda x: confidence_order.get(x.confidence, 0), reverse=True)

        return filtered[:10]

    def _filter_rag_citations(
        self,
        citations: list[Any],
        min_confidence: float = 0.7
    ) -> list[Any]:
        """Filtruje RAG citations - tylko high-quality (confidence > threshold).

        Args:
            citations: Lista RAG citations (Document objects)
            min_confidence: Minimalny confidence score (default 0.7)

        Returns:
            Filtrowana lista citations (max 10)
        """
        if not citations:
            return []

        filtered = []
        for cit in citations:
            # Check if citation has confidence score in metadata
            confidence = 1.0  # Default if not available
            if hasattr(cit, 'metadata') and cit.metadata:
                confidence = cit.metadata.get('confidence', cit.metadata.get('score', 1.0))

            # Filter by confidence
            if confidence >= min_confidence:
                filtered.append(cit)

        # Return top 10
        return filtered[:10]
