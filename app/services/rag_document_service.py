"""Serwis zarzÄ…dzajÄ…cy dokumentami RAG - wczytywanie, chunking, vector store.

Ten moduÅ‚ odpowiada za podstawowÄ… infrastrukturÄ™ przetwarzania dokumentÃ³w:
- Wczytywanie PDF/DOCX
- Dzielenie na chunki
- Generowanie embeddingÃ³w
- Zapis do Neo4j Vector Store
- ZarzÄ…dzanie dokumentami (lista, usuwanie)

Graph RAG funkcjonalnoÅ›Ä‡ znajduje siÄ™ w rag_graph_service.py
"""

from __future__ import annotations

import asyncio
import logging
from pathlib import Path
from typing import Any, Dict, List, Tuple
from uuid import UUID

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from langchain_community.document_loaders import Docx2txtLoader, PyPDFLoader
from langchain_community.graphs import Neo4jGraph
from langchain_community.vectorstores import Neo4jVector
from langchain_core.documents import Document
from langchain_experimental.graph_transformers.llm import LLMGraphTransformer
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

from app.core.config import get_settings
from app.models.rag_document import RAGDocument

settings = get_settings()
logger = logging.getLogger(__name__)


class RAGDocumentService:
    """Serwis zarzÄ…dzajÄ…cy dokumentami, indeksem wektorowym.

    Zakres odpowiedzialnoÅ›ci:

    1. Wczytywanie dokumentÃ³w PDF/DOCX i dzielenie ich na fragmenty.
    2. Generowanie embeddingÃ³w i zapis chunkÃ³w w indeksie wektorowym Neo4j.
    3. ZarzÄ…dzanie dokumentami w bazie PostgreSQL (lista, usuwanie z czyszczeniem
       danych w Neo4j).

    Uwaga: Budowa grafu wiedzy i Graph RAG znajdujÄ… siÄ™ w GraphRAGService.
    """

    def __init__(self) -> None:
        """Inicjalizuje wszystkie niezbÄ™dne komponenty LangChain i Neo4j."""

        self.settings = settings

        # Model konwersacyjny wykorzystywany zarÃ³wno do budowy grafu, jak i
        # generowania finalnych odpowiedzi Graph RAG.
        self.llm = ChatGoogleGenerativeAI(
            model=settings.GRAPH_MODEL,
            google_api_key=self.settings.GOOGLE_API_KEY,
            temperature=0,
        )

        # Embeddingi Google Gemini wykorzystywane przez indeks wektorowy Neo4j.
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model=settings.EMBEDDING_MODEL,
            google_api_key=settings.GOOGLE_API_KEY,
        )

        # Inicjalizacja Neo4j Vector Store z retry logic (dla Docker startup race condition)
        self.vector_store = self._init_vector_store_with_retry()

        # Inicjalizacja Neo4j Graph Store z retry logic
        self.graph_store = self._init_graph_store_with_retry()

    def _init_vector_store_with_retry(self, max_retries: int = 10, initial_delay: float = 1.0):
        """Inicjalizuje Neo4j Vector Store z retry logic (dla Docker startup).

        Neo4j w Dockerze potrzebuje 10-15s na start (plugins: APOC, GDS).
        Retry z exponential backoff zapobiega race condition przy startup.

        Args:
            max_retries: Maksymalna liczba prÃ³b (default: 10 = ~30s total)
            initial_delay: PoczÄ…tkowe opÃ³Åºnienie w sekundach (default: 1.0s)

        Returns:
            Neo4jVector instance lub None jeÅ›li wszystkie prÃ³by failed
        """
        import time

        logger.info("ðŸ”„ Inicjalizacja Neo4j Vector Store (z retry logic)")
        logger.info("   URL: %s, User: %s", settings.NEO4J_URI, settings.NEO4J_USER)

        delay = initial_delay
        for attempt in range(1, max_retries + 1):
            try:
                vector_store = Neo4jVector(
                    url=settings.NEO4J_URI,
                    username=settings.NEO4J_USER,
                    password=settings.NEO4J_PASSWORD,
                    embedding=self.embeddings,
                    index_name="rag_document_embeddings",
                    node_label="RAGChunk",
                    text_node_property="text",
                    embedding_node_property="embedding",
                )
                logger.info("âœ… Neo4j Vector Store poÅ‚Ä…czony (prÃ³ba %d/%d)", attempt, max_retries)
                return vector_store

            except Exception as exc:
                if attempt < max_retries:
                    logger.warning(
                        "âš ï¸  Neo4j Vector Store - prÃ³ba %d/%d failed: %s. Retry za %.1fs...",
                        attempt, max_retries, str(exc)[:100], delay
                    )
                    time.sleep(delay)
                    delay = min(delay * 1.5, 10.0)  # Exponential backoff (cap at 10s)
                else:
                    logger.error(
                        "âŒ Neo4j Vector Store - wszystkie %d prÃ³b failed. RAG wyÅ‚Ä…czony.",
                        max_retries,
                        exc_info=True
                    )
                    return None

        return None

    def _init_graph_store_with_retry(self, max_retries: int = 10, initial_delay: float = 1.0):
        """Inicjalizuje Neo4j Graph Store z retry logic (dla Docker startup).

        Args:
            max_retries: Maksymalna liczba prÃ³b (default: 10 = ~30s total)
            initial_delay: PoczÄ…tkowe opÃ³Åºnienie w sekundach (default: 1.0s)

        Returns:
            Neo4jGraph instance lub None jeÅ›li wszystkie prÃ³by failed
        """
        import time

        logger.info("ðŸ”„ Inicjalizacja Neo4j Graph Store (z retry logic)")

        delay = initial_delay
        for attempt in range(1, max_retries + 1):
            try:
                graph_store = Neo4jGraph(
                    url=settings.NEO4J_URI,
                    username=settings.NEO4J_USER,
                    password=settings.NEO4J_PASSWORD,
                )
                logger.info("âœ… Neo4j Graph Store poÅ‚Ä…czony (prÃ³ba %d/%d)", attempt, max_retries)
                return graph_store

            except Exception as exc:
                if attempt < max_retries:
                    logger.warning(
                        "âš ï¸  Neo4j Graph Store - prÃ³ba %d/%d failed: %s. Retry za %.1fs...",
                        attempt, max_retries, str(exc)[:100], delay
                    )
                    time.sleep(delay)
                    delay = min(delay * 1.5, 10.0)  # Exponential backoff (cap at 10s)
                else:
                    logger.error(
                        "âŒ Neo4j Graph Store - wszystkie %d prÃ³b failed. GraphRAG wyÅ‚Ä…czony.",
                        max_retries,
                        exc_info=True
                    )
                    return None

        return None

    async def ingest_document(self, file_path: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Przetwarza dokument przez peÅ‚ny pipeline: load â†’ chunk â†’ graph â†’ vector.

        Args:
            file_path: ÅšcieÅ¼ka do pliku PDF lub DOCX zapisanej kopii dokumentu.
            metadata: Metadane dokumentu (doc_id, title, country, itp.).

        Returns:
            SÅ‚ownik zawierajÄ…cy liczbÄ™ chunkÃ³w oraz status zakoÅ„czenia procesu.

        Raises:
            RuntimeError: Gdy brakuje poÅ‚Ä…czenia z Neo4j (vector store jest kluczowy).
            FileNotFoundError: JeÅ›li plik nie istnieje.
            ValueError: Przy nieobsÅ‚ugiwanym rozszerzeniu lub braku treÅ›ci.
        """

        if not self.vector_store:
            raise RuntimeError("Brak poÅ‚Ä…czenia z Neo4j Vector Store â€“ ingest niemoÅ¼liwy.")

        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"Nie znaleziono pliku: {file_path}")

        logger.info("Rozpoczynam przetwarzanie dokumentu: %s", path.name)

        try:
            # 1. LOAD â€“ wybÃ³r loadera zaleÅ¼nie od rozszerzenia pliku.
            file_extension = path.suffix.lower()
            if file_extension == ".pdf":
                loader = PyPDFLoader(str(path))
                logger.info("UÅ¼ywam PyPDFLoader dla pliku %s", path.name)
            elif file_extension == ".docx":
                loader = Docx2txtLoader(str(path))
                logger.info("UÅ¼ywam Docx2txtLoader dla pliku %s", path.name)
            else:
                raise ValueError(
                    f"NieobsÅ‚ugiwany typ pliku: {file_extension}. Dozwolone: PDF, DOCX."
                )

            documents = await asyncio.to_thread(loader.load)
            if not documents:
                raise ValueError("Nie udaÅ‚o siÄ™ odczytaÄ‡ zawartoÅ›ci dokumentu.")
            logger.info("Wczytano %s segmentÃ³w dokumentu ÅºrÃ³dÅ‚owego.", len(documents))

            # 2. SPLIT â€“ dzielenie tekstu na fragmenty z kontrolowanym overlapem.
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=settings.RAG_CHUNK_SIZE,
                chunk_overlap=settings.RAG_CHUNK_OVERLAP,
                separators=["\n\n", "\n", ". ", " ", ""],
                length_function=len,
            )
            chunks = text_splitter.split_documents(documents)
            if not chunks:
                raise ValueError("Nie wygenerowano Å¼adnych fragmentÃ³w tekstu.")
            logger.info(
                "Podzielono dokument na %s fragmentÃ³w (chunk_size=%s, overlap=%s)",
                len(chunks),
                settings.RAG_CHUNK_SIZE,
                settings.RAG_CHUNK_OVERLAP,
            )

            # 3. METADATA â€“ wzbogacenie kaÅ¼dego chunku o metadane identyfikujÄ…ce.
            doc_id = metadata.get("doc_id")
            for index, chunk in enumerate(chunks):
                chunk.metadata.update(
                    {
                        "doc_id": str(doc_id),
                        "chunk_index": index,
                        "title": metadata.get("title", "Nieznany dokument"),
                        "country": metadata.get("country", "Poland"),
                        "source_file": path.name,
                    }
                )

            # 4. GRAPH â€“ prÃ³bujemy zbudowaÄ‡ graf wiedzy, jeÅ›li Neo4j Graph jest dostÄ™pny.
            if self.graph_store:
                try:
                    logger.info("GenerujÄ™ strukturÄ™ grafowÄ… na podstawie uniwersalnego modelu.")
                    transformer = LLMGraphTransformer(
                        llm=self.llm,
                        allowed_nodes=[
                            "Obserwacja",   # Fakty, obserwacje (merge Przyczyna, Skutek tutaj)
                            "Wskaznik",     # WskaÅºniki liczbowe, statystyki
                            "Demografia",   # Grupy demograficzne
                            "Trend",        # Trendy czasowe, zmiany w czasie
                            "Lokalizacja",  # Miejsca geograficzne
                        ],
                        allowed_relationships=[
                            "OPISUJE",           # Opisuje cechÄ™/wÅ‚aÅ›ciwoÅ›Ä‡
                            "DOTYCZY",           # Dotyczy grupy/kategorii
                            "POKAZUJE_TREND",    # Pokazuje trend czasowy
                            "ZLOKALIZOWANY_W",   # Zlokalizowane w miejscu
                            "POWIAZANY_Z",       # OgÃ³lne powiÄ…zanie (merge: przyczynowoÅ›Ä‡, porÃ³wnania)
                        ],
                        node_properties=[
                            "streszczenie",     # MUST: Jednozdaniowe podsumowanie (max 150 znakÃ³w)
                            "skala",            # WielkoÅ›Ä‡/wartoÅ›Ä‡ z jednostkÄ… (np. "67%", "1.2 mln")
                            "pewnosc",          # MUST: PewnoÅ›Ä‡: "wysoka", "srednia", "niska"
                            "okres_czasu",      # Okres czasu (YYYY lub YYYY-YYYY)
                            "kluczowe_fakty",   # Opcjonalnie: max 3 fakty (separated by semicolons)
                        ],
                        relationship_properties=[
                            "sila",  # SiÅ‚a relacji: "silna", "umiarkowana", "slaba"
                        ],
                        additional_instructions="""
JÄ˜ZYK: Wszystkie nazwy i wartoÅ›ci MUSZÄ„ byÄ‡ PO POLSKU.

KRYTYCZNE OGRANICZENIA ILOÅšCIOWE:
- MAX 3 WÄ˜ZÅY na chunk (tylko najwaÅ¼niejsze!)
- MAX 5 RELACJI na chunk
- Tylko pewnosc "wysoka" lub "srednia" (NIGDY "niska")
- JeÅ›li chunk nie zawiera WAÅ»NYCH informacji â†’ 0 wÄ™zÅ‚Ã³w (to OK!)

=== TYPY WÄ˜ZÅÃ“W (5) ===
- Obserwacja: Fakty, obserwacje spoÅ‚eczne (wÅ‚Ä…cznie z przyczynami i skutkami)
- Wskaznik: WskaÅºniki liczbowe, statystyki (np. stopa zatrudnienia)
- Demografia: Grupy demograficzne (np. mÅ‚odzi doroÅ›li)
- Trend: Trendy czasowe, zmiany w czasie
- Lokalizacja: Miejsca geograficzne

=== TYPY RELACJI (5) ===
- OPISUJE: Opisuje cechÄ™/wÅ‚aÅ›ciwoÅ›Ä‡
- DOTYCZY: Dotyczy grupy/kategorii
- POKAZUJE_TREND: Pokazuje trend czasowy
- ZLOKALIZOWANY_W: Zlokalizowane w miejscu
- POWIAZANY_Z: OgÃ³lne powiÄ…zanie (przyczynowoÅ›Ä‡, porÃ³wnania, korelacje)

=== PROPERTIES WÄ˜ZÅÃ“W (5 - uproszczone!) ===
- streszczenie (MUST): 1 zdanie, max 150 znakÃ³w
- skala: WartoÅ›Ä‡ z jednostkÄ… (np. "78.4%", "5000 PLN", "1.2 mln osÃ³b")
- pewnosc (MUST): TYLKO "wysoka" lub "srednia" (NIGDY "niska")
- okres_czasu: YYYY lub YYYY-YYYY
- kluczowe_fakty: Max 3 fakty oddzielone Å›rednikami

=== PROPERTIES RELACJI (1) ===
- sila: "silna" / "umiarkowana" / "slaba"

=== PRZYKÅADY (FEW-SHOT) ===

PRZYKÅAD 1 - Wskaznik:
Tekst: "W 2022 stopa zatrudnienia kobiet 25-34 z wyÅ¼szym wynosiÅ‚a 78.4% wedÅ‚ug GUS"
WÄ™zeÅ‚: {{
  type: "Wskaznik",
  streszczenie: "Stopa zatrudnienia kobiet 25-34 z wyÅ¼szym wyksztaÅ‚ceniem",
  skala: "78.4%",
  pewnosc: "wysoka",
  okres_czasu: "2022",
  kluczowe_fakty: "wysoka stopa zatrudnienia; kobiety mÅ‚ode; wyksztaÅ‚cenie wyÅ¼sze"
}}

PRZYKÅAD 2 - Obserwacja:
Tekst: "MÅ‚odzi mieszkaÅ„cy duÅ¼ych miast coraz czÄ™Å›ciej wynajmujÄ… mieszkania zamiast kupowaÄ‡"
WÄ™zeÅ‚: {{
  type: "Obserwacja",
  streszczenie: "MÅ‚odzi w miastach preferujÄ… wynajem nad zakup mieszkaÅ„",
  pewnosc: "srednia",
  kluczowe_fakty: "mÅ‚odzi doroÅ›li; duÅ¼e miasta; wynajem mieszkaÅ„"
}}

PRZYKÅAD 3 - Trend:
Tekst: "Od 2018 do 2023 wzrÃ³sÅ‚ odsetek osÃ³b pracujÄ…cych zdalnie z 12% do 31%"
WÄ™zeÅ‚: {{
  type: "Trend",
  streszczenie: "Wzrost pracy zdalnej w Polsce",
  skala: "12% â†’ 31%",
  pewnosc: "wysoka",
  okres_czasu: "2018-2023",
  kluczowe_fakty: "praca zdalna; wzrost; pandemia"
}}

=== DEDUPLIKACJA (KRYTYCZNE!) ===
Przed utworzeniem wÄ™zÅ‚a sprawdÅº czy podobny juÅ¼ istnieje:
- "Stopa zatrudnienia kobiet 25-34" â‰ˆ "Zatrudnienie mÅ‚odych kobiet" â†’ MERGE
- UÅ¼ywaj POWIAZANY_Z aby Å‚Ä…czyÄ‡ podobne koncepty zamiast tworzyÄ‡ duplikaty
- Priorytet: 1 PRECYZYJNY wÄ™zeÅ‚ > 3 podobne wÄ™zÅ‚y

=== CONFIDENCE FILTERING (KRYTYCZNE!) ===
- TYLKO pewnosc "wysoka" lub "srednia"
- JeÅ›li informacja jest niepewna/nieweryfikowalna â†’ NIE TWÃ“RZ wÄ™zÅ‚a
- Priorytet: 1 PEWNY wÄ™zeÅ‚ > 5 niepewnych wÄ™zÅ‚Ã³w

=== VALIDATION RULES ===
- streszczenie: Zawsze wypeÅ‚nij (1 zdanie, max 150 znakÃ³w)
- pewnosc: Zawsze wypeÅ‚nij (TYLKO "wysoka" lub "srednia" - jeÅ›li niska â†’ nie twÃ³rz wÄ™zÅ‚a!)
- skala: Tylko dla Wskaznik (inne: opcjonalnie)
- kluczowe_fakty: Max 3 fakty, separated by semicolons
- doc_id, chunk_index: KRYTYCZNE dla lifecycle (zachowane automatycznie)

=== FOCUS ===
Priorytet: JAKOÅšÄ† > iloÅ›Ä‡. MAX 3 wÄ™zÅ‚y, TYLKO pewne informacje. Mniej = lepiej.
                        """.strip(),
                    )
                    graph_documents = await transformer.aconvert_to_graph_documents(chunks)

                    # Wzbogacenie wÄ™zÅ‚Ã³w o metadane dokumentu
                    # Uwaga: _enrich_graph_nodes jest teraz w GraphRAGService
                    # Ale dla document ingest uÅ¼ywamy lokalnej metody
                    from app.services.rag_graph_service import GraphRAGService
                    graph_service = GraphRAGService()
                    enriched_graph_documents = graph_service._enrich_graph_nodes(
                        graph_documents,
                        doc_id=str(doc_id),
                        metadata=metadata
                    )

                    self.graph_store.add_graph_documents(enriched_graph_documents, include_source=True)
                    logger.info("Zapisano strukturÄ™ grafowÄ… dla dokumentu %s", doc_id)
                except Exception as graph_exc:  # pragma: no cover - logujemy, ale nie przerywamy
                    logger.error(
                        "Nie udaÅ‚o siÄ™ wygenerowaÄ‡ grafu wiedzy dla dokumentu %s: %s",
                        doc_id,
                        graph_exc,
                        exc_info=True,
                    )

            else:
                logger.warning(
                    "Neo4j Graph Store nie jest dostÄ™pny â€“ dokument zostanie przetworzony "
                    "bez struktury grafowej."
                )

            # 5. VECTOR â€“ zapis chunkÃ³w do indeksu wektorowego w Neo4j.
            logger.info("GenerujÄ™ embeddingi i zapisujÄ™ je w indeksie wektorowym...")
            await self.vector_store.aadd_documents(chunks)
            logger.info(
                "ZakoÅ„czono przetwarzanie %s fragmentÃ³w dokumentu %s",
                len(chunks),
                doc_id,
            )

            return {"num_chunks": len(chunks), "status": "ready"}

        except Exception as exc:  # pragma: no cover - logujemy peÅ‚nÄ… diagnostykÄ™
            logger.error(
                "BÅ‚Ä…d podczas przetwarzania dokumentu %s: %s",
                file_path,
                exc,
                exc_info=True,
            )
            return {"num_chunks": 0, "status": "failed", "error": str(exc)}

    async def list_documents(self, db: AsyncSession) -> List[RAGDocument]:
        """Zwraca listÄ™ aktywnych dokumentÃ³w posortowanych malejÄ…co po dacie."""

        result = await db.execute(
            select(RAGDocument)
            .where(RAGDocument.is_active.is_(True))
            .order_by(RAGDocument.created_at.desc())
        )
        return result.scalars().all()

    async def delete_document(self, doc_id: UUID, db: AsyncSession) -> None:
        """Usuwa dokument z PostgreSQL i czyÅ›ci powiÄ…zane dane w Neo4j."""

        doc = await db.get(RAGDocument, doc_id)
        if not doc:
            raise ValueError(f"Document {doc_id} not found")

        doc.is_active = False
        await db.commit()

        await self._delete_chunks_from_neo4j(str(doc_id))

        if self.graph_store:
            try:
                self.graph_store.query(
                    "MATCH (n {doc_id: $doc_id}) DETACH DELETE n",
                    params={"doc_id": str(doc_id)},
                )
                logger.info("UsuniÄ™to wÄ™zÅ‚y grafu dla dokumentu %s", doc_id)
            except Exception as exc:  # pragma: no cover - logujemy, ale nie przerywamy
                logger.error(
                    "Nie udaÅ‚o siÄ™ usunÄ…Ä‡ wÄ™zÅ‚Ã³w grafu dokumentu %s: %s",
                    doc_id,
                    exc,
                )

    async def _delete_chunks_from_neo4j(self, doc_id: str) -> None:
        """CzyÅ›ci wszystkie chunki dokumentu z indeksu Neo4j Vector."""

        if not self.vector_store:
            return

        try:
            driver = self.vector_store._driver  # DostÄ™p wewnÄ™trzny â€“ akceptowalny w serwisie.

            def delete_chunks() -> None:
                with driver.session() as session:
                    session.execute_write(
                        lambda tx: tx.run(
                            "MATCH (n:RAGChunk {doc_id: $doc_id}) DETACH DELETE n",
                            doc_id=doc_id,
                        )
                    )

            await asyncio.to_thread(delete_chunks)
            logger.info("UsuniÄ™to wektorowe chunki dokumentu %s", doc_id)
        except Exception as exc:  # pragma: no cover - logujemy, ale nie przerywamy
            logger.error("Nie udaÅ‚o siÄ™ usunÄ…Ä‡ chunkÃ³w dokumentu %s z Neo4j: %s", doc_id, exc)
