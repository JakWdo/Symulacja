# üõ†Ô∏è Scripts - Utility Scripts dla Market Research SaaS

Ten folder zawiera skrypty pomocnicze (utility scripts) do zarzƒÖdzania infrastrukturƒÖ i inicjalizacji systemu.

---

## üìú Dostƒôpne Skrypty

### 1. init_db.py

**Opis:** Inicjalizacja bazy danych PostgreSQL

**Co robi:**
- W≈ÇƒÖcza rozszerzenie `pgvector` (wektory dla embeddings AI)
- Tworzy wszystkie tabele z modeli SQLAlchemy (Project, Persona, FocusGroup, PersonaEvent, etc.)

**Kiedy u≈ºywaƒá:**
- Pierwszy setup projektu (alternatywa dla Alembic migrations)
- Development environment reset
- Testowanie czystej bazy danych

**Uruchomienie:**
```bash
# Z poziomu root projektu
python scripts/init_db.py

# Lub jako modu≈Ç
python -m scripts.init_db
```

**Wymagania:**
- PostgreSQL uruchomiony (`docker-compose up -d postgres`)
- `DATABASE_URL` skonfigurowany w `.env`

**Uwagi:**
- Bezpiecznie: u≈ºywa `CREATE IF NOT EXISTS` - nie nadpisuje istniejƒÖcych danych
- W produkcji zalecane jest u≈ºywanie Alembic migrations zamiast tego skryptu

---

### 2. init_neo4j_indexes.py

**Opis:** Inicjalizacja indeks√≥w Neo4j dla RAG System

**Co robi:**
1. **Vector Index** (`rag_document_embeddings`)
   - Dla semantic search (Google Gemini embeddings)
   - Node: `RAGChunk`
   - Property: `embedding`
   - Dimensions: 768
   - Similarity: cosine

2. **Fulltext Index** (`rag_fulltext_index`)
   - Dla keyword search (Lucene-based)
   - Node: `RAGChunk`
   - Property: `text`

**Kiedy u≈ºywaƒá:**
- **PRZED pierwszym u≈ºyciem RAG!** (wymagane dla hybrid search)
- Po resecie Neo4j database
- Weryfikacja ≈ºe indeksy istniejƒÖ

**Uruchomienie:**
```bash
# Z poziomu root projektu
python scripts/init_neo4j_indexes.py
```

**Wymagania:**
- Neo4j uruchomiony (`docker-compose up -d neo4j`)
- `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD` w `.env`
- Neo4j 5.x+ (dla vector index support)

**Output:**
- ‚úÖ Potwierdza ≈ºe indeksy zosta≈Çy utworzone lub ju≈º istniejƒÖ
- üìä Pokazuje liczbƒô RAGChunk nodes w bazie
- ‚ö†Ô∏è Ostrzega je≈õli Neo4j niedostƒôpny lub wersja za stara

**Uwagi:**
- Indeksy sƒÖ tworzone asynchronicznie - mogƒÖ byƒá w stanie POPULATING przez chwilƒô
- Sprawd≈∫ status: `SHOW INDEXES` w Neo4j Browser (http://localhost:7474)

---

## üöÄ Workflow Setup Projektu

### Pierwsze Uruchomienie (New Developer)

```bash
# 1. Start Docker services
docker-compose up -d

# 2. Poczekaj na inicjalizacjƒô baz
sleep 10

# 3. Migracje bazy danych (preferowana metoda)
docker-compose exec api alembic upgrade head

# LUB alternatywnie: init_db.py
python scripts/init_db.py

# 4. Inicjalizuj Neo4j indeksy (WYMAGANE dla RAG!)
python scripts/init_neo4j_indexes.py

# 5. Weryfikuj ≈ºe wszystko dzia≈Ça
docker-compose ps
curl http://localhost:8000/docs  # API docs
curl http://localhost:7474        # Neo4j browser
```

### Reset Environment (Clean State)

```bash
# 1. Zatrzymaj i usu≈Ñ wszystko (UWAGA: usuwa dane!)
docker-compose down -v

# 2. Start od nowa
docker-compose up -d

# 3. Poczekaj na inicjalizacjƒô
sleep 10

# 4. Migracje
docker-compose exec api alembic upgrade head

# 5. Neo4j indeksy
python scripts/init_neo4j_indexes.py

# 6. (Opcjonalnie) Upload RAG documents
# U≈ºyj frontendu lub POST /api/v1/rag/documents/upload
```

---

## üìù Dodawanie Nowych Skrypt√≥w

### Template: Nowy Skrypt Utility

```python
#!/usr/bin/env python3
"""
Opis co robi skrypt

U≈ºycie:
    python scripts/my_script.py [args]

Wymagania:
    - Lista wymaga≈Ñ (DB, API keys, etc.)
"""

import sys
from pathlib import Path

# Dodaj root directory do path (je≈õli potrzebne importy z app/)
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.config import get_settings

settings = get_settings()


def main():
    """
    G≈Ç√≥wna funkcja skryptu
    """
    print("=" * 80)
    print("SCRIPT NAME")
    print("=" * 80)

    # Implementacja...

    print("‚úÖ Script completed successfully")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
```

### Konwencje dla Skrypt√≥w

1. **Shebang:** `#!/usr/bin/env python3` (dla Unix-like systems)
2. **Docstring:** Jasny opis, usage, requirements
3. **Exit codes:** 0 = success, 1 = error
4. **Logging:** Print progress i results (user-friendly)
5. **Error handling:** Try/except z informacyjnymi error messages
6. **Idempotentno≈õƒá:** Bezpieczne re-run (CREATE IF NOT EXISTS)

---

## üß™ Testowanie Skrypt√≥w

### Manual Testing

```bash
# Test init_db.py
docker-compose up -d postgres
python scripts/init_db.py
# Verify: psql do bazy, sprawd≈∫ \dt (list tables)

# Test init_neo4j_indexes.py
docker-compose up -d neo4j
python scripts/init_neo4j_indexes.py
# Verify: Neo4j Browser ‚Üí SHOW INDEXES
```

### Automated Testing

Testy skrypt√≥w powinny byƒá w `tests/integration/` lub `tests/manual/`:

```python
# tests/integration/test_scripts.py

@pytest.mark.integration
async def test_init_db_script():
    """Test ≈ºe init_db.py dzia≈Ça poprawnie"""
    result = subprocess.run(
        ["python", "scripts/init_db.py"],
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    assert "Database initialization complete" in result.stdout
```

---

## üîç Debugging Skrypt√≥w

### Common Issues

#### ‚ùå "Module not found" error
```bash
# RozwiƒÖzanie: Uruchom jako modu≈Ç lub dodaj do PYTHONPATH
python -m scripts.init_db
# LUB
PYTHONPATH=/Users/jakubwdowicz/market-research-saas python scripts/init_db.py
```

#### ‚ùå "Connection refused" (PostgreSQL)
```bash
# RozwiƒÖzanie: Sprawd≈∫ czy Docker dzia≈Ça
docker-compose ps
docker-compose logs postgres
docker-compose up -d postgres
```

#### ‚ùå "Connection refused" (Neo4j)
```bash
# RozwiƒÖzanie: Neo4j mo≈ºe potrzebowaƒá ~30s na start
docker-compose logs neo4j
# Poczekaj a≈º zobaczysz: "Started."
sleep 30
python scripts/init_neo4j_indexes.py
```

#### ‚ùå Neo4j "unsupported feature" error
```bash
# RozwiƒÖzanie: U≈ºywasz Neo4j <5.0
# Vector indexes wymagajƒÖ Neo4j 5.x+
docker-compose down
# Zaktualizuj docker-compose.yml do neo4j:5-enterprise lub neo4j:5
docker-compose up -d neo4j
```

---

## üìö PowiƒÖzana Dokumentacja

- **G≈Ç√≥wna dokumentacja:** [../CLAUDE.md](../CLAUDE.md)
- **Setup i instalacja:** [../README.md](../README.md)
- **Testy:** [../docs/TESTING.md](../docs/TESTING.md)
- **RAG System:** [../docs/RAG_HYBRID_SEARCH.md](../docs/RAG_HYBRID_SEARCH.md)
- **GraphRAG:** [../docs/GRAPH_RAG.md](../docs/GRAPH_RAG.md)

---

## ü§ù Contributing

DodajƒÖc nowy skrypt:
1. Dodaj jasny docstring z usage i requirements
2. Dodaj do tego README.md
3. Dodaj testy (je≈õli ma sens)
4. Update [../CLAUDE.md](../CLAUDE.md) je≈õli skrypt zmienia workflow

---

### 3. backup_neo4j.py ‚≠ê NOWY

**Opis:** Backup grafu Neo4j do pliku .cypher (Cypher statements)

**Co robi:**
- Eksportuje wszystkie nodes i relationships do Cypher CREATE statements
- Weryfikuje po≈ÇƒÖczenie z Neo4j przed backup
- Tworzy timestamped backups w `data/backups/`
- Wspiera `--dry-run` mode (podglƒÖd bez tworzenia backup)
- Weryfikuje ≈ºe backup siƒô powi√≥d≈Ç

**Kiedy u≈ºywaƒá:**
- **PRZED cleanup operations** (np. cleanup_legacy_mentions.py)
- **PRZED production deployment**
- Regularnie jako czƒô≈õƒá backup strategy
- Po wa≈ºnych zmianach w grafie

**Uruchomienie:**
```bash
# Dry-run (podglƒÖd bez tworzenia backup)
python scripts/backup_neo4j.py --dry-run

# W≈Ça≈õciwy backup (domy≈õlna lokalizacja)
python scripts/backup_neo4j.py

# Backup do custom lokalizacji
python scripts/backup_neo4j.py --output /path/to/backup.cypher
```

**Output:**
- Default: `data/backups/neo4j-backup-YYYY-MM-DD-HH-MM.cypher`
- Custom: ≈öcie≈ºka podana w `--output`

**Co NIE jest w backup:**
- ‚ö†Ô∏è **Embedding vectors** (zbyt du≈ºe dla text backup)
- Po restore musisz ponownie uruchomiƒá RAG ingest aby odtworzyƒá embeddings

**Przywracanie backup:**
```bash
# 1. Zatrzymaj aplikacjƒô
docker-compose down

# 2. Usu≈Ñ Neo4j volume (UWAGA: usuwa wszystkie dane!)
docker volume rm market-research-saas_neo4j_data

# 3. Uruchom Neo4j
docker-compose up -d neo4j

# 4. Za≈Çaduj backup
cat data/backups/neo4j-backup-2025-10-15-12-00.cypher | \
  docker exec -i market-research-saas-neo4j-1 cypher-shell \
  -u neo4j -p dev_password_change_in_prod

# 5. Re-create indexes
python scripts/init_neo4j_indexes.py

# 6. Re-create embeddings (upload dokumenty ponownie)
# POST /api/v1/rag/documents/upload
```

**Uwagi:**
- Backup NIE zawiera embedding vectors (zbyt du≈ºe)
- Wielko≈õƒá backup: ~50KB per 1000 nodes (bez embeddings)
- Restore mo≈ºe zajƒÖƒá kilka minut dla du≈ºych graf√≥w

---

### 4. cleanup_legacy_mentions.py ‚≠ê NOWY

**Opis:** Usuwanie legacy data z archived feature (graph_service.py)

**Co usuwa:**
- **MENTIONS relationships** (2757 relacji = 51% wszystkich relacji)
- **Concept nodes** (20)
- **Emotion nodes** (1)
- **Persona nodes** bez `doc_id` (nie u≈ºywane przez personas table)

**Co NIE usuwa (RAG nodes - INTACT):**
- ‚úÖ Wskaznik, Obserwacja, Trend, Demografia, Lokalizacja, RAGChunk nodes
- ‚úÖ OPISUJE, DOTYCZY, POKAZUJE_TREND, ZLOKALIZOWANY_W, POWIAZANY_Z relationships

**Kiedy u≈ºywaƒá:**
- Po potwierdzeniu ≈ºe archived feature (graph_service.py) nie jest u≈ºywane
- Aby oczy≈õciƒá graf z legacy data
- **TYLKO je≈õli masz backup!**

**Uruchomienie:**

‚ö†Ô∏è **WA≈ªNE: Zawsze najpierw zr√≥b backup!**

```bash
# KROK 1: Backup (WYMAGANE!)
python scripts/backup_neo4j.py

# KROK 2: Dry-run (sprawd≈∫ co zostanie usuniƒôte)
python scripts/cleanup_legacy_mentions.py --dry-run

# KROK 3: W≈Ça≈õciwy cleanup (po potwierdzeniu ≈ºe dry-run OK)
python scripts/cleanup_legacy_mentions.py
```

**Interactive Confirmation:**
Script wymaga wpisania `YES` aby kontynuowaƒá (safety check).

**Expected Results:**
```
BEFORE ‚Üí AFTER
Total Nodes: 2753 ‚Üí ~2728 (-25)
Total Relationships: 5453 ‚Üí ~2696 (-2757)

LEGACY DATA DELETED:
MENTIONS relationships: 2757 ‚Üí 0
Concept nodes: 20 ‚Üí 0
Emotion nodes: 1 ‚Üí 0
Unused Persona nodes: 4 ‚Üí 0

RAG DATA INTACT:
Wskaznik: 150 ‚Üí 150 (no change)
Obserwacja: 200 ‚Üí 200 (no change)
```

**Rollback (je≈õli co≈õ posz≈Ço nie tak):**
Zobacz instrukcje w output cleanup script lub backup_neo4j.py

**Uwagi:**
- Batch delete (1000 items na raz) dla performance
- Pre + Post verification (fail fast je≈õli co≈õ nie tak)
- Detailed logging (INFO level)
- Idempotent (mo≈ºe byƒá uruchomiony multiple times)

---

## üìä Code Review Report - MENTIONS Usage

### Podsumowanie

**Status:** ‚úÖ Bezpieczne do usuniƒôcia

MENTIONS relationships sƒÖ u≈ºywane TYLKO przez archived feature `app/services/archived/graph_service.py`.

### Pliki U≈ºywajƒÖce MENTIONS

1. **app/services/archived/graph_service.py** (ARCHIVED)
   - Status: Feature archived, nie u≈ºywane w obecnej wersji
   - Usage: Tworzenie MENTIONS relationships w `_extract_concepts_and_emotions()`

2. **app/api/graph_analysis.py** (API Endpoints)
   - Status: Endpoints ukryte z frontend UI (AppSidebar, App.tsx)
   - Impact cleanup: Endpoints przestanƒÖ dzia≈Çaƒá (ale ju≈º sƒÖ ukryte)
   - Recommendation: Mo≈ºna pozostawiƒá (backend-only) lub usunƒÖƒá

3. **app/api/focus_groups.py** (Background Task)
   - Status: Automatyczne budowanie grafu po zako≈Ñczeniu focus group (linia 166)
   - Impact cleanup: Task bƒôdzie failowaƒá (ale gracefully catchowany)
   - Recommendation: Wy≈ÇƒÖczyƒá automatyczne budowanie grafu (zakomentowaƒá linie 164-173)

4. **app/schemas/graph.py** (API Schemas)
   - Status: Schemas wspominajƒÖ "mentions" jako przyk≈Çad
   - Impact cleanup: Schemas mogƒÖ pozostaƒá (backward compatibility)
   - Recommendation: Dodaƒá deprecation notice

5. **tests/** (Unit Tests)
   - Status: Testy dla GraphService i MENTIONS relationships
   - Impact cleanup: Testy mogƒÖ pozostaƒá (dokumentujƒÖ legacy behavior)
   - Recommendation: Dodaƒá skip marker lub przenie≈õƒá do `tests/archived/`

### Dependency Check Results

‚úÖ **Brak blocking dependencies**

All MENTIONS relationships follow expected pattern:
- `Persona ‚Üí MENTIONS ‚Üí Concept` (100% of relationships)

**Konkluzja:** Bezpieczne do usuniƒôcia.

---

## üöÄ Workflow Setup Projektu

### Pierwsze Uruchomienie (New Developer)

```bash
# 1. Start Docker services
docker-compose up -d

# 2. Poczekaj na inicjalizacjƒô baz
sleep 10

# 3. Migracje bazy danych (preferowana metoda)
docker-compose exec api alembic upgrade head

# 4. Inicjalizuj Neo4j indeksy (WYMAGANE dla RAG!)
python scripts/init_neo4j_indexes.py

# 5. (OPCJONALNIE) Backup przed jakimikolwiek zmianami
python scripts/backup_neo4j.py

# 6. (OPCJONALNIE) Cleanup legacy data (je≈õli nie jest u≈ºywane)
# python scripts/cleanup_legacy_mentions.py --dry-run

# 7. Weryfikuj ≈ºe wszystko dzia≈Ça
docker-compose ps
curl http://localhost:8000/docs  # API docs
```

### Reset Environment (Clean State)

```bash
# 1. (OPCJONALNIE) Backup je≈õli chcesz zachowaƒá dane
python scripts/backup_neo4j.py

# 2. Zatrzymaj i usu≈Ñ wszystko (UWAGA: usuwa dane!)
docker-compose down -v

# 3. Start od nowa
docker-compose up -d

# 4. Poczekaj na inicjalizacjƒô
sleep 10

# 5. Migracje
docker-compose exec api alembic upgrade head

# 6. Neo4j indeksy
python scripts/init_neo4j_indexes.py

# 7. (Opcjonalnie) Restore backup je≈õli chcesz
# cat data/backups/neo4j-backup-YYYY-MM-DD-HH-MM.cypher | \
#   docker exec -i market-research-saas-neo4j-1 cypher-shell \
#   -u neo4j -p dev_password_change_in_prod
```

### Maintenance Workflow (Cleanup Legacy Data)

```bash
# 1. BACKUP FIRST!
python scripts/backup_neo4j.py

# 2. Dry-run (sprawd≈∫ co zostanie usuniƒôte)
python scripts/cleanup_legacy_mentions.py --dry-run

# 3. Przejrzyj output dry-run
# - Sprawd≈∫ legacy data counts
# - Sprawd≈∫ ≈ºe RAG nodes sƒÖ intact

# 4. W≈Ça≈õciwy cleanup (ONLY if dry-run OK)
python scripts/cleanup_legacy_mentions.py

# 5. Weryfikuj ≈ºe cleanup siƒô powi√≥d≈Ç
# - Sprawd≈∫ post-cleanup summary
# - Przetestuj RAG queries: POST /api/v1/rag/ask
```

**Ostatnia aktualizacja:** 2025-10-15
**Liczba skrypt√≥w:** 4
