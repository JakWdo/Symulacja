# Prompts Index - Complete Catalog

Katalog wszystkich 25 prompt√≥w w systemie konfiguracji Sight. Ka≈ºdy prompt zawiera ID, wersjƒô, parametry i przyk≈Çad u≈ºycia.

**Ostatnia aktualizacja:** 2025-10-27
**≈ÅƒÖczna liczba prompt√≥w:** 25 (23 base + 2 warianty)

---

## üìë Spis Tre≈õci

- [Focus Groups (2)](#focus-groups)
- [Personas (7)](#personas)
- [RAG - Retrieval Augmented Generation (2)](#rag)
- [Surveys (4)](#surveys)
- [System Prompts (10)](#system-prompts)

---

## Focus Groups

### `focus_groups.discussion_summary`

**Plik:** `config/prompts/focus_groups/discussion_summary.yaml`
**Wersja:** 1.0.0
**Opis:** Generate comprehensive strategic summary of focus group discussion

**Parametry:**
- `topic` - temat dyskusji w grupie fokusowej
- `description` - opis projektu badawczego
- `demo_context` - kontekst demograficzny uczestnik√≥w (opcjonalny)
- `discussion_text` - pe≈Çny transkrypt dyskusji
- `recommendations_section` - sekcja z rekomendacjami (opcjonalna)

**U≈ºywany w:**
- `DiscussionSummarizer` (app/services/focus_groups/discussion_summarizer.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("focus_groups.discussion_summary")
rendered = template.render(
    topic="AI in healthcare",
    description="Badanie percepcji AI w s≈Çu≈ºbie zdrowia",
    demo_context="8 uczestnik√≥w (4K/4M), 25-45 lat",
    discussion_text="[transkrypt]",
    recommendations_section="## 5. STRATEGIC RECOMMENDATIONS\n..."
)
```

**Output:** Markdown summary z 6 sekcjami (Executive Summary, Key Insights, Surprising Findings, Segment Analysis, Recommendations, Sentiment Narrative)

---

### `focus_groups.persona_response`

**Plik:** `config/prompts/focus_groups/persona_response.yaml`
**Wersja:** 1.0.0
**Opis:** Generate persona response in focus group discussion (2-4 sentences, natural, conversational)

**Parametry:**
- `full_name` - pe≈Çne imiƒô i nazwisko persony
- `age` - wiek
- `gender` - p≈Çeƒá
- `occupation` - zaw√≥d
- `education_level` - poziom wykszta≈Çcenia
- `location` - lokalizacja geograficzna
- `values` - warto≈õci persony
- `interests` - zainteresowania
- `background_story` - historia ≈ºycia persony
- `context_text` - dodatkowy kontekst z RAG (opcjonalny)
- `question` - pytanie moderatora

**U≈ºywany w:**
- `FocusGroupServiceLangChain` (app/services/focus_groups/focus_group_service_langchain.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("focus_groups.persona_response")
rendered = template.render(
    full_name="Anna Kowalska",
    age=32,
    gender="kobieta",
    occupation="Marketing Manager",
    education_level="wy≈ºsze",
    location="Warszawa",
    values="rozw√≥j osobisty, work-life balance",
    interests="joga, podcasty biznesowe",
    background_story="[historia]",
    context_text="",
    question="Co my≈õlisz o produktach ekologicznych?"
)
```

**Output:** 2-4 zdania naturalnej odpowiedzi persony

---

## Personas

### `personas.jtbd`

**Plik:** `config/prompts/personas/jtbd.yaml`
**Wersja:** 1.0.0
**Opis:** Jobs-to-be-Done analysis for personas using JTBD methodology

**Parametry:**
- `age` - wiek persony
- `occupation` - zaw√≥d
- `values` - warto≈õci
- `interests` - zainteresowania
- `background` - t≈Ço ≈ºyciowe
- `segment_name` - nazwa segmentu
- `rag_section` - kontekst z RAG (opcjonalny)
- `formatted_responses` - ostatnie 10 odpowiedzi z grup fokusowych

**U≈ºywany w:**
- `PersonaNeedsService` (app/services/personas/persona_needs_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.jtbd")
rendered = template.render(
    age=28,
    occupation="Grafik freelancer",
    values="niezale≈ºno≈õƒá, kreatywno≈õƒá",
    interests="design, fotografia",
    background="[historia]",
    segment_name="M≈Çodzi Profesjonali≈õci",
    rag_section="",
    formatted_responses="[ostatnie odpowiedzi]"
)
```

**Output:** JSON z Jobs-to-be-Done, desired outcomes, pain points (z severity, quotes, solutions)

---

### `personas.orchestration`

**Plik:** `config/prompts/personas/orchestration.yaml`
**Wersja:** 1.0.0
**Opis:** Persona allocation orchestration - deep sociological analysis with educational briefs

**Parametry:**
- `num_personas` - liczba person do wygenerowania
- `project_description` - opis projektu badawczego
- `additional_context` - dodatkowy kontekst od u≈ºytkownika
- `target_demographics` - docelowy rozk≈Çad demograficzny (JSON)
- `graph_context` - kontekst z Graph RAG (opcjonalny)

**U≈ºywany w:**
- `PersonaOrchestrationService` (app/services/personas/persona_orchestration.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts, models
from app.services.shared.clients import build_chat_model

# Model config (gemini-2.5-pro, temp=0.3)
model_config = models.get("personas", "orchestration")
llm = build_chat_model(**model_config.params)

template = prompts.get("personas.orchestration")
rendered = template.render(
    num_personas=20,
    project_description="Badanie aplikacji fitness",
    additional_context="Focus na m≈Çodych u≈ºytkownik√≥w",
    target_demographics='{"age_groups": {"18-24": 0.3, "25-34": 0.5}}',
    graph_context="[insights z Neo4j]"
)
```

**Output:** JSON z `total_personas`, `overall_context`, `groups[]` (ka≈ºda z d≈Çugim briefem 900-1200 znak√≥w, segment_characteristics, graph_insights, allocation_reasoning)

---

### `personas.persona_generation_system`

**Plik:** `config/prompts/personas/persona_generation_system.yaml`
**Wersja:** 1.0.0
**Opis:** System prompt dla generatora person - tworzy realistyczne syntetyczne persony dla polskiego rynku

**Parametry:** brak (system prompt)

**U≈ºywany w:**
- `PersonaGeneratorLangChain` (app/services/personas/persona_generator_langchain.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.persona_generation_system")
system_message = template.messages[0]["content"]

# U≈ºywane jako system prompt w LangChain
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", system_message),
    ("user", "Generate persona: {demographics}")
])
```

**Output:** U≈ºywany jako system prompt (brak bezpo≈õredniego output)

---

### `personas.persona_uniqueness`

**Plik:** `config/prompts/personas/persona_uniqueness.yaml`
**Wersja:** 1.0.0
**Opis:** Describe what makes this persona unique within their segment (250-400 words)

**Parametry:**
- `persona_name` - pe≈Çne imiƒô i nazwisko
- `age` - wiek
- `occupation` - zaw√≥d
- `background_story` - historia ≈ºycia
- `values` - warto≈õci
- `interests` - zainteresowania
- `segment_name` - nazwa segmentu
- `segment_brief_summary` - brief segmentu (typowy przedstawiciel)

**U≈ºywany w:**
- `PersonaDetailsService` (app/services/personas/persona_details_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.persona_uniqueness")
rendered = template.render(
    persona_name="Anna Kowalska",
    age=32,
    occupation="Marketing Manager",
    background_story="[historia]",
    values="rozw√≥j osobisty",
    interests="joga, podcasty",
    segment_name="AspirujƒÖce Profesjonalistki 25-34",
    segment_brief_summary="[brief segmentu]"
)
```

**Output:** 3-4 akapity (250-400 s≈Ç√≥w) opisujƒÖce unikalno≈õƒá persony wzglƒôdem segmentu

---

### `personas.segment_brief`

**Plik:** `config/prompts/personas/segment_brief.yaml`
**Wersja:** 1.0.0
**Opis:** Generate long, engaging, personal segment description (400-800 words)

**Parametry:**
- `segment_name` - nazwa segmentu
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `location` - lokalizacja
- `income` - przedzia≈Ç dochodowy
- `rag_context` - kontekst z RAG (dane spo≈Çeczne z Polski)
- `example_personas` - przyk≈Çadowe persony z segmentu (opcjonalne)

**U≈ºywany w:**
- `SegmentBriefService` (app/services/personas/segment_brief_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_brief")
rendered = template.render(
    segment_name="M≈Çodzi Profesjonali≈õci",
    age_range="25-34",
    gender="r√≥≈ºnorodny",
    education="wy≈ºsze",
    location="du≈ºe miasta",
    income="8-12k PLN netto",
    rag_context="[dane spo≈Çeczne z RAG]",
    example_personas="Anna (32, Marketing), Tomasz (29, IT)"
)
```

**Output:** 400-800 s≈Ç√≥w storytelling description w 4 sekcjach (Kim sƒÖ? / Kontekst zawodowy / Warto≈õci / Wyzwania)

---

### `personas.segment_context`

**Plik:** `config/prompts/personas/segment_context.yaml`
**Wersja:** 1.0.0
**Opis:** Generate social context for a segment (500-800 chars)

**Parametry:**
- `segment_name` - nazwa segmentu
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `income` - przedzia≈Ç dochodowy
- `insights_text` - insights z grafu wiedzy
- `citations_text` - cytaty z RAG
- `project_goal` - cel projektu badawczego

**U≈ºywany w:**
- `PersonaOrchestrationService` (wewnƒôtrznie dla contextual briefs)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_context")
rendered = template.render(
    segment_name="M≈Çodzi Prekariusze",
    age_range="18-24",
    gender="r√≥≈ºnorodny",
    education="≈õrednie / licencjat w trakcie",
    income="3-5k PLN netto",
    insights_text="[insights z Neo4j]",
    citations_text="[cytaty z dokument√≥w RAG]",
    project_goal="Badanie aplikacji finansowych"
)
```

**Output:** 500-800 znak√≥w kontekstu spo≈Çecznego dla segmentu

---

### `personas.segment_name`

**Plik:** `config/prompts/personas/segment_name.yaml`
**Wersja:** 1.0.0
**Opis:** Generate meaningful, evocative segment names (2-4 words)

**Parametry:**
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `income` - przedzia≈Ç dochodowy
- `insights_text` - insights z grafu wiedzy
- `citations_text` - cytaty z RAG

**U≈ºywany w:**
- `PersonaOrchestrationService` (generowanie nazw segment√≥w)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_name")
rendered = template.render(
    age_range="25-34",
    gender="kobieta",
    education="wy≈ºsze",
    income="8-12k PLN netto",
    insights_text="Wysoka stopa zatrudnienia, stabilna kariera",
    citations_text="78.4% zatrudnienia w grupie 25-34"
)
```

**Output:** 2-4 s≈Çowa nazwy segmentu (np. "AspirujƒÖce Profesjonalistki 25-34", "M≈Çodzi Prekariusze")

---

## RAG

### `rag.cypher_generation`

**Plik:** `config/prompts/rag/cypher_generation.yaml`
**Wersja:** 1.0.0
**Opis:** Generate Cypher query from natural language question (Polish society analyst)

**Parametry:**
- `graph_schema` - schema grafu Neo4j
- `question` - pytanie w jƒôzyku naturalnym

**U≈ºywany w:**
- `GraphRAGService` (app/services/rag/rag_graph_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("rag.cypher_generation")
rendered = template.render(
    graph_schema="Node labels: Obserwacja, Wskaznik, Demografia...",
    question="Jakie sƒÖ najwiƒôksze wska≈∫niki zatrudnienia w Polsce?"
)
```

**Output:** Cypher query (string) do wykonania na grafie Neo4j

**Wƒôz≈Çy:** Obserwacja, Wskaznik, Demografia, Trend, Lokalizacja
**Relacje:** OPISUJE, DOTYCZY, POKAZUJE_TREND, ZLOKALIZOWANY_W, POWIAZANY_Z

---

### `rag.graph_rag_answer`

**Plik:** `config/prompts/rag/graph_rag_answer.yaml`
**Wersja:** 1.0.0
**Opis:** Answer question using graph context and RAG documents (Polish social expert)

**Parametry:**
- `question` - pytanie u≈ºytkownika
- `context` - kontekst z grafu i dokument√≥w RAG

**U≈ºywany w:**
- `GraphRAGService.answer_question()` (app/services/rag/rag_graph_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("rag.graph_rag_answer")
rendered = template.render(
    question="Jakie sƒÖ typowe zarobki m≈Çodych profesjonalist√≥w?",
    context="[kontekst z Neo4j + vector search]"
)
```

**Output:** Odpowied≈∫ po polsku z precyzyjnymi danymi z kontekstu

---

## Surveys

### `surveys.multiple_choice`

**Plik:** `config/prompts/surveys/multiple_choice.yaml`
**Wersja:** 1.0.0
**Opis:** Generate multiple-choice survey response as a specific persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony (demografia, warto≈õci, background)
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `options` - lista opcji odpowiedzi

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.multiple_choice")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Kt√≥re aplikacje fitness u≈ºywasz?",
    description="Mo≈ºesz wybraƒá wiele opcji",
    options="Nike Training Club\nStrava\nFitbit\nInne"
)
```

**Output:** Comma-separated list wybanych opcji (np. "Nike Training Club, Strava")

---

### `surveys.open_text`

**Plik:** `config/prompts/surveys/open_text.yaml`
**Wersja:** 1.0.0
**Opis:** Generate open-text survey response as a specific persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.open_text")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Co my≈õlisz o produktach ekologicznych?",
    description=""
)
```

**Output:** 2-4 zdania naturalnej odpowiedzi persony

---

### `surveys.rating_scale`

**Plik:** `config/prompts/surveys/rating_scale.yaml`
**Wersja:** 1.0.0
**Opis:** Generate rating scale survey response as a specific persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `scale_min` - minimalna warto≈õƒá skali (np. 1)
- `scale_max` - maksymalna warto≈õƒá skali (np. 10)

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.rating_scale")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Jak oceniasz jako≈õƒá us≈Çug w restauracji?",
    description="1 = bardzo s≈Çabo, 10 = doskonale",
    scale_min=1,
    scale_max=10
)
```

**Output:** Pojedyncza liczba (np. "8")

---

### `surveys.single_choice`

**Plik:** `config/prompts/surveys/single_choice.yaml`
**Wersja:** 1.0.0
**Opis:** Generate single-choice survey response as a specific persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `options` - lista opcji odpowiedzi

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.single_choice")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Jak czƒôsto korzystasz z social media?",
    description="",
    options="Codziennie\nKilka razy w tygodniu\nRzadko\nWcale"
)
```

**Output:** Wybrana opcja (np. "Codziennie")

---

## System Prompts

### `system.conversational_tone`

**Plik:** `config/prompts/system/conversational_tone.yaml`
**Wersja:** 1.0.0
**Opis:** Conversational style - like talking to a teammate, not reading a report

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Mo≈ºe byƒá kombinowany z innymi promptami dla stylu konwersacyjnego

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

# Get both prompts
conversational = prompts.get("system.conversational_tone")
main_prompt = prompts.get("personas.segment_brief")

# Combine system messages
system_message = conversational.messages[0]["content"] + "\n\n" + main_prompt.messages[0]["content"]
```

**Efekt:** Naturalny, konwersacyjny ton (jak kolega z zespo≈Çu, nie raport)

---

### `system.educational`

**Plik:** `config/prompts/system/educational.yaml`
**Wersja:** 1.0.0
**Opis:** Educational approach - teach the user, don't just deliver information

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Kombinowany z promptami wymagajƒÖcymi edukacyjnego podej≈õcia (np. orchestration)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

educational = prompts.get("system.educational")
# U≈ºywane jako czƒô≈õƒá system message
```

**Efekt:** Wyja≈õnia "dlaczego", u≈ºywa analogii, buduje wiedzƒô stopniowo

---

### `system.formatting_markdown`

**Plik:** `config/prompts/system/formatting_markdown.yaml`
**Wersja:** 1.0.0
**Opis:** Markdown formatting instructions for better readability (English)

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Prompty generujƒÖce d≈Çugi tekst w jƒôzyku angielskim

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

formatting = prompts.get("system.formatting_markdown")
# Dodaj do system message dla lepszego formatowania
```

**Efekt:** Output formatowany w Markdown (## headings, **bold**, bullets)

---

### `system.formatting_polish_markdown`

**Plik:** `config/prompts/system/formatting_polish_markdown.yaml`
**Wersja:** 1.0.0
**Opis:** Markdown formatting instructions for better readability (Polish)

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Prompty generujƒÖce d≈Çugi tekst po polsku

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

formatting = prompts.get("system.formatting_polish_markdown")
# Dodaj do system message dla lepszego formatowania
```

**Efekt:** Output formatowany w Markdown (## nag≈Ç√≥wki, **pogrubienie**, wypunktowania)

---

### `system.json_output`

**Plik:** `config/prompts/system/json_output.yaml`
**Wersja:** 1.0.0
**Opis:** JSON output instructions - strict formatting for parseable responses

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Wszystkie prompty wymagajƒÖce JSON output (orchestration, jtbd, etc.)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

json_instructions = prompts.get("system.json_output")
# Kombinuj z g≈Ç√≥wnym promptem dla strict JSON
```

**Efekt:** Wymusza valid JSON bez markdown code blocks, text wrappers, trailing commas

---

### `system.market_research_expert`

**Plik:** `config/prompts/system/market_research_expert.yaml`
**Wersja:** 1.0.0
**Opis:** Expert system prompt for market research analysis - strategic insights for product teams

**Parametry:** brak (system prompt)

**U≈ºywany w:**
- `DiscussionSummarizer` (focus group summaries)
- Inne serwisy wymagajƒÖce market research expertise

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

expert = prompts.get("system.market_research_expert")
system_message = expert.messages[0]["content"]
```

**Efekt:** Analiza z perspektywy eksperta market research (actionable insights, patterns, strategic recommendations)

---

### `system.market_research_expert` (variant B)

**Plik:** `config/prompts/system/market_research_expert_variant_b.yaml`
**Wersja:** 1.1.0
**Opis:** Expert system prompt for market research - VARIANT B (more concise)
**Variant:** b

**Parametry:** brak (system prompt)

**U≈ºywany w:** A/B testing prompt√≥w (bardziej zwiƒôz≈Ça wersja eksperta)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

# Random weighted selection
expert = prompts.get("system.market_research_expert")

# Lub konkretny variant
expert_b = prompts.get("system.market_research_expert", variant="b")
```

**Efekt:** Bardziej zwiƒôz≈Ça wersja eksperta (focus na actionable insights, bez fluff)

---

### `system.polish_society_expert`

**Plik:** `config/prompts/system/polish_society_expert.yaml`
**Wersja:** 1.0.0
**Opis:** Expert on Polish sociology and social research - grounded in real data

**Parametry:** brak (system prompt)

**U≈ºywany w:**
- `PersonaOrchestrationService` (orchestration)
- `SegmentBriefService` (segment briefs)
- Wszystkie serwisy wymagajƒÖce wiedzy o polskim spo≈Çecze≈Ñstwie

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

expert = prompts.get("system.polish_society_expert")
system_message = expert.messages[0]["content"]
```

**Efekt:** Analiza z perspektywy eksperta socjologii polskiej (konkretne liczby, ≈∫r√≥d≈Ça GUS/CBOS, kontekst spo≈Çeczno-ekonomiczny)

---

### `system.quality_control`

**Plik:** `config/prompts/system/quality_control.yaml`
**Wersja:** 1.0.0
**Opis:** Quality control specialist for AI-generated content verification

**Parametry:** brak (system prompt)

**U≈ºywany w:** Potencjalnie do walidacji wygenerowanych person / tre≈õci (obecnie nie u≈ºywany w production)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

qc = prompts.get("system.quality_control")
# U≈ºywane do weryfikacji wygenerowanych person
```

**Efekt:** Weryfikuje consistency, realizm, jƒôzyk polski, brak stereotyp√≥w

---

### `system.storytelling`

**Plik:** `config/prompts/system/storytelling.yaml`
**Wersja:** 1.0.0
**Opis:** Skilled storyteller who creates compelling narratives from data

**Parametry:** brak (modifier prompt)

**U≈ºywany w:** Kombinowany z segment briefs dla storytelling approach

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

storytelling = prompts.get("system.storytelling")
# U≈ºywane jako czƒô≈õƒá system message dla briefs
```

**Efekt:** Hook na poczƒÖtku, emotional connection, concrete examples, actionable insights na ko≈Ñcu

---

## üîç Szybkie Wyszukiwanie

### Po Kategorii
- **Focus Groups** - discussion_summary, persona_response
- **Personas** - jtbd, orchestration, persona_generation_system, persona_uniqueness, segment_brief, segment_context, segment_name
- **RAG** - cypher_generation, graph_rag_answer
- **Surveys** - multiple_choice, open_text, rating_scale, single_choice
- **System** - conversational_tone, educational, formatting_markdown, formatting_polish_markdown, json_output, market_research_expert, polish_society_expert, quality_control, storytelling

### Po Serwisie

**PersonaGeneratorLangChain:**
- personas.persona_generation_system

**PersonaOrchestrationService:**
- personas.orchestration
- personas.segment_name
- personas.segment_context
- system.polish_society_expert

**SegmentBriefService:**
- personas.segment_brief
- system.polish_society_expert
- system.storytelling

**PersonaNeedsService:**
- personas.jtbd

**PersonaDetailsService:**
- personas.persona_uniqueness

**FocusGroupServiceLangChain:**
- focus_groups.persona_response

**DiscussionSummarizer:**
- focus_groups.discussion_summary
- system.market_research_expert

**GraphRAGService:**
- rag.cypher_generation
- rag.graph_rag_answer
- system.polish_society_expert

**SurveyResponseGenerator:**
- surveys.single_choice
- surveys.multiple_choice
- surveys.rating_scale
- surveys.open_text

---

## üìö Dodatkowe Zasoby

**G≈Ç√≥wna dokumentacja:**
- `config/README.md` - Kompletny przewodnik po systemie konfiguracji
- `config/models.yaml` - Model registry (fallback chain)
- `config/pricing.yaml` - Model pricing dla cost tracking

**Walidacja:**
```bash
# Waliduj wszystkie prompty
python scripts/config_validate.py

# Check placeholders
python scripts/config_validate.py --check-placeholders

# Auto-bump versions
python scripts/config_validate.py --auto-bump
```

**Testy:**
```bash
# Test prompt registry
pytest tests/config/test_prompt_registry.py -v

# Test model registry
pytest tests/config/test_model_registry.py -v
```

---

**Ostatnia aktualizacja:** 2025-10-27
**Autor:** Claude Code + Config System Team
