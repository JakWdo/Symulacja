# Indeks Prompt√≥w - Kompletny Katalog

Katalog wszystkich 25 prompt√≥w w systemie konfiguracji Sight. Ka≈ºdy prompt zawiera ID, wersjƒô, parametry i przyk≈Çad u≈ºycia.

**Ostatnia aktualizacja:** 2025-10-27
**≈ÅƒÖczna liczba prompt√≥w:** 25 (23 bazowe + 2 warianty)

---

## üìë Spis Tre≈õci

- [Grupy Fokusowe (2)](#grupy-fokusowe)
- [Persony (7)](#persony)
- [RAG - Retrieval Augmented Generation (2)](#rag)
- [Ankiety (4)](#ankiety)
- [Prompty Systemowe (10)](#prompty-systemowe)

---

## Grupy Fokusowe

### `focus_groups.discussion_summary`

**Plik:** `config/prompts/focus_groups/discussion_summary.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje kompleksowe strategiczne podsumowanie dyskusji w grupie fokusowej

**Parametry:**
- `topic` - temat dyskusji w grupie fokusowej
- `description` - opis projektu badawczego
- `demo_context` - kontekst demograficzny uczestnik√≥w (opcjonalny)
- `discussion_text` - pe≈Çny transkrypt dyskusji
- `recommendations_section` - sekcja z rekomendacjami (opcjonalna)

**U≈ºywany w:**
- `DiscussionSummarizer` (app/services/focus_groups/discussion_summarizer.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("focus_groups.discussion_summary")
rendered = template.render(
    topic="AI w s≈Çu≈ºbie zdrowia",
    description="Badanie percepcji AI w s≈Çu≈ºbie zdrowia",
    demo_context="8 uczestnik√≥w (4K/4M), 25-45 lat",
    discussion_text="[transkrypt]",
    recommendations_section="## 5. REKOMENDACJE STRATEGICZNE\n..."
)
```

**Output:** Podsumowanie w formacie Markdown z 6 sekcjami (Executive Summary, Kluczowe Wnioski, ZaskakujƒÖce Odkrycia, Analiza Segment√≥w, Rekomendacje, Narracja Sentymentu)

---

### `focus_groups.persona_response`

**Plik:** `config/prompts/focus_groups/persona_response.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje odpowied≈∫ persony w dyskusji grupowej (2-4 zdania, naturalna, konwersacyjna)

**Parametry:**
- `full_name` - pe≈Çne imiƒô i nazwisko persony
- `age` - wiek
- `gender` - p≈Çeƒá
- `occupation` - zaw√≥d
- `education_level` - poziom wykszta≈Çcenia
- `location` - lokalizacja geograficzna
- `values` - warto≈õci persony
- `interests` - zainteresowania
- `background_story` - historia ≈ºycia persony
- `context_text` - dodatkowy kontekst z RAG (opcjonalny)
- `question` - pytanie moderatora

**U≈ºywany w:**
- `FocusGroupServiceLangChain` (app/services/focus_groups/focus_group_service_langchain.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("focus_groups.persona_response")
rendered = template.render(
    full_name="Anna Kowalska",
    age=32,
    gender="kobieta",
    occupation="Marketing Manager",
    education_level="wy≈ºsze",
    location="Warszawa",
    values="rozw√≥j osobisty, work-life balance",
    interests="joga, podcasty biznesowe",
    background_story="[historia]",
    context_text="",
    question="Co my≈õlisz o produktach ekologicznych?"
)
```

**Output:** 2-4 zdania naturalnej odpowiedzi persony

---

## Persony

### `personas.jtbd`

**Plik:** `config/prompts/personas/jtbd.yaml`
**Wersja:** 1.0.0
**Opis:** Analiza Jobs-to-be-Done dla person z wykorzystaniem metodologii JTBD

**Parametry:**
- `age` - wiek persony
- `occupation` - zaw√≥d
- `values` - warto≈õci
- `interests` - zainteresowania
- `background` - t≈Ço ≈ºyciowe
- `segment_name` - nazwa segmentu
- `rag_section` - kontekst z RAG (opcjonalny)
- `formatted_responses` - ostatnie 10 odpowiedzi z grup fokusowych

**U≈ºywany w:**
- `PersonaNeedsService` (app/services/personas/persona_needs_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.jtbd")
rendered = template.render(
    age=28,
    occupation="Grafik freelancer",
    values="niezale≈ºno≈õƒá, kreatywno≈õƒá",
    interests="design, fotografia",
    background="[historia]",
    segment_name="M≈Çodzi Profesjonali≈õci",
    rag_section="",
    formatted_responses="[ostatnie odpowiedzi]"
)
```

**Output:** JSON z Jobs-to-be-Done, po≈ºƒÖdanymi rezultatami, bolƒÖczkami (z severity, cytatami, rozwiƒÖzaniami)

---

### `personas.orchestration`

**Plik:** `config/prompts/personas/orchestration.yaml`
**Wersja:** 1.0.0
**Opis:** Orkiestracja alokacji person - g≈Çƒôboka analiza socjologiczna z edukacyjnymi briefami

**Parametry:**
- `num_personas` - liczba person do wygenerowania
- `project_description` - opis projektu badawczego
- `additional_context` - dodatkowy kontekst od u≈ºytkownika
- `target_demographics` - docelowy rozk≈Çad demograficzny (JSON)
- `graph_context` - kontekst z Graph RAG (opcjonalny)

**U≈ºywany w:**
- `PersonaOrchestrationService` (app/services/personas/persona_orchestration.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts, models
from app.services.shared.clients import build_chat_model

# Konfiguracja modelu (gemini-2.5-pro, temp=0.3)
model_config = models.get("personas", "orchestration")
llm = build_chat_model(**model_config.params)

template = prompts.get("personas.orchestration")
rendered = template.render(
    num_personas=20,
    project_description="Badanie aplikacji fitness",
    additional_context="Fokus na m≈Çodych u≈ºytkownik√≥w",
    target_demographics='{"age_groups": {"18-24": 0.3, "25-34": 0.5}}',
    graph_context="[insights z Neo4j]"
)
```

**Output:** JSON z `total_personas`, `overall_context`, `groups[]` (ka≈ºda z d≈Çugim briefem 900-1200 znak√≥w, cechami segmentu, insightami z grafu, uzasadnieniem alokacji)

---

### `personas.persona_generation_system`

**Plik:** `config/prompts/personas/persona_generation_system.yaml`
**Wersja:** 1.0.0
**Opis:** Systemowy prompt dla generatora person - tworzy realistyczne syntetyczne persony dla polskiego rynku

**Parametry:** brak (prompt systemowy)

**U≈ºywany w:**
- `PersonaGeneratorLangChain` (app/services/personas/persona_generator_langchain.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.persona_generation_system")
system_message = template.messages[0]["content"]

# U≈ºywane jako system prompt w LangChain
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", system_message),
    ("user", "Wygeneruj personƒô: {demographics}")
])
```

**Output:** U≈ºywany jako prompt systemowy (brak bezpo≈õredniego outputu)

---

### `personas.persona_uniqueness`

**Plik:** `config/prompts/personas/persona_uniqueness.yaml`
**Wersja:** 1.0.0
**Opis:** Opisuje co czyni tƒô personƒô wyjƒÖtkowƒÖ w ramach jej segmentu (250-400 s≈Ç√≥w)

**Parametry:**
- `persona_name` - pe≈Çne imiƒô i nazwisko
- `age` - wiek
- `occupation` - zaw√≥d
- `background_story` - historia ≈ºycia
- `values` - warto≈õci
- `interests` - zainteresowania
- `segment_name` - nazwa segmentu
- `segment_brief_summary` - brief segmentu (typowy przedstawiciel)

**U≈ºywany w:**
- `PersonaDetailsService` (app/services/personas/persona_details_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.persona_uniqueness")
rendered = template.render(
    persona_name="Anna Kowalska",
    age=32,
    occupation="Marketing Manager",
    background_story="[historia]",
    values="rozw√≥j osobisty",
    interests="joga, podcasty",
    segment_name="AspirujƒÖce Profesjonalistki 25-34",
    segment_brief_summary="[brief segmentu]"
)
```

**Output:** 3-4 akapity (250-400 s≈Ç√≥w) opisujƒÖce unikalno≈õƒá persony wzglƒôdem segmentu

---

### `personas.segment_brief`

**Plik:** `config/prompts/personas/segment_brief.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje d≈Çugi, anga≈ºujƒÖcy, osobisty opis segmentu (400-800 s≈Ç√≥w)

**Parametry:**
- `segment_name` - nazwa segmentu
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `location` - lokalizacja
- `income` - przedzia≈Ç dochodowy
- `rag_context` - kontekst z RAG (dane spo≈Çeczne z Polski)
- `example_personas` - przyk≈Çadowe persony z segmentu (opcjonalne)

**U≈ºywany w:**
- `SegmentBriefService` (app/services/personas/segment_brief_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_brief")
rendered = template.render(
    segment_name="M≈Çodzi Profesjonali≈õci",
    age_range="25-34",
    gender="r√≥≈ºnorodny",
    education="wy≈ºsze",
    location="du≈ºe miasta",
    income="8-12k PLN netto",
    rag_context="[dane spo≈Çeczne z RAG]",
    example_personas="Anna (32, Marketing), Tomasz (29, IT)"
)
```

**Output:** 400-800 s≈Ç√≥w opisu storytellingowego w 4 sekcjach (Kim sƒÖ? / Kontekst zawodowy / Warto≈õci / Wyzwania)

---

### `personas.segment_context`

**Plik:** `config/prompts/personas/segment_context.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje kontekst spo≈Çeczny dla segmentu (500-800 znak√≥w)

**Parametry:**
- `segment_name` - nazwa segmentu
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `income` - przedzia≈Ç dochodowy
- `insights_text` - insights z grafu wiedzy
- `citations_text` - cytaty z RAG
- `project_goal` - cel projektu badawczego

**U≈ºywany w:**
- `PersonaOrchestrationService` (wewnƒôtrznie dla kontekstowych brief√≥w)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_context")
rendered = template.render(
    segment_name="M≈Çodzi Prekariusze",
    age_range="18-24",
    gender="r√≥≈ºnorodny",
    education="≈õrednie / licencjat w trakcie",
    income="3-5k PLN netto",
    insights_text="[insights z Neo4j]",
    citations_text="[cytaty z dokument√≥w RAG]",
    project_goal="Badanie aplikacji finansowych"
)
```

**Output:** 500-800 znak√≥w kontekstu spo≈Çecznego dla segmentu

---

### `personas.segment_name`

**Plik:** `config/prompts/personas/segment_name.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje znaczƒÖce, evokacyjne nazwy segment√≥w (2-4 s≈Çowa)

**Parametry:**
- `age_range` - zakres wiekowy
- `gender` - p≈Çeƒá
- `education` - wykszta≈Çcenie
- `income` - przedzia≈Ç dochodowy
- `insights_text` - insights z grafu wiedzy
- `citations_text` - cytaty z RAG

**U≈ºywany w:**
- `PersonaOrchestrationService` (generowanie nazw segment√≥w)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("personas.segment_name")
rendered = template.render(
    age_range="25-34",
    gender="kobieta",
    education="wy≈ºsze",
    income="8-12k PLN netto",
    insights_text="Wysoka stopa zatrudnienia, stabilna kariera",
    citations_text="78.4% zatrudnienia w grupie 25-34"
)
```

**Output:** 2-4 s≈Çowa nazwy segmentu (np. "AspirujƒÖce Profesjonalistki 25-34", "M≈Çodzi Prekariusze")

---

## RAG

### `rag.cypher_generation`

**Plik:** `config/prompts/rag/cypher_generation.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje zapytanie Cypher z pytania w jƒôzyku naturalnym (analityk spo≈Çecze≈Ñstwa polskiego)

**Parametry:**
- `graph_schema` - schemat grafu Neo4j
- `question` - pytanie w jƒôzyku naturalnym

**U≈ºywany w:**
- `GraphRAGService` (app/services/rag/rag_graph_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("rag.cypher_generation")
rendered = template.render(
    graph_schema="Etykiety wƒôz≈Ç√≥w: Obserwacja, Wskaznik, Demografia...",
    question="Jakie sƒÖ najwiƒôksze wska≈∫niki zatrudnienia w Polsce?"
)
```

**Output:** Zapytanie Cypher (string) do wykonania na grafie Neo4j

**Wƒôz≈Çy:** Obserwacja, Wskaznik, Demografia, Trend, Lokalizacja
**Relacje:** OPISUJE, DOTYCZY, POKAZUJE_TREND, ZLOKALIZOWANY_W, POWIAZANY_Z

---

### `rag.graph_rag_answer`

**Plik:** `config/prompts/rag/graph_rag_answer.yaml`
**Wersja:** 1.0.0
**Opis:** Odpowiada na pytanie wykorzystujƒÖc kontekst z grafu i dokument√≥w RAG (polski ekspert spo≈Çeczny)

**Parametry:**
- `question` - pytanie u≈ºytkownika
- `context` - kontekst z grafu i dokument√≥w RAG

**U≈ºywany w:**
- `GraphRAGService.answer_question()` (app/services/rag/rag_graph_service.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("rag.graph_rag_answer")
rendered = template.render(
    question="Jakie sƒÖ typowe zarobki m≈Çodych profesjonalist√≥w?",
    context="[kontekst z Neo4j + vector search]"
)
```

**Output:** Odpowied≈∫ po polsku z precyzyjnymi danymi z kontekstu

---

## Ankiety

### `surveys.multiple_choice`

**Plik:** `config/prompts/surveys/multiple_choice.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje odpowied≈∫ wielokrotnego wyboru w ankiecie jako konkretna persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony (demografia, warto≈õci, t≈Ço)
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `options` - lista opcji odpowiedzi

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.multiple_choice")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Kt√≥re aplikacje fitness u≈ºywasz?",
    description="Mo≈ºesz wybraƒá wiele opcji",
    options="Nike Training Club\nStrava\nFitbit\nInne"
)
```

**Output:** Lista wybranych opcji rozdzielona przecinkami (np. "Nike Training Club, Strava")

---

### `surveys.open_text`

**Plik:** `config/prompts/surveys/open_text.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje odpowied≈∫ tekstowƒÖ w ankiecie jako konkretna persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.open_text")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Co my≈õlisz o produktach ekologicznych?",
    description=""
)
```

**Output:** 2-4 zdania naturalnej odpowiedzi persony

---

### `surveys.rating_scale`

**Plik:** `config/prompts/surveys/rating_scale.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje odpowied≈∫ na skali ocen w ankiecie jako konkretna persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `scale_min` - minimalna warto≈õƒá skali (np. 1)
- `scale_max` - maksymalna warto≈õƒá skali (np. 10)

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.rating_scale")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Jak oceniasz jako≈õƒá us≈Çug w restauracji?",
    description="1 = bardzo s≈Çabo, 10 = doskonale",
    scale_min=1,
    scale_max=10
)
```

**Output:** Pojedyncza liczba (np. "8")

---

### `surveys.single_choice`

**Plik:** `config/prompts/surveys/single_choice.yaml`
**Wersja:** 1.0.0
**Opis:** Generuje odpowied≈∫ jednokrotnego wyboru w ankiecie jako konkretna persona

**Parametry:**
- `persona_context` - pe≈Çny kontekst persony
- `question` - pytanie ankietowe
- `description` - dodatkowy opis pytania (opcjonalny)
- `options` - lista opcji odpowiedzi

**U≈ºywany w:**
- `SurveyResponseGenerator` (app/services/surveys/survey_response_generator.py)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

template = prompts.get("surveys.single_choice")
rendered = template.render(
    persona_context="Anna, 32 lata, Marketing Manager...",
    question="Jak czƒôsto korzystasz z social media?",
    description="",
    options="Codziennie\nKilka razy w tygodniu\nRzadko\nWcale"
)
```

**Output:** Wybrana opcja (np. "Codziennie")

---

## Prompty Systemowe

### `system.conversational_tone`

**Plik:** `config/prompts/system/conversational_tone.yaml`
**Wersja:** 1.0.0
**Opis:** Styl konwersacyjny - jak rozmowa z kolegƒÖ z zespo≈Çu, nie czytanie raportu

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Mo≈ºe byƒá kombinowany z innymi promptami dla stylu konwersacyjnego

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

# Pobierz oba prompty
conversational = prompts.get("system.conversational_tone")
main_prompt = prompts.get("personas.segment_brief")

# Po≈ÇƒÖcz komunikaty systemowe
system_message = conversational.messages[0]["content"] + "\n\n" + main_prompt.messages[0]["content"]
```

**Efekt:** Naturalny, konwersacyjny ton (jak kolega z zespo≈Çu, nie raport)

---

### `system.educational`

**Plik:** `config/prompts/system/educational.yaml`
**Wersja:** 1.0.0
**Opis:** Podej≈õcie edukacyjne - ucz u≈ºytkownika, nie tylko dostarczaj informacji

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Kombinowany z promptami wymagajƒÖcymi edukacyjnego podej≈õcia (np. orchestration)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

educational = prompts.get("system.educational")
# U≈ºywane jako czƒô≈õƒá system message
```

**Efekt:** Wyja≈õnia "dlaczego", u≈ºywa analogii, buduje wiedzƒô stopniowo

---

### `system.formatting_markdown`

**Plik:** `config/prompts/system/formatting_markdown.yaml`
**Wersja:** 1.0.0
**Opis:** Instrukcje formatowania Markdown dla lepszej czytelno≈õci (angielski)

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Prompty generujƒÖce d≈Çugi tekst w jƒôzyku angielskim

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

formatting = prompts.get("system.formatting_markdown")
# Dodaj do system message dla lepszego formatowania
```

**Efekt:** Output formatowany w Markdown (## headings, **bold**, bullets)

---

### `system.formatting_polish_markdown`

**Plik:** `config/prompts/system/formatting_polish_markdown.yaml`
**Wersja:** 1.0.0
**Opis:** Instrukcje formatowania Markdown dla lepszej czytelno≈õci (polski)

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Prompty generujƒÖce d≈Çugi tekst po polsku

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

formatting = prompts.get("system.formatting_polish_markdown")
# Dodaj do system message dla lepszego formatowania
```

**Efekt:** Output formatowany w Markdown (## nag≈Ç√≥wki, **pogrubienie**, wypunktowania)

---

### `system.json_output`

**Plik:** `config/prompts/system/json_output.yaml`
**Wersja:** 1.0.0
**Opis:** Instrukcje outputu JSON - ≈õcis≈Çe formatowanie dla parsowalnych odpowiedzi

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Wszystkie prompty wymagajƒÖce outputu JSON (orchestration, jtbd, itp.)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

json_instructions = prompts.get("system.json_output")
# Kombinuj z g≈Ç√≥wnym promptem dla ≈õcis≈Çego JSON
```

**Efekt:** Wymusza poprawny JSON bez markdown code blocks, text wrappers, trailing commas

---

### `system.market_research_expert`

**Plik:** `config/prompts/system/market_research_expert.yaml`
**Wersja:** 1.0.0
**Opis:** Ekspert systemowy prompt dla analizy bada≈Ñ rynkowych - strategiczne wnioski dla zespo≈Ç√≥w produktowych

**Parametry:** brak (prompt systemowy)

**U≈ºywany w:**
- `DiscussionSummarizer` (podsumowania grup fokusowych)
- Inne serwisy wymagajƒÖce ekspertyzy market research

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

expert = prompts.get("system.market_research_expert")
system_message = expert.messages[0]["content"]
```

**Efekt:** Analiza z perspektywy eksperta market research (actionable insights, wzorce, rekomendacje strategiczne)

---

### `system.market_research_expert` (wariant B)

**Plik:** `config/prompts/system/market_research_expert_variant_b.yaml`
**Wersja:** 1.1.0
**Opis:** Ekspert systemowy prompt dla market research - WARIANT B (bardziej zwiƒôz≈Çy)
**Wariant:** b

**Parametry:** brak (prompt systemowy)

**U≈ºywany w:** Testy A/B prompt√≥w (bardziej zwiƒôz≈Ça wersja eksperta)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

# Losowy wa≈ºony wyb√≥r
expert = prompts.get("system.market_research_expert")

# Lub konkretny wariant
expert_b = prompts.get("system.market_research_expert", variant="b")
```

**Efekt:** Bardziej zwiƒôz≈Ça wersja eksperta (fokus na actionable insights, bez zbƒôdnych s≈Ç√≥w)

---

### `system.polish_society_expert`

**Plik:** `config/prompts/system/polish_society_expert.yaml`
**Wersja:** 1.0.0
**Opis:** Ekspert w dziedzinie socjologii i bada≈Ñ spo≈Çecznych w Polsce - oparty na rzeczywistych danych

**Parametry:** brak (prompt systemowy)

**U≈ºywany w:**
- `PersonaOrchestrationService` (orchestration)
- `SegmentBriefService` (briefe segment√≥w)
- Wszystkie serwisy wymagajƒÖce wiedzy o polskim spo≈Çecze≈Ñstwie

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

expert = prompts.get("system.polish_society_expert")
system_message = expert.messages[0]["content"]
```

**Efekt:** Analiza z perspektywy eksperta socjologii polskiej (konkretne liczby, ≈∫r√≥d≈Ça GUS/CBOS, kontekst spo≈Çeczno-ekonomiczny)

---

### `system.quality_control`

**Plik:** `config/prompts/system/quality_control.yaml`
**Wersja:** 1.0.0
**Opis:** Specjalista kontroli jako≈õci dla weryfikacji tre≈õci generowanych przez AI

**Parametry:** brak (prompt systemowy)

**U≈ºywany w:** Potencjalnie do walidacji wygenerowanych person / tre≈õci (obecnie nie u≈ºywany w produkcji)

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

qc = prompts.get("system.quality_control")
# U≈ºywane do weryfikacji wygenerowanych person
```

**Efekt:** Weryfikuje sp√≥jno≈õƒá, realizm, jƒôzyk polski, brak stereotyp√≥w

---

### `system.storytelling`

**Plik:** `config/prompts/system/storytelling.yaml`
**Wersja:** 1.0.0
**Opis:** Utalentowany storyteller tworzƒÖcy anga≈ºujƒÖce narracje z danych

**Parametry:** brak (prompt modyfikujƒÖcy)

**U≈ºywany w:** Kombinowany z briefami segment√≥w dla podej≈õcia storytellingowego

**Przyk≈Çad u≈ºycia:**
```python
from config import prompts

storytelling = prompts.get("system.storytelling")
# U≈ºywane jako czƒô≈õƒá system message dla brief√≥w
```

**Efekt:** Hook na poczƒÖtku, emotional connection, konkretne przyk≈Çady, actionable insights na ko≈Ñcu

---

## üîç Szybkie Wyszukiwanie

### Po Kategorii
- **Grupy Fokusowe** - discussion_summary, persona_response
- **Persony** - jtbd, orchestration, persona_generation_system, persona_uniqueness, segment_brief, segment_context, segment_name
- **RAG** - cypher_generation, graph_rag_answer
- **Ankiety** - multiple_choice, open_text, rating_scale, single_choice
- **Systemowe** - conversational_tone, educational, formatting_markdown, formatting_polish_markdown, json_output, market_research_expert, polish_society_expert, quality_control, storytelling

### Po Serwisie

**PersonaGeneratorLangChain:**
- personas.persona_generation_system

**PersonaOrchestrationService:**
- personas.orchestration
- personas.segment_name
- personas.segment_context
- system.polish_society_expert

**SegmentBriefService:**
- personas.segment_brief
- system.polish_society_expert
- system.storytelling

**PersonaNeedsService:**
- personas.jtbd

**PersonaDetailsService:**
- personas.persona_uniqueness

**FocusGroupServiceLangChain:**
- focus_groups.persona_response

**DiscussionSummarizer:**
- focus_groups.discussion_summary
- system.market_research_expert

**GraphRAGService:**
- rag.cypher_generation
- rag.graph_rag_answer
- system.polish_society_expert

**SurveyResponseGenerator:**
- surveys.single_choice
- surveys.multiple_choice
- surveys.rating_scale
- surveys.open_text

---

## üìö Dodatkowe Zasoby

**G≈Ç√≥wna dokumentacja:**
- `config/README.md` - Kompletny przewodnik po systemie konfiguracji
- `config/models.yaml` - Rejestr modeli (fallback chain)
- `config/pricing.yaml` - Ceny modeli dla ≈õledzenia koszt√≥w

**Walidacja:**
```bash
# Waliduj wszystkie prompty
python scripts/config_validate.py

# Sprawd≈∫ placeholdery
python scripts/config_validate.py --check-placeholders

# Auto-bump wersji
python scripts/config_validate.py --auto-bump
```

**Testy:**
```bash
# Test rejestru prompt√≥w
pytest tests/config/test_prompt_registry.py -v

# Test rejestru modeli
pytest tests/config/test_model_registry.py -v
```

---

**Ostatnia aktualizacja:** 2025-10-27